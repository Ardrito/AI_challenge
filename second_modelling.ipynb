{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3026e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.transforms as transformers\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import math\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5cd2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states_scaler = joblib.load(\"initial_states_scaler.gz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166932f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.82638725e+03 4.58659977e-03 8.72826111e+01 3.59665972e+02\n",
      " 3.59640694e+02 3.59845867e+02 4.50029728e+01 1.79871944e+02\n",
      " 4.99987154e+02]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "File ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d73f3788-ff00-452a-ab1e-00d5bc57cd64",
       "rows": [
        [
         "0",
         "0",
         "0.800022283128424",
         "0.4109313380973263",
         "0.015596378929025434",
         "0.4004074932051341",
         "0.7147327836978034",
         "0.28449374666140165",
         "0.7450528789395089",
         "0.32627039186482976",
         "0.895051887696147"
        ],
        [
         "1",
         "1",
         "0.7997654229304167",
         "0.4106660191758262",
         "0.01569114859265497",
         "0.39872532994606746",
         "0.6956258678435426",
         "0.3036397811450043",
         "0.7439667147468552",
         "0.6950278085728413",
         "0.8892687452881175"
        ],
        [
         "2",
         "2",
         "0.7708713980755206",
         "0.4355220555061562",
         "0.013964986862230688",
         "0.3971760726347921",
         "0.6792594617911087",
         "0.319939611168103",
         "0.6109454079575612",
         "0.7905824340971317",
         "0.9049850075427899"
        ],
        [
         "3",
         "3",
         "0.7707496635402151",
         "0.4376552819060178",
         "0.013863447936913076",
         "0.3961654625997282",
         "0.6698738602823231",
         "0.32940564139987",
         "0.5698624504084041",
         "0.8120333848908229",
         "0.9026064999969332"
        ],
        [
         "4",
         "4",
         "0.7699696298107597",
         "0.4423675653830102",
         "0.012990213179165266",
         "0.39337783366690093",
         "0.6354360067571765",
         "0.3639688020841423",
         "0.4506177024534861",
         "0.1372362146311119",
         "0.8997767740453225"
        ],
        [
         "5",
         "5",
         "0.7696159541349488",
         "0.44475550980865697",
         "0.01323390659993251",
         "0.39236282430603886",
         "0.6242248653829351",
         "0.3752628165101548",
         "0.403323161037004",
         "0.15879379168493613",
         "0.9009281629069563"
        ],
        [
         "6",
         "6",
         "0.7688589609278651",
         "0.4492873556620363",
         "0.01343021518888321",
         "0.39033396330163034",
         "0.6016792280441955",
         "0.39795135923075614",
         "0.31706544356685695",
         "0.20153251544178358",
         "0.9056025881642592"
        ],
        [
         "7",
         "7",
         "0.794422050030704",
         "0.4637000270673862",
         "0.014425296657009312",
         "0.3673305833344238",
         "0.36155801633467977",
         "0.6398976119388314",
         "0.7253682051925625",
         "0.28971745444568764",
         "0.8125775973938706"
        ],
        [
         "8",
         "8",
         "0.793885029121995",
         "0.46960094524327184",
         "0.013721293441463445",
         "0.3647048804634237",
         "0.33679284549551963",
         "0.664800824017438",
         "0.7251552534094956",
         "0.745672233612828",
         "0.8149679324845622"
        ],
        [
         "9",
         "9",
         "0.7938649107688747",
         "0.4673403598305177",
         "0.013721293441463445",
         "0.36423168280610146",
         "0.33183689342811834",
         "0.6697616083183744",
         "0.7240694157027615",
         "0.28878314142333794",
         "0.815393865599792"
        ],
        [
         "10",
         "10",
         "0.7927462593600971",
         "0.47314574639138524",
         "0.014641913031027798",
         "0.3590366964879313",
         "0.28508295634791375",
         "0.7166695051969607",
         "0.7221813884263273",
         "0.2656681789456027",
         "0.8249775324243216"
        ],
        [
         "11",
         "11",
         "0.7925880970914889",
         "0.47220115469040624",
         "0.015034530208925645",
         "0.3579567005951063",
         "0.27314426990910673",
         "0.7286459466919225",
         "0.7220455044181385",
         "0.22190394685656217",
         "0.827688981099905"
        ],
        [
         "12",
         "12",
         "0.7921197201283157",
         "0.46562098844576033",
         "0.014107141357676767",
         "0.35484776651671845",
         "0.2409287288363509",
         "0.7608913195557654",
         "0.99",
         "0.99",
         "0.99"
        ],
        [
         "13",
         "13",
         "0.7916998179376122",
         "0.4744405383117302",
         "0.013572369684329288",
         "0.3522223723703357",
         "0.21608821752153917",
         "0.7856929426615548",
         "0.7220197621208722",
         "0.6774427794309571",
         "0.8438215500320217"
        ],
        [
         "14",
         "14",
         "0.7915706104620668",
         "0.47009975568840845",
         "0.01284128942203111",
         "0.3511403697674977",
         "0.20643274889914912",
         "0.7952875218406165",
         "0.7200729581016938",
         "0.6337591948032556",
         "0.8475833727612908"
        ],
        [
         "15",
         "15",
         "0.7908860385575238",
         "0.4656740670564915",
         "0.013477600020699754",
         "0.34763140576611173",
         "0.1731747920649188",
         "0.8284513605655142",
         "0.7187822344726941",
         "0.24166870017786046",
         "0.8596456080071999"
        ],
        [
         "16",
         "16",
         "0.749302751128841",
         "0.485732938611942",
         "0.011500975607820152",
         "0.34458946492969994",
         "0.14048158002563432",
         "0.861221624557699",
         "0.05366443222194012",
         "0.7888051087560117",
         "0.9594072482041031"
        ],
        [
         "17",
         "17",
         "0.7903849397355316",
         "0.4564299871475464",
         "0.01284128942203111",
         "0.3444729985677852",
         "0.13976985954867968",
         "0.8616207677116854",
         "0.7178129631328108",
         "0.17596763735588988",
         "0.8709489600891518"
        ],
        [
         "18",
         "18",
         "0.789887267282495",
         "0.455273179846517",
         "0.013572369684329288",
         "0.34189460774440183",
         "0.11664704932423609",
         "0.884694536838279",
         "0.7183999573853441",
         "0.6976813830345996",
         "0.8790822062453979"
        ],
        [
         "19",
         "19",
         "0.7891945169172487",
         "0.44981799350503665",
         "0.01303759801098181",
         "0.33877957635482026",
         "0.0861169426217436",
         "0.9149644815904372",
         "0.7175427604400291",
         "0.6974168136055485",
         "0.8890031966333184"
        ],
        [
         "20",
         "20",
         "0.7889270406295132",
         "0.44641117697624944",
         "0.013619754516145832",
         "0.3377115435409196",
         "0.0753584616462944",
         "0.9256335183435227",
         "0.7186151642760081",
         "0.6538437667752793",
         "0.892241628153002"
        ],
        [
         "21",
         "21",
         "0.788545379376199",
         "0.44566822469033496",
         "0.013206829553183752",
         "0.33620890364687195",
         "0.05942534052196747",
         "0.9414864567211916",
         "0.7167418627042674",
         "0.21876533359442335",
         "0.8967213944947708"
        ],
        [
         "22",
         "22",
         "0.7884172010961201",
         "0.4177662223677574",
         "0.01569114859265497",
         "0.3348387837948439",
         "0.038721607988066564",
         "0.96271368769273",
         "0.7148962533524527",
         "0.9147693761752336",
         "0.8999064502666531"
        ],
        [
         "23",
         "23",
         "0.7869406628634046",
         "0.428347547201345",
         "0.01303759801098181",
         "0.32966015988139596",
         "0.9919316217253527",
         "0.00841671275806407",
         "0.7181592936334449",
         "0.8930696956094202",
         "0.9101518078691162"
        ],
        [
         "24",
         "24",
         "0.786660832413375",
         "0.4262248969864798",
         "0.012746519758401575",
         "0.3286393619339578",
         "0.9828321750764446",
         "0.01746685009511742",
         "0.7181132874208941",
         "0.9148626026803461",
         "0.9117963966586492"
        ],
        [
         "25",
         "25",
         "0.7861246622803115",
         "0.4251741974854862",
         "0.012448672244133263",
         "0.3258049612215942",
         "0.9513942002037282",
         "0.048669887455084944",
         "0.7164201271055569",
         "0.17551112493652937",
         "0.9152180430470724"
        ],
        [
         "26",
         "26",
         "0.7858414218179703",
         "0.42048321464277716",
         "0.012062824327916388",
         "0.3243193011815036",
         "0.935578026641504",
         "0.0643516669036492",
         "0.99",
         "0.99",
         "0.99"
        ],
        [
         "27",
         "27",
         "0.7852177099630175",
         "0.4174265983333772",
         "0.01223205587011833",
         "0.32208428931382516",
         "0.9112489196824214",
         "0.08851881723989645",
         "0.718315770046773",
         "0.5891349438016285",
         "0.9161641610624695"
        ],
        [
         "28",
         "28",
         "0.7850173770239408",
         "0.41473085727121417",
         "0.012326825533747865",
         "0.3211378939991807",
         "0.9011979907559708",
         "0.09848407937551083",
         "0.7182779996046313",
         "0.6762491516168285",
         "0.9157402318464442"
        ],
        [
         "29",
         "29",
         "0.7846894069124382",
         "0.4135209466487456",
         "0.012353902580500176",
         "0.31944940188545734",
         "0.8829788728632564",
         "0.11662145937615977",
         "0.7180272553895382",
         "0.045719625598037605",
         "0.9151376211095206"
        ],
        [
         "30",
         "30",
         "0.7843816118000504",
         "0.411695492174671",
         "0.012672057879836274",
         "0.3179611948672732",
         "0.8671088957031537",
         "0.13240893797689848",
         "0.717561152636715",
         "0.6114715019832577",
         "0.9135546927912112"
        ],
        [
         "31",
         "31",
         "0.7838749515968431",
         "0.40699385901482027",
         "0.012963136132416508",
         "0.31586456880934494",
         "0.843584758498267",
         "0.15583298816033814",
         "0.7170539312482175",
         "0.59009751422535",
         "0.9109021327937133"
        ],
        [
         "32",
         "32",
         "0.7836482056516267",
         "0.40464834288275237",
         "0.012868366468783421",
         "0.3153249953592814",
         "0.8374943764819149",
         "0.16191574347971865",
         "0.7169104154831198",
         "0.06818147298114158",
         "0.910196189649118"
        ],
        [
         "33",
         "33",
         "0.7831590896497822",
         "0.4086176740738409",
         "0.012306517748683632",
         "0.31336413095185545",
         "0.8165349803667045",
         "0.18281909046609865",
         "0.7163049214213392",
         "0.17734030301493425",
         "0.906530192801592"
        ],
        [
         "34",
         "34",
         "0.7828674320012823",
         "0.40559290987301283",
         "0.012868366468783421",
         "0.3118740715859669",
         "0.8009684493231863",
         "0.19829131806375674",
         "0.7159677743284141",
         "0.7432023542715553",
         "0.9028128734553957"
        ],
        [
         "35",
         "35",
         "0.7822761218786951",
         "0.40549740296870274",
         "0.012719442711649265",
         "0.30971238181492133",
         "0.7786745387171309",
         "0.22056366404305894",
         "0.7149190906670222",
         "0.6567585859556186",
         "0.8973830399487178"
        ],
        [
         "36",
         "36",
         "0.7820459146936294",
         "0.4054443243579715",
         "0.013545292637576978",
         "0.30870346976525304",
         "0.7669710596854044",
         "0.23224682117370612",
         "0.7147131289450016",
         "0.678789550485396",
         "0.8943960234159574"
        ],
        [
         "37",
         "37",
         "0.7812880839778131",
         "0.4026318498893496",
         "0.01133174406561821",
         "0.3065917933822265",
         "0.7414760279883693",
         "0.2577212648235794",
         "0.7131916562664044",
         "0.6576892177147664",
         "0.8879346286583183"
        ],
        [
         "38",
         "38",
         "0.7810760046098864",
         "0.40174033679911236",
         "0.011602514533137764",
         "0.30604890114252586",
         "0.7367806798613367",
         "0.2624600087584516",
         "0.7144310003650989",
         "0.13583861683642268",
         "0.8868999891932279"
        ],
        [
         "39",
         "39",
         "0.7801477530908834",
         "0.40645257085467823",
         "0.012502826337634332",
         "0.3036232518236019",
         "0.7090176373906137",
         "0.2903237241251168",
         "0.712710004172971",
         "0.7892211935810258",
         "0.8779660385058644"
        ],
        [
         "40",
         "40",
         "0.7799889570786149",
         "0.40751389596210547",
         "0.01240128741231672",
         "0.3024743331599421",
         "0.6964826341747486",
         "0.3028129469834272",
         "0.7103953610762274",
         "0.680911748874319",
         "0.8735243199032504"
        ],
        [
         "41",
         "41",
         "0.7792588185956433",
         "0.40489243530211444",
         "0.012793904590214566",
         "0.30044570369899654",
         "0.6738783300721819",
         "0.32550137738997786",
         "0.7090120354514053",
         "0.7252414917203385",
         "0.866060803962593"
        ],
        [
         "42",
         "42",
         "0.7788390941876067",
         "0.4040646264290315",
         "0.012644980833083963",
         "0.2993596104949779",
         "0.6622325914869588",
         "0.33716351941161704",
         "0.7113969877487593",
         "0.6821985667843078",
         "0.862622130909614"
        ],
        [
         "43",
         "43",
         "0.7777667383405422",
         "0.40787474649863437",
         "0.01476375974140609",
         "0.2961948744419946",
         "0.6279169346554146",
         "0.37161175119894807",
         "0.7072072881601198",
         "0.6184741880673839",
         "0.8504587808855124"
        ],
        [
         "44",
         "44",
         "0.7774554550423431",
         "0.40877686048459727",
         "0.013355753310317908",
         "0.2951679020022084",
         "0.6166143966385798",
         "0.3829874054129685",
         "0.7069759790463086",
         "0.6407389048429875",
         "0.8468694796494881"
        ],
        [
         "45",
         "45",
         "0.7768547731281288",
         "0.40758820107498545",
         "0.012110209159732932",
         "0.29312931617235166",
         "0.5966915496084613",
         "0.4030289865874",
         "0.7052306050430059",
         "0.6853146593336448",
         "0.8394113820296333"
        ],
        [
         "46",
         "46",
         "0.7766079714494616",
         "0.4111966570188265",
         "0.013355753310317908",
         "0.2920559578588008",
         "0.583976146093828",
         "0.4158093883689162",
         "0.99",
         "0.99",
         "0.99"
        ],
        [
         "47",
         "47",
         "0.7760246946935716",
         "0.42351857973932033",
         "0.017376694752954336",
         "0.2897959392971128",
         "0.5631251291054771",
         "0.4368025902753308",
         "0.7038493529931769",
         "0.4914186572438845",
         "0.8287413608586548"
        ],
        [
         "48",
         "48",
         "0.7762229003317813",
         "0.41552683874643326",
         "0.01722777099582018",
         "0.2893191141255361",
         "0.5594721967399189",
         "0.44033424332504073",
         "0.7043883590912529",
         "0.03492253561472819",
         "0.827661003377777"
        ],
        [
         "49",
         "49",
         "0.7755497662840547",
         "0.4150386539077199",
         "0.01435083477844401",
         "0.2871807330631043",
         "0.533188637421182",
         "0.46695208851044606",
         "0.7022708952640643",
         "0.9497366811184903",
         "0.8210272783076645"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 8119
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.800022</td>\n",
       "      <td>0.410931</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.400407</td>\n",
       "      <td>0.714733</td>\n",
       "      <td>0.284494</td>\n",
       "      <td>0.745053</td>\n",
       "      <td>0.326270</td>\n",
       "      <td>0.895052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.799765</td>\n",
       "      <td>0.410666</td>\n",
       "      <td>0.015691</td>\n",
       "      <td>0.398725</td>\n",
       "      <td>0.695626</td>\n",
       "      <td>0.303640</td>\n",
       "      <td>0.743967</td>\n",
       "      <td>0.695028</td>\n",
       "      <td>0.889269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.770871</td>\n",
       "      <td>0.435522</td>\n",
       "      <td>0.013965</td>\n",
       "      <td>0.397176</td>\n",
       "      <td>0.679259</td>\n",
       "      <td>0.319940</td>\n",
       "      <td>0.610945</td>\n",
       "      <td>0.790582</td>\n",
       "      <td>0.904985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.770750</td>\n",
       "      <td>0.437655</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>0.396165</td>\n",
       "      <td>0.669874</td>\n",
       "      <td>0.329406</td>\n",
       "      <td>0.569862</td>\n",
       "      <td>0.812033</td>\n",
       "      <td>0.902606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.769970</td>\n",
       "      <td>0.442368</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.393378</td>\n",
       "      <td>0.635436</td>\n",
       "      <td>0.363969</td>\n",
       "      <td>0.450618</td>\n",
       "      <td>0.137236</td>\n",
       "      <td>0.899777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>8114</td>\n",
       "      <td>0.535067</td>\n",
       "      <td>0.607103</td>\n",
       "      <td>0.159052</td>\n",
       "      <td>0.284968</td>\n",
       "      <td>0.668307</td>\n",
       "      <td>0.521740</td>\n",
       "      <td>0.890529</td>\n",
       "      <td>0.801062</td>\n",
       "      <td>0.851842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>8115</td>\n",
       "      <td>0.690987</td>\n",
       "      <td>0.229441</td>\n",
       "      <td>0.847954</td>\n",
       "      <td>0.277111</td>\n",
       "      <td>0.423743</td>\n",
       "      <td>0.628984</td>\n",
       "      <td>0.613536</td>\n",
       "      <td>0.776649</td>\n",
       "      <td>0.835652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>8116</td>\n",
       "      <td>0.711425</td>\n",
       "      <td>0.203270</td>\n",
       "      <td>0.936350</td>\n",
       "      <td>0.269214</td>\n",
       "      <td>0.120393</td>\n",
       "      <td>0.364463</td>\n",
       "      <td>0.523885</td>\n",
       "      <td>0.269405</td>\n",
       "      <td>0.837877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8117</th>\n",
       "      <td>8117</td>\n",
       "      <td>0.575161</td>\n",
       "      <td>0.506746</td>\n",
       "      <td>0.338160</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.890747</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>0.801671</td>\n",
       "      <td>0.252504</td>\n",
       "      <td>0.847061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>8118</td>\n",
       "      <td>0.514594</td>\n",
       "      <td>0.950478</td>\n",
       "      <td>0.066051</td>\n",
       "      <td>0.257084</td>\n",
       "      <td>0.276716</td>\n",
       "      <td>0.502326</td>\n",
       "      <td>0.060708</td>\n",
       "      <td>0.723779</td>\n",
       "      <td>0.888823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8119 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      File ID         0         1         2         3         4         5  \\\n",
       "0           0  0.800022  0.410931  0.015596  0.400407  0.714733  0.284494   \n",
       "1           1  0.799765  0.410666  0.015691  0.398725  0.695626  0.303640   \n",
       "2           2  0.770871  0.435522  0.013965  0.397176  0.679259  0.319940   \n",
       "3           3  0.770750  0.437655  0.013863  0.396165  0.669874  0.329406   \n",
       "4           4  0.769970  0.442368  0.012990  0.393378  0.635436  0.363969   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "8114     8114  0.535067  0.607103  0.159052  0.284968  0.668307  0.521740   \n",
       "8115     8115  0.690987  0.229441  0.847954  0.277111  0.423743  0.628984   \n",
       "8116     8116  0.711425  0.203270  0.936350  0.269214  0.120393  0.364463   \n",
       "8117     8117  0.575161  0.506746  0.338160  0.257812  0.890747  0.457447   \n",
       "8118     8118  0.514594  0.950478  0.066051  0.257084  0.276716  0.502326   \n",
       "\n",
       "             6         7         8  \n",
       "0     0.745053  0.326270  0.895052  \n",
       "1     0.743967  0.695028  0.889269  \n",
       "2     0.610945  0.790582  0.904985  \n",
       "3     0.569862  0.812033  0.902606  \n",
       "4     0.450618  0.137236  0.899777  \n",
       "...        ...       ...       ...  \n",
       "8114  0.890529  0.801062  0.851842  \n",
       "8115  0.613536  0.776649  0.835652  \n",
       "8116  0.523885  0.269405  0.837877  \n",
       "8117  0.801671  0.252504  0.847061  \n",
       "8118  0.060708  0.723779  0.888823  \n",
       "\n",
       "[8119 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_states = []\n",
    "\n",
    "path = \"input_data/\"\n",
    "\n",
    "for dir, sub_dir, files in os.walk(path):\n",
    "    for file in sorted(files):\n",
    "        #print(file)\n",
    "        temp = pd.read_csv((path+file),index_col=None, header=0)\n",
    "        initial_states.append(temp)\n",
    "\n",
    "initial_states_df = pd.concat(initial_states,axis=0,ignore_index=True)\n",
    "\n",
    "initial_states_norm_df = np.where(initial_states_df.iloc[:,2:] > 1e+10,0.0, initial_states_df.iloc[:,2:])\n",
    "\n",
    "initial_states_scaler = MinMaxScaler()\n",
    "initial_states_scaler_values = initial_states_scaler.fit(initial_states_norm_df)\n",
    "\n",
    "initial_states_normalized = initial_states_scaler_values.transform(initial_states_df.iloc[:,2:].values)\n",
    "\n",
    "initial_states_normalized = np.where(initial_states_normalized >=1, 0.99,initial_states_normalized)\n",
    "\n",
    "initial_states_normalized = pd.concat([initial_states_df['File ID'],pd.DataFrame(initial_states_normalized)],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "initial_states_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b475574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_states = []\n",
    "\n",
    "# path = \"input_data/\"\n",
    "\n",
    "# for dir, sub_dir, files in os.walk(path):\n",
    "#     for file in sorted(files):\n",
    "#         #print(file)\n",
    "#         temp = pd.read_csv((path+file),index_col=None, header=0)\n",
    "#         initial_states.append(temp)\n",
    "\n",
    "# initial_states_df = pd.concat(initial_states,axis=0,ignore_index=True)\n",
    "\n",
    "# hold = initial_states_df\n",
    "# x = initial_states_df.iloc[:,2:].values\n",
    "# x = normalize(x,norm='l2')\n",
    "# hold = pd.concat([hold['File ID'],pd.DataFrame(x)],axis=1)\n",
    "# initial_states_normalized = hold\n",
    "# #'2000-08-02 04:50:33'\n",
    "# timestamps = initial_states_df['Timestamp']\n",
    "# initial_states_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e980523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullDatasetPT(Dataset):\n",
    "    def __init__(self, initial_states_df, pt_dir='data/new_processed/pt_files'):\n",
    "        self.data = initial_states_df.reset_index(drop=True)\n",
    "        self.pt_dir = pt_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        file_id = str(int(row['File ID'])).zfill(5)\n",
    "        pt_path = os.path.join(self.pt_dir, f\"{file_id}.pt\")\n",
    "\n",
    "        if not os.path.exists(pt_path):\n",
    "            raise FileNotFoundError(f\".pt file not found for File ID: {file_id}\")\n",
    "\n",
    "        static_input = torch.tensor(row.drop(\"File ID\").fillna(0.0).values, dtype=torch.float32)\n",
    "        pt_data = torch.load(pt_path)\n",
    "\n",
    "        return (\n",
    "            static_input,\n",
    "            pt_data[\"density\"],\n",
    "            pt_data[\"density_mask\"],\n",
    "            pt_data[\"goes\"],\n",
    "            pt_data[\"goes_mask\"],\n",
    "            pt_data[\"omni2\"],\n",
    "            pt_data[\"omni2_mask\"]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd2593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Positional Encoding for Sequences\n",
    "# -----------------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=10000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000.0) / d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# -----------------------------------\n",
    "# STORMTransformer with Mask Handling\n",
    "# -----------------------------------\n",
    "class STORMTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 static_dim=9,\n",
    "                 omni2_dim=57,\n",
    "                 goes_dim=42,\n",
    "                 d_model=256,\n",
    "                 output_len=432,\n",
    "                 nhead=8,\n",
    "                 num_layers=4,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "\n",
    "        self.omni2_proj = nn.Linear(omni2_dim, d_model)\n",
    "        self.goes_proj = nn.Linear(goes_dim, d_model)\n",
    "\n",
    "        self.omni2_pos = PositionalEncoding(d_model)\n",
    "        self.goes_pos = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.omni2_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.goes_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256,360),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(360, output_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, static_input, omni2_seq, goes_seq, omni2_mask=None, goes_mask=None):\n",
    "        B = static_input.size(0)\n",
    "\n",
    "        #print(\"static input\",static_input.shape)\n",
    "        static_embed = self.static_encoder(static_input)\n",
    "        #print(\"static embed\", static_embed)\n",
    "        #static_embed = self.static_encoder(static_input)\n",
    "\n",
    "        omni2_embed = self.omni2_proj(omni2_seq)\n",
    "        omni2_embed = self.omni2_pos(omni2_embed)\n",
    "        omni2_key_mask = (~omni2_mask.bool()).any(dim=-1) if omni2_mask is not None else None\n",
    "        omni2_out = self.omni2_encoder(omni2_embed, src_key_padding_mask=omni2_key_mask)\n",
    "        omni2_summary = omni2_out.mean(dim=1)\n",
    "\n",
    "        if goes_seq.shape[1] > 1024:\n",
    "            step = goes_seq.shape[1] // 1024\n",
    "            goes_seq = goes_seq[:, ::step, :]\n",
    "            goes_mask = goes_mask[:, ::step, :] if goes_mask is not None else None\n",
    "        # global tester_mask\n",
    "        # global tester_seq\n",
    "        # tester_seq = goes_seq\n",
    "        # tester_mask = goes_mask\n",
    "        #print(goes_seq,\"\\n\",goes_mask)\n",
    "        #print(goes_mask.sum())\n",
    "        goes_embed = self.goes_proj(goes_seq)\n",
    "        goes_embed = self.goes_pos(goes_embed)\n",
    "        goes_key_mask = (~goes_mask.bool()).any(dim=-1) if goes_mask is not None else None\n",
    "        # global tester_key_mask\n",
    "        # global tester_embed\n",
    "        # tester_embed = goes_embed\n",
    "        # tester_key_mask = goes_key_mask\n",
    "        goes_out = self.goes_encoder(goes_embed, src_key_padding_mask=goes_key_mask)\n",
    "        goes_summary = goes_out.mean(dim=1)\n",
    "\n",
    "        combined = torch.cat((static_embed, omni2_summary, goes_summary), dim=-1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "# -----------------------------------\n",
    "# Masked MSE Loss\n",
    "# -----------------------------------\n",
    "def masked_mse_loss(preds, targets, mask, eps=1e-8):\n",
    "    # preds = torch.nan_to_num(preds, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    # targets = torch.nan_to_num(targets, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    # loss = (preds - targets) ** 2 * mask\n",
    "    # return loss.sum() / (mask.sum() + eps)\n",
    "    diff = (targets - preds) * mask\n",
    "    sq = torch.square(diff)\n",
    "    sum = torch.sum(sq)\n",
    "    N = torch.sum(mask)\n",
    "    # print(sum)\n",
    "    # print(N)\n",
    "    loss = torch.sqrt((sum/N))\n",
    "    return loss\n",
    "\n",
    "# -----------------------------------\n",
    "# Full Training Loop with FullDataset\n",
    "# -----------------------------------\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7e5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_storm_transformer(initial_states_df, num_epochs=20, batch_size=2, lr=1e-3, device=None):\n",
    "    # from full_dataset import FullDataset\n",
    "    # from storm_transformer import STORMTransformer, masked_mse_loss\n",
    "    torch.manual_seed(42)\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # 🔀 Train/validation split\n",
    "    train_df, val_df = train_test_split(initial_states_df[0:100], test_size=0.05, random_state=42)\n",
    "\n",
    "    train_dataset = FullDatasetPT(train_df)\n",
    "    val_dataset = FullDatasetPT(val_df)\n",
    "\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=8, pin_memory=True, )\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "\n",
    "    model = STORMTransformer().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    checkpoint_path = \"checkpoints/storm_last.pt\"\n",
    "    best_model_path = \"checkpoints/storm_best.pt\"\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    # 🔁 Resume support\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"🔁 Resuming from checkpoint: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint.get('epoch', 0)\n",
    "        best_val_loss = checkpoint.get('val_loss', float(\"inf\"))\n",
    "\n",
    "    # 🚀 Training loop\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        print(f\"\\n🚀 Epoch {epoch + 1}/{num_epochs}\")\n",
    "        #start_load = time.time()\n",
    "        for batch in tqdm(train_loader):\n",
    "            static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = batch\n",
    "            #nd_load = time.time()\n",
    "\n",
    "            static_input = static_input.to(device)\n",
    "            density = density.to(device)\n",
    "            density_mask = density_mask.to(device)\n",
    "            goes = goes.to(device)\n",
    "            goes_mask = goes_mask.to(device)\n",
    "            omni2 = omni2.to(device)\n",
    "            omni2_mask = omni2_mask.to(device)\n",
    "\n",
    "            # if (omni2_mask.any(dim=-1).sum(dim=1) == 0).any() or (goes_mask.any(dim=-1).sum(dim=1) == 0).any():\n",
    "            #     print(\"⚠️ Skipping batch with fully masked inputs\")\n",
    "            #     continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "            #print (preds)\n",
    "            loss = masked_mse_loss(preds, density, density_mask)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            #end_batch = time.time()\n",
    "\n",
    "            # print (\"Load time:\", end_load - start_load )\n",
    "            # print (\"Calc time:\", end_batch - end_load)\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        print (\"Preds:\", preds)\n",
    "        print (\"Targets\",density)\n",
    "        # 🧪 Validation\n",
    "        \n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = batch\n",
    "\n",
    "                static_input = static_input.to(device)\n",
    "                density = density.to(device)\n",
    "                density_mask = density_mask.to(device)\n",
    "                goes = goes.to(device)\n",
    "                goes_mask = goes_mask.to(device)\n",
    "                omni2 = omni2.to(device)\n",
    "                omni2_mask = omni2_mask.to(device)\n",
    "\n",
    "                if (omni2_mask.any(dim=-1).sum(dim=1) == 0).any() or (goes_mask.any(dim=-1).sum(dim=1) == 0).any():\n",
    "                    continue\n",
    "\n",
    "                preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "                loss = masked_mse_loss(preds, density, density_mask)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # 🧠 Mask diagnostics\n",
    "                goes_mask_sum = goes_mask.sum().item()\n",
    "                omni2_mask_sum = omni2_mask.sum().item()\n",
    "                density_mask_sum = density_mask.sum().item()\n",
    "\n",
    "                print(f\"🧪 Eval Batch {batch_idx+1}/{len(val_loader)} — \"\n",
    "                      f\"OMNI2 Mask Sum: {omni2_mask_sum} | \"\n",
    "                      f\"GOES Mask Sum: {goes_mask_sum} | \"\n",
    "                      f\"Density Mask Sum: {density_mask_sum}\")\n",
    "\n",
    "                # ⚠️ Alert if any mask has < 10% coverage\n",
    "                if omni2_mask_sum < 0.1 * omni2_mask.numel():\n",
    "                    print(\"⚠️ Low OMNI2 coverage in this batch!\")\n",
    "                if goes_mask_sum < 0.1 * goes_mask.numel():\n",
    "                    print(\"⚠️ Low GOES coverage in this batch!\")\n",
    "                if density_mask_sum < 0.1 * density_mask.numel():\n",
    "                    print(\"⚠️ Low density mask coverage in this batch!\")\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"\\n📊 Epoch {epoch+1}/{num_epochs} — \"\n",
    "              f\"Train Loss: {avg_train_loss} | Val Loss: {avg_val_loss}\")\n",
    "        \n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "        \n",
    "        print (\"Preds:\", preds)\n",
    "        print (\"Targets\",density)\n",
    "\n",
    "        # 💾 Save full checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': avg_val_loss\n",
    "        }, checkpoint_path)\n",
    "\n",
    "        # 💎 Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), f\"checkpoints/epoch{epoch}.pt\")\n",
    "            print(\"✅ Best model updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f393f7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:17<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[ 4.5051e-04,  4.2748e-05, -8.1519e-04, -1.8458e-04,  1.9350e-03,\n",
      "         -1.9516e-03, -1.3435e-03,  6.2724e-04,  5.0115e-04, -3.5229e-04,\n",
      "         -8.5708e-04,  5.9400e-04,  5.5478e-04, -1.0511e-03, -4.1045e-04,\n",
      "          9.4252e-05,  1.4596e-03,  6.4479e-04,  9.2144e-04,  4.1785e-04,\n",
      "          6.4290e-04, -3.7951e-04, -8.3137e-04,  3.2952e-04,  8.2809e-05,\n",
      "         -4.2203e-04,  2.2619e-04, -5.6146e-04, -1.1807e-03,  5.8202e-04,\n",
      "          3.7260e-04,  1.1405e-03,  2.6640e-04, -5.4953e-05,  3.8037e-04,\n",
      "         -1.5548e-03, -8.8468e-05, -1.1471e-03, -1.7978e-03, -9.3518e-04,\n",
      "         -1.3375e-03,  2.9879e-04, -8.4687e-05,  5.0087e-05,  3.3275e-04,\n",
      "         -3.0634e-04,  7.0128e-04, -7.0680e-04,  3.9315e-04,  4.9062e-04,\n",
      "          1.9522e-04, -1.5027e-03,  1.0462e-03, -2.5434e-04, -7.1629e-04,\n",
      "         -7.4010e-05, -2.2833e-04,  8.1785e-04, -6.0689e-05,  1.0185e-03,\n",
      "         -4.7459e-04, -4.1417e-04,  1.0787e-03,  8.6594e-04, -6.0217e-04,\n",
      "         -1.1614e-03,  5.4628e-04,  6.3313e-04, -5.3483e-04,  9.2915e-04,\n",
      "         -6.7067e-04,  9.8724e-05,  5.1170e-04,  8.9446e-04, -3.6924e-04,\n",
      "         -1.3614e-04,  6.4784e-04,  6.2812e-04, -1.5526e-04,  4.9115e-04,\n",
      "         -1.5529e-03, -5.7128e-04, -5.7790e-04,  4.9169e-04,  7.8302e-04,\n",
      "         -1.0826e-03,  1.0383e-04,  4.3501e-04, -3.4569e-04,  5.0228e-04,\n",
      "          4.7024e-04, -1.0233e-03,  8.7194e-04,  4.2460e-04,  1.3565e-03,\n",
      "         -3.5497e-04,  2.9361e-04, -4.0047e-06, -6.5592e-04,  4.8573e-04,\n",
      "         -9.8662e-04,  3.3385e-04,  5.9705e-04,  1.0089e-03,  1.0287e-03,\n",
      "         -1.3283e-03,  2.1940e-03,  1.8312e-03,  1.1229e-03,  2.7481e-03,\n",
      "          2.3685e-03, -1.5219e-03, -1.2020e-03,  1.4848e-04,  2.7414e-03,\n",
      "         -2.2320e-03,  1.0119e-03,  4.9424e-04, -1.0027e-03,  2.3211e-03,\n",
      "          1.8315e-03, -9.4078e-04,  1.4305e-03,  1.2983e-03,  8.7120e-04,\n",
      "          7.4911e-04,  1.8323e-04,  2.6848e-03, -8.1354e-04, -2.1397e-03,\n",
      "         -4.9442e-04, -9.1343e-04, -2.5667e-04, -2.2738e-03,  2.6565e-03,\n",
      "         -7.2723e-04, -1.1669e-03,  9.2503e-04, -1.9952e-03, -2.9745e-04,\n",
      "          2.1479e-03, -2.4616e-04, -3.1653e-03,  3.7802e-03,  2.0272e-03,\n",
      "         -4.6744e-04,  2.0537e-04, -8.9774e-04,  3.2590e-03, -6.6100e-04,\n",
      "          3.0108e-05, -2.5570e-03,  5.0580e-04, -1.1409e-03, -6.8641e-04,\n",
      "          2.2414e-04,  2.2042e-03,  1.2222e-03, -7.1291e-04, -1.5639e-03,\n",
      "          3.5373e-04, -1.5802e-03,  6.5818e-04, -9.2932e-04, -1.5167e-03,\n",
      "          8.4048e-04, -9.8311e-04, -1.0660e-03, -1.0648e-03, -3.7372e-04,\n",
      "          6.5836e-04, -6.2586e-04,  7.0076e-04,  1.5973e-03,  3.4709e-05,\n",
      "          1.4808e-03,  1.5229e-05, -2.2038e-04, -1.8760e-03, -6.5950e-04,\n",
      "         -1.6236e-03, -1.9024e-03, -7.7354e-04, -6.4570e-04, -1.7897e-04,\n",
      "          3.2656e-03, -1.0129e-03,  3.3680e-03, -1.6558e-03,  1.7231e-03,\n",
      "          4.2688e-05,  3.7486e-04,  3.4474e-04, -2.1106e-03,  1.3549e-03,\n",
      "          1.5136e-03, -8.9908e-04,  4.0700e-04, -2.8657e-03, -2.9219e-04,\n",
      "          1.6145e-05,  1.1446e-03, -1.7234e-03, -1.8600e-03, -1.1277e-03,\n",
      "          1.8595e-04, -1.2461e-03, -3.3421e-03, -1.1827e-05,  1.5756e-04,\n",
      "          6.0871e-04,  1.1349e-04,  9.6127e-05, -8.6631e-04,  1.8658e-03,\n",
      "         -3.2945e-03,  6.8489e-04,  2.2848e-04,  3.2112e-03, -3.4771e-04,\n",
      "          6.8823e-04, -9.0286e-04, -4.2609e-04,  2.3822e-04,  1.4987e-04,\n",
      "         -3.5604e-04,  3.0500e-03, -2.5531e-04, -8.9562e-05, -2.6300e-04,\n",
      "         -5.2237e-04, -1.9016e-04, -1.0725e-04,  7.5603e-04,  5.2763e-04,\n",
      "          3.0461e-04,  3.3299e-04, -8.3456e-04,  4.0574e-03,  1.7213e-03,\n",
      "         -7.6160e-04, -3.7214e-04, -9.0635e-04,  4.0820e-04, -2.0144e-05,\n",
      "         -7.7468e-04, -2.0022e-04, -8.3904e-05,  7.6421e-04,  1.1110e-04,\n",
      "         -4.1258e-07, -3.6267e-04, -1.5808e-03,  3.5743e-04, -1.1624e-03,\n",
      "          1.6970e-04,  1.6049e-04, -3.6533e-04, -5.3486e-04,  3.0069e-05,\n",
      "          3.1872e-04, -1.6062e-04, -2.2471e-03, -2.2728e-03,  7.1938e-04,\n",
      "          2.0833e-03, -2.2351e-04, -3.8742e-04,  4.8595e-04, -4.9531e-05,\n",
      "         -8.4032e-04,  4.6760e-03,  6.3235e-04, -8.0395e-04,  1.6595e-03,\n",
      "         -8.2703e-04,  1.7401e-03,  5.6796e-04,  1.2249e-03,  4.9251e-04,\n",
      "          1.6595e-03,  8.5177e-04,  9.5253e-04,  9.3987e-04, -8.6517e-04,\n",
      "          1.0627e-03, -1.2322e-03, -8.7972e-04,  7.5323e-04,  1.9187e-03,\n",
      "          3.9896e-04, -9.4370e-04, -8.7173e-04, -4.5247e-04, -3.7009e-04,\n",
      "          1.8441e-03, -1.4082e-03, -4.6198e-04, -1.2794e-04,  3.2508e-04,\n",
      "         -8.4622e-04,  1.7562e-04, -5.2097e-04,  1.0661e-04,  1.8837e-04,\n",
      "         -1.1941e-03,  1.0772e-03, -2.8685e-05,  5.2363e-04, -8.5083e-04,\n",
      "          5.5775e-04,  2.6935e-04,  7.8365e-05,  6.7834e-04,  5.6987e-04,\n",
      "         -4.2046e-04,  5.3480e-04, -4.1733e-04,  2.7210e-04, -8.0306e-04,\n",
      "         -1.6959e-03,  1.1175e-03, -3.4015e-03, -1.3236e-03,  1.1838e-03,\n",
      "          2.6471e-03,  8.7032e-04,  8.1524e-04,  1.7605e-03,  1.5043e-03,\n",
      "          2.6638e-03,  6.7700e-04, -3.4646e-03,  7.9191e-05, -4.9882e-04,\n",
      "         -1.3810e-03,  8.1275e-04, -9.3829e-04,  6.9481e-04, -2.5534e-04,\n",
      "         -6.1330e-04,  8.7799e-04, -9.2303e-04, -6.0339e-04, -2.0272e-03,\n",
      "         -6.2056e-04, -4.3991e-04, -2.8123e-04,  5.4475e-04, -2.7141e-04,\n",
      "         -4.3124e-04,  7.9303e-04,  1.0124e-03,  1.3550e-03,  3.0845e-04,\n",
      "          1.2229e-03,  6.3126e-04,  7.6980e-04,  1.1748e-03, -1.4314e-04,\n",
      "          6.0209e-04, -3.9523e-04, -5.4487e-04, -1.0585e-04,  3.9030e-04,\n",
      "         -1.1529e-04, -3.0769e-03,  7.5496e-04,  2.1894e-04, -1.9902e-03,\n",
      "          1.2509e-03,  8.8762e-04, -1.1866e-04, -3.1605e-04, -8.4960e-04,\n",
      "          1.1159e-03,  2.0698e-03, -3.1516e-04,  1.2320e-04,  2.4478e-03,\n",
      "          6.1769e-04,  1.4222e-03,  7.5149e-04,  7.9298e-04, -6.1312e-04,\n",
      "          5.3350e-04, -4.6145e-04,  6.8881e-04,  1.2400e-03,  7.0683e-04,\n",
      "         -1.0404e-03,  9.1391e-04,  2.1077e-03, -1.4471e-03,  1.0602e-03,\n",
      "          9.6435e-05, -8.2748e-04,  2.2168e-03,  2.6462e-04, -6.9751e-04,\n",
      "          8.5715e-04,  3.6790e-04, -1.5809e-03,  1.0915e-03,  4.1706e-04,\n",
      "         -2.6136e-03, -2.1471e-03,  1.8068e-03,  1.0183e-03,  4.8217e-04,\n",
      "          9.2966e-04,  2.6635e-03,  3.9247e-04,  1.3347e-03,  8.6823e-04,\n",
      "          1.5566e-03,  1.3395e-03, -6.2917e-04, -4.8166e-04, -3.2200e-04,\n",
      "         -3.1875e-04, -2.1923e-03, -9.5186e-04, -2.9333e-04, -1.3364e-03,\n",
      "          1.1911e-03, -6.9611e-04,  1.0832e-03, -3.6209e-04, -1.6671e-03,\n",
      "         -1.9054e-04,  3.2326e-04]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[2.7085e-12, 2.7301e-12, 2.7506e-12, 2.7262e-12, 2.6999e-12, 2.7021e-12,\n",
      "         2.7115e-12, 2.7160e-12, 2.7087e-12, 2.6995e-12, 2.6940e-12, 2.6890e-12,\n",
      "         2.6944e-12, 2.7176e-12, 2.7476e-12, 2.7543e-12, 2.7537e-12, 2.7755e-12,\n",
      "         2.8067e-12, 2.8053e-12, 2.7847e-12, 2.7910e-12, 2.8541e-12, 2.9434e-12,\n",
      "         2.9301e-12, 2.9191e-12, 2.9473e-12, 2.9506e-12, 2.9720e-12, 2.9755e-12,\n",
      "         2.9971e-12, 3.0563e-12, 3.0440e-12, 3.0479e-12, 3.0665e-12, 3.0898e-12,\n",
      "         3.1188e-12, 3.1340e-12, 3.1555e-12, 3.1883e-12, 3.2060e-12, 3.1590e-12,\n",
      "         3.1468e-12, 3.1724e-12, 3.1771e-12, 3.1549e-12, 3.1232e-12, 3.1276e-12,\n",
      "         3.1526e-12, 3.1731e-12, 3.2490e-12, 3.3303e-12, 3.3373e-12, 3.3503e-12,\n",
      "         3.3388e-12, 3.3275e-12, 3.3397e-12, 3.3410e-12, 3.3489e-12, 3.3805e-12,\n",
      "         3.3852e-12, 3.3916e-12, 3.3810e-12, 3.3701e-12, 3.4091e-12, 3.4231e-12,\n",
      "         3.4276e-12, 3.4362e-12, 3.4693e-12, 3.4869e-12, 3.5331e-12, 3.5482e-12,\n",
      "         3.5657e-12, 3.5984e-12, 3.6379e-12, 3.6800e-12, 3.7203e-12, 3.7530e-12,\n",
      "         3.7567e-12, 3.7397e-12, 3.7438e-12, 3.7609e-12, 3.7116e-12, 3.6768e-12,\n",
      "         3.6747e-12, 3.7016e-12, 3.6802e-12, 3.6370e-12, 3.6417e-12, 3.6131e-12,\n",
      "         3.6372e-12, 3.6316e-12, 3.6428e-12, 3.6126e-12, 3.6122e-12, 3.6197e-12,\n",
      "         3.6034e-12, 3.5622e-12, 3.5846e-12, 3.5709e-12, 3.5710e-12, 3.5896e-12,\n",
      "         3.6189e-12, 3.6365e-12, 3.6165e-12, 3.6029e-12, 3.6454e-12, 3.6471e-12,\n",
      "         3.6274e-12, 3.6141e-12, 3.6155e-12, 3.6269e-12, 3.6198e-12, 3.6197e-12,\n",
      "         3.6000e-12, 3.5642e-12, 3.5708e-12, 3.5702e-12, 3.5892e-12, 3.5907e-12,\n",
      "         3.5757e-12, 3.5725e-12, 3.5561e-12, 3.5680e-12, 3.5521e-12, 3.5237e-12,\n",
      "         3.5018e-12, 3.5369e-12, 3.5618e-12, 3.5576e-12, 3.5284e-12, 3.5159e-12,\n",
      "         3.5089e-12, 3.4936e-12, 3.4906e-12, 3.4801e-12, 3.4774e-12, 3.4699e-12,\n",
      "         3.4797e-12, 3.4867e-12, 3.5072e-12, 3.5080e-12, 3.4938e-12, 3.5081e-12,\n",
      "         3.5289e-12, 3.5170e-12, 3.5005e-12, 3.4977e-12, 3.5007e-12, 3.5079e-12,\n",
      "         3.5069e-12, 3.4856e-12, 3.4930e-12, 3.4474e-12, 3.3797e-12, 3.3671e-12,\n",
      "         3.3571e-12, 3.3427e-12, 3.3217e-12, 3.3046e-12, 3.3151e-12, 3.3138e-12,\n",
      "         3.2861e-12, 3.2831e-12, 3.2651e-12, 3.2661e-12, 3.2572e-12, 3.2660e-12,\n",
      "         3.2619e-12, 3.2562e-12, 3.2595e-12, 3.2456e-12, 3.2656e-12, 3.2565e-12,\n",
      "         3.2381e-12, 3.2293e-12, 3.2435e-12, 3.2634e-12, 3.2596e-12, 3.2248e-12,\n",
      "         3.2254e-12, 3.2410e-12, 3.2615e-12, 3.2532e-12, 3.2219e-12, 3.2129e-12,\n",
      "         3.1836e-12, 3.1631e-12, 3.1519e-12, 3.1419e-12, 3.1332e-12, 3.1233e-12,\n",
      "         3.1180e-12, 3.1138e-12, 3.1164e-12, 3.1052e-12, 3.0883e-12, 3.0918e-12,\n",
      "         3.0989e-12, 3.0874e-12, 3.0872e-12, 3.0802e-12, 3.0645e-12, 3.0757e-12,\n",
      "         3.0678e-12, 3.0599e-12, 3.0566e-12, 3.0397e-12, 3.0630e-12, 3.0999e-12,\n",
      "         3.0778e-12, 3.0759e-12, 3.0707e-12, 3.0695e-12, 3.0648e-12, 3.0756e-12,\n",
      "         3.0654e-12, 3.0766e-12, 3.0492e-12, 3.0049e-12, 3.0138e-12, 3.0109e-12,\n",
      "         2.9926e-12, 3.0131e-12, 3.0090e-12, 3.0103e-12, 3.0205e-12, 3.0144e-12,\n",
      "         3.0166e-12, 3.0228e-12, 3.0244e-12, 3.0218e-12, 3.0229e-12, 3.0168e-12,\n",
      "         3.0103e-12, 2.9617e-12, 2.9312e-12, 2.9079e-12, 2.8830e-12, 2.8625e-12,\n",
      "         2.8472e-12, 2.8484e-12, 2.8552e-12, 2.8602e-12, 2.8628e-12, 2.8257e-12,\n",
      "         2.7929e-12, 2.7966e-12, 2.7691e-12, 2.7656e-12, 2.7744e-12, 2.7781e-12,\n",
      "         2.7761e-12, 2.7828e-12, 2.7846e-12, 2.7748e-12, 2.7610e-12, 2.7569e-12,\n",
      "         2.7505e-12, 2.7477e-12, 2.7432e-12, 2.7349e-12, 2.7175e-12, 2.7192e-12,\n",
      "         2.7151e-12, 2.7077e-12, 2.6928e-12, 2.7165e-12, 2.7422e-12, 2.7413e-12,\n",
      "         2.7351e-12, 2.7303e-12, 2.7371e-12, 2.7264e-12, 2.7177e-12, 2.7210e-12,\n",
      "         2.7221e-12, 2.7419e-12, 2.7486e-12, 2.7460e-12, 2.7395e-12, 2.7436e-12,\n",
      "         2.7277e-12, 2.7298e-12, 2.7258e-12, 2.7128e-12, 2.6803e-12, 2.6759e-12,\n",
      "         2.6796e-12, 2.6819e-12, 2.6838e-12, 2.6900e-12, 2.7007e-12, 2.7201e-12,\n",
      "         2.7688e-12, 2.7783e-12, 2.7808e-12, 2.7786e-12, 2.7774e-12, 2.7717e-12,\n",
      "         2.7761e-12, 2.7928e-12, 2.8080e-12, 2.7700e-12, 2.7762e-12, 2.7899e-12,\n",
      "         2.7958e-12, 2.7949e-12, 2.8012e-12, 2.8040e-12, 2.8071e-12, 2.8018e-12,\n",
      "         2.8003e-12, 2.7869e-12, 2.7618e-12, 2.7461e-12, 2.7411e-12, 2.7376e-12,\n",
      "         2.7264e-12, 2.7192e-12, 2.7041e-12, 2.7006e-12, 2.7089e-12, 2.7001e-12,\n",
      "         2.6897e-12, 2.6947e-12, 2.7030e-12, 2.6966e-12, 2.6858e-12, 2.6784e-12,\n",
      "         2.6935e-12, 2.7123e-12, 2.7191e-12, 2.7118e-12, 2.7155e-12, 2.7144e-12,\n",
      "         2.7217e-12, 2.7098e-12, 2.7105e-12, 2.7370e-12, 2.7442e-12, 2.7429e-12,\n",
      "         2.7426e-12, 2.7450e-12, 2.7506e-12, 2.7573e-12, 2.7600e-12, 2.7733e-12,\n",
      "         2.7762e-12, 2.7787e-12, 2.7652e-12, 2.7597e-12, 2.7457e-12, 2.7441e-12,\n",
      "         2.7298e-12, 2.7346e-12, 2.7318e-12, 2.7323e-12, 2.7297e-12, 2.7223e-12,\n",
      "         2.7217e-12, 2.7255e-12, 2.7264e-12, 2.7353e-12, 2.7432e-12, 2.7499e-12,\n",
      "         2.7658e-12, 2.7634e-12, 2.7522e-12, 2.7485e-12, 2.7396e-12, 2.7260e-12,\n",
      "         2.7171e-12, 2.7139e-12, 2.7055e-12, 2.6786e-12, 2.6700e-12, 2.6499e-12,\n",
      "         2.6522e-12, 2.6407e-12, 2.6356e-12, 2.6355e-12, 2.6352e-12, 2.6387e-12,\n",
      "         2.6345e-12, 2.6131e-12, 2.5980e-12, 2.5914e-12, 2.5795e-12, 2.5741e-12,\n",
      "         2.5787e-12, 2.5904e-12, 2.6036e-12, 2.6320e-12, 2.6286e-12, 2.6228e-12,\n",
      "         2.6882e-12, 2.7522e-12, 2.7325e-12, 2.7196e-12, 2.7284e-12, 2.7444e-12,\n",
      "         2.7570e-12, 2.7660e-12, 2.7887e-12, 2.8192e-12, 2.7725e-12, 2.8081e-12,\n",
      "         2.8261e-12, 2.8368e-12, 2.8743e-12, 2.9023e-12, 2.9372e-12, 2.9638e-12,\n",
      "         2.9862e-12, 2.9839e-12, 3.0220e-12, 3.0665e-12, 3.0812e-12, 3.0480e-12,\n",
      "         2.9878e-12, 3.0009e-12, 3.0285e-12, 3.0267e-12, 2.9551e-12, 2.8718e-12,\n",
      "         2.8484e-12, 2.8623e-12, 2.8416e-12, 2.8267e-12, 2.8183e-12, 2.8067e-12]],\n",
      "       device='cuda:0')\n",
      "🧪 Eval Batch 1/3 — OMNI2 Mask Sum: 164160.0 | GOES Mask Sum: 683824.0 | Density Mask Sum: 784.0\n",
      "⚠️ Low GOES coverage in this batch!\n",
      "🧪 Eval Batch 2/3 — OMNI2 Mask Sum: 164160.0 | GOES Mask Sum: 679068.0 | Density Mask Sum: 718.0\n",
      "⚠️ Low GOES coverage in this batch!\n",
      "🧪 Eval Batch 3/3 — OMNI2 Mask Sum: 82080.0 | GOES Mask Sum: 333536.0 | Density Mask Sum: 254.0\n",
      "⚠️ Low GOES coverage in this batch!\n",
      "\n",
      "📊 Epoch 1/20 — Train Loss: 0.01422093584308944 | Val Loss: 0.0011331827069322269\n",
      "Preds: tensor([[ 2.3374e-03,  2.7469e-03, -9.1417e-04, -2.5077e-04,  7.3042e-04,\n",
      "         -7.4201e-04, -1.6519e-03,  7.4023e-04,  1.9140e-03,  9.5232e-04,\n",
      "         -1.2957e-03, -2.4490e-04,  6.9986e-04, -8.1104e-04, -7.1548e-05,\n",
      "         -1.6705e-03,  9.9869e-04,  4.4130e-04,  1.5318e-03,  1.0764e-03,\n",
      "          1.3794e-03,  2.4223e-04, -1.2372e-03,  1.7276e-04,  4.3329e-04,\n",
      "         -1.6932e-03,  1.6345e-04, -1.2626e-03, -2.3299e-03, -6.9734e-04,\n",
      "          5.6073e-04,  1.5373e-03,  1.1157e-03, -1.1971e-04,  8.1051e-04,\n",
      "         -1.2009e-03,  6.5439e-04, -1.2300e-03, -4.0446e-04,  2.8100e-05,\n",
      "         -1.6374e-03,  1.5282e-03,  8.6916e-04, -4.8045e-04,  1.0187e-03,\n",
      "          4.3015e-04,  4.5020e-06, -1.6678e-03,  1.1949e-03,  4.0125e-04,\n",
      "          1.4774e-03, -1.5520e-03,  5.2117e-04, -6.3735e-04, -6.8960e-04,\n",
      "         -6.4751e-04,  1.5157e-04,  7.6546e-04, -1.0190e-04,  1.0855e-03,\n",
      "         -4.3827e-04, -6.7584e-04,  3.2695e-04, -6.4035e-04, -1.6060e-03,\n",
      "         -1.5600e-03,  9.6709e-04,  1.4508e-04,  7.1058e-04,  5.1208e-04,\n",
      "         -4.2093e-04,  6.9424e-04, -3.4358e-05,  9.2794e-04,  5.0253e-04,\n",
      "         -1.0265e-03,  9.2341e-04,  3.4508e-04,  1.2086e-04,  1.2552e-03,\n",
      "         -1.2787e-03, -9.2995e-04, -4.1431e-04,  9.9621e-05,  1.3891e-03,\n",
      "         -9.5338e-04,  4.4514e-04,  9.0278e-04,  8.2406e-05,  1.9742e-03,\n",
      "         -3.5806e-04, -6.6200e-04, -2.7381e-05,  6.3123e-04,  1.2882e-03,\n",
      "          5.5293e-04, -2.5312e-04,  2.9407e-04,  9.7523e-05,  4.9634e-04,\n",
      "         -1.3521e-03,  8.3603e-05, -3.5821e-04,  1.2247e-03,  4.1485e-05,\n",
      "         -6.8688e-04,  1.9636e-03,  2.4119e-03,  7.4487e-04,  3.1848e-03,\n",
      "          2.9702e-03, -1.1038e-03, -1.6637e-03,  2.5665e-04,  2.8950e-03,\n",
      "         -1.9142e-03,  1.3682e-03,  1.5881e-04, -7.0186e-04,  1.8787e-03,\n",
      "          2.1367e-03, -5.0343e-04,  9.6177e-04,  1.6110e-03,  1.9695e-04,\n",
      "          1.2161e-03,  3.6508e-04,  3.1821e-03, -5.0828e-04, -1.8156e-03,\n",
      "         -5.9633e-04, -2.6074e-03, -2.0990e-04, -2.0932e-03,  2.6128e-03,\n",
      "         -4.0511e-04, -1.1806e-03,  1.5957e-03, -1.8703e-03, -3.9014e-04,\n",
      "          2.4457e-03, -8.4978e-05, -2.7155e-03,  3.2722e-03,  2.1262e-03,\n",
      "         -4.0413e-04,  6.7096e-04, -8.7441e-04,  3.6428e-03, -2.6687e-04,\n",
      "         -2.8301e-04, -2.1690e-03, -3.4090e-04, -7.8997e-04, -5.8429e-04,\n",
      "         -2.2807e-04,  2.3369e-03,  9.9030e-04, -9.4562e-04, -1.0824e-03,\n",
      "          6.2272e-04, -5.6407e-04,  8.2903e-05, -2.1350e-04, -1.2780e-03,\n",
      "          8.2257e-04, -1.7132e-04, -9.0536e-04, -1.4224e-03,  8.7878e-04,\n",
      "          1.2952e-04, -8.7585e-04,  2.4154e-04,  9.2424e-04, -2.6087e-04,\n",
      "          1.2139e-03,  8.3751e-04, -7.4568e-04, -1.8834e-03,  9.3782e-05,\n",
      "         -9.0454e-04, -1.1292e-03, -3.4454e-04,  2.3154e-04, -1.0026e-04,\n",
      "          2.6527e-03,  9.8571e-06,  4.2983e-03, -1.1399e-03,  5.0753e-04,\n",
      "         -5.8287e-04,  7.4622e-04, -4.7227e-04, -1.8108e-04,  3.2903e-04,\n",
      "          7.2802e-04,  7.8641e-04, -1.2940e-03, -1.4573e-03, -1.1127e-03,\n",
      "          1.3206e-04,  5.6691e-04, -2.2636e-03,  6.5704e-05, -4.1482e-04,\n",
      "         -2.3869e-04, -6.1769e-04, -1.5168e-03, -3.6486e-04,  1.1853e-04,\n",
      "         -1.6746e-05, -5.5112e-04,  1.2450e-03, -4.7675e-04,  1.5219e-03,\n",
      "         -2.9945e-03, -6.2568e-04,  1.5899e-04,  2.1260e-03,  1.8139e-04,\n",
      "         -9.1745e-04, -7.3233e-04,  1.2468e-04, -4.6656e-05,  4.7760e-04,\n",
      "          6.2322e-04,  1.6220e-03, -1.0939e-03,  6.2119e-05, -7.8180e-04,\n",
      "          4.1183e-04,  9.0478e-04, -3.0571e-04,  1.6925e-04,  6.2359e-04,\n",
      "          1.0560e-04,  9.0201e-04,  2.1744e-04,  3.4098e-03,  3.8524e-04,\n",
      "          2.7616e-04, -1.5914e-03, -9.9280e-04, -4.6669e-04,  5.0306e-04,\n",
      "         -8.6177e-05, -1.2028e-03, -4.8107e-04,  2.0584e-04, -1.6999e-03,\n",
      "          2.3857e-04,  4.5148e-04, -5.2531e-04,  3.4805e-04, -4.3320e-04,\n",
      "          9.8642e-04,  8.0775e-05,  2.1902e-04, -4.3409e-04,  3.4405e-04,\n",
      "         -2.9538e-05,  3.9613e-04, -1.2417e-03, -1.6266e-03,  5.8241e-05,\n",
      "          1.6852e-03,  4.6617e-04, -3.1311e-04, -1.1605e-05,  5.2767e-04,\n",
      "         -7.8954e-04,  4.2143e-03, -1.2843e-04, -6.0829e-04,  9.3706e-04,\n",
      "         -9.6042e-04,  1.0973e-03,  5.0736e-04,  1.1443e-03, -3.1689e-04,\n",
      "          1.6935e-03,  3.1840e-05,  4.4253e-04,  6.1771e-05, -1.0071e-03,\n",
      "          4.3167e-04, -1.4844e-03,  1.1554e-04,  3.2174e-04,  1.5359e-03,\n",
      "          3.3303e-04, -8.3695e-04, -3.3119e-04, -2.7099e-04, -4.9566e-04,\n",
      "          9.8624e-04, -2.5400e-04, -1.3293e-03, -1.8967e-05,  8.8910e-04,\n",
      "         -1.5036e-03, -6.1095e-05, -3.6799e-04,  5.5608e-04,  4.9685e-04,\n",
      "         -5.1687e-04,  1.2634e-03,  3.2451e-04,  3.8571e-04, -8.1028e-05,\n",
      "          1.8812e-04, -6.5559e-04, -2.7002e-04,  8.3820e-04,  1.6460e-04,\n",
      "         -3.5180e-04,  7.4618e-06,  6.7048e-05, -3.9434e-04, -4.6244e-04,\n",
      "         -1.4266e-03,  5.5504e-04, -2.7716e-03, -1.7549e-03,  7.2489e-04,\n",
      "          2.6865e-03,  6.8153e-04,  1.5736e-03,  8.9429e-04,  6.1011e-04,\n",
      "          3.3524e-03,  5.9119e-04, -3.4218e-03, -6.8510e-05, -2.7147e-04,\n",
      "         -1.1004e-03,  1.1029e-03, -1.4511e-03,  7.6277e-04, -6.9294e-04,\n",
      "         -9.8287e-04,  2.8663e-04, -2.3082e-04, -1.5109e-03, -2.1041e-03,\n",
      "         -1.3674e-03,  3.1492e-04,  3.1529e-04,  3.9120e-04, -3.6096e-04,\n",
      "         -4.3225e-04,  4.3532e-04,  8.8755e-04,  1.3180e-03, -4.5621e-04,\n",
      "         -2.5341e-05,  3.7258e-05, -4.4325e-05, -1.4119e-04,  5.5701e-05,\n",
      "         -4.6782e-05, -1.2359e-04, -4.1398e-04, -1.3956e-04, -7.2632e-04,\n",
      "          2.8716e-04, -2.4816e-03, -4.7334e-04,  7.4841e-06, -7.4709e-04,\n",
      "          6.4743e-04,  3.4255e-04,  7.1178e-05,  2.9370e-04, -1.4500e-03,\n",
      "          1.4748e-03,  1.2702e-03, -1.2787e-04,  3.8411e-04,  1.3199e-03,\n",
      "          3.1155e-04,  1.8848e-03,  7.9764e-04,  1.6691e-03, -4.8013e-04,\n",
      "          1.7749e-04, -1.0148e-04,  4.3109e-04, -3.3910e-04,  5.9550e-04,\n",
      "         -3.5876e-04,  4.7625e-04,  2.3799e-03, -1.6597e-03,  2.9228e-04,\n",
      "          2.7140e-04, -1.1703e-03,  2.0113e-03,  9.6948e-04, -5.6491e-04,\n",
      "         -3.3069e-04,  8.4801e-05, -1.1587e-03,  1.2667e-03,  1.0373e-03,\n",
      "         -2.5625e-03, -2.2299e-03,  1.4934e-03,  1.2496e-03,  3.2427e-04,\n",
      "          1.3827e-03,  2.1575e-03,  4.7817e-04,  1.4426e-03,  6.5351e-04,\n",
      "          1.2428e-03,  1.8654e-03,  1.3776e-04, -6.4384e-04, -7.5597e-04,\n",
      "         -4.4670e-04, -2.4627e-03, -1.0029e-03, -1.5288e-04, -8.8634e-04,\n",
      "          7.1836e-04, -1.0181e-03,  3.9532e-04, -5.6262e-04, -1.3538e-03,\n",
      "         -3.2578e-04,  3.0920e-04]], device='cuda:0')\n",
      "Targets tensor([[2.7148e-12, 2.7233e-12, 2.7289e-12, 2.7087e-12, 2.7114e-12, 2.7205e-12,\n",
      "         2.7232e-12, 2.7230e-12, 2.7582e-12, 2.7302e-12, 2.7363e-12, 2.7476e-12,\n",
      "         2.7522e-12, 2.7243e-12, 2.7381e-12, 2.7521e-12, 2.7626e-12, 2.7216e-12,\n",
      "         2.6950e-12, 2.6917e-12, 2.6823e-12, 2.6827e-12, 2.6736e-12, 2.6690e-12,\n",
      "         2.6684e-12, 2.6975e-12, 2.7068e-12, 2.6855e-12, 2.7152e-12, 2.7047e-12,\n",
      "         2.7048e-12, 2.7180e-12, 2.7344e-12, 2.7506e-12, 2.7476e-12, 2.7309e-12,\n",
      "         2.7705e-12, 2.8143e-12, 2.8265e-12, 2.8291e-12, 2.8340e-12, 2.8104e-12,\n",
      "         2.8100e-12, 2.8360e-12, 2.8364e-12, 2.8380e-12, 2.8279e-12, 2.8103e-12,\n",
      "         2.8159e-12, 2.8057e-12, 2.8091e-12, 2.7990e-12, 2.7971e-12, 2.8002e-12,\n",
      "         2.7830e-12, 2.7680e-12, 2.7394e-12, 2.7465e-12, 2.7469e-12, 2.7542e-12,\n",
      "         2.7728e-12, 2.7516e-12, 2.7451e-12, 2.7441e-12, 2.7562e-12, 2.7782e-12,\n",
      "         2.7717e-12, 2.7698e-12, 2.7676e-12, 2.7969e-12, 2.7670e-12, 2.7421e-12,\n",
      "         2.7511e-12, 2.7713e-12, 2.7924e-12, 2.7953e-12, 2.7881e-12, 2.8010e-12,\n",
      "         2.7897e-12, 2.7860e-12, 2.7801e-12, 2.7817e-12, 2.7710e-12, 2.7285e-12,\n",
      "         2.6908e-12, 2.6978e-12, 2.7031e-12, 2.6827e-12, 2.6657e-12, 2.6559e-12,\n",
      "         2.6618e-12, 2.6343e-12, 2.6451e-12, 2.6589e-12, 2.6507e-12, 2.6459e-12,\n",
      "         2.6464e-12, 2.6547e-12, 2.6509e-12, 2.6163e-12, 2.6044e-12, 2.5844e-12,\n",
      "         2.5552e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.4223e-12, 2.4067e-12, 2.4343e-12, 2.4674e-12, 2.4672e-12,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4723e-12,\n",
      "         2.4679e-12, 2.4716e-12, 2.4694e-12, 2.4503e-12, 2.4312e-12, 2.4293e-12,\n",
      "         2.4102e-12, 2.4058e-12, 2.4001e-12, 2.3961e-12, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.3480e-12, 2.3683e-12, 2.3947e-12, 2.4130e-12, 2.4180e-12, 2.4109e-12,\n",
      "         2.4069e-12, 2.3628e-12, 2.3544e-12, 2.3593e-12, 2.3513e-12, 2.3225e-12,\n",
      "         2.3039e-12, 2.3010e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2264e-12, 2.2235e-12,\n",
      "         2.2265e-12, 2.2266e-12, 2.2201e-12, 2.2196e-12, 2.2227e-12, 2.2276e-12,\n",
      "         2.2029e-12, 2.1976e-12, 2.1928e-12, 2.2165e-12, 2.2343e-12, 2.2305e-12,\n",
      "         2.2265e-12, 2.2239e-12, 2.2443e-12, 2.2507e-12, 2.2438e-12, 2.2505e-12,\n",
      "         2.2805e-12, 2.2790e-12, 2.2798e-12, 2.2811e-12, 2.2847e-12, 2.2606e-12,\n",
      "         2.2538e-12, 2.2656e-12, 2.2675e-12, 2.2584e-12, 2.2374e-12, 2.2284e-12,\n",
      "         2.2254e-12, 2.2194e-12, 2.2078e-12, 2.1969e-12, 2.1955e-12, 2.1984e-12,\n",
      "         2.1924e-12, 2.1857e-12, 2.1890e-12, 2.1841e-12, 2.1793e-12, 2.1751e-12,\n",
      "         2.1883e-12, 2.1775e-12, 2.1924e-12, 2.1946e-12, 2.2013e-12, 2.1791e-12,\n",
      "         2.1857e-12, 2.1916e-12, 2.2010e-12, 2.1949e-12, 2.2195e-12, 2.2297e-12,\n",
      "         2.2359e-12, 2.2401e-12, 2.2362e-12, 2.2386e-12, 2.2455e-12, 2.2484e-12,\n",
      "         2.2484e-12, 2.2486e-12, 2.2761e-12, 2.3024e-12, 2.3055e-12, 2.3133e-12,\n",
      "         2.3300e-12, 2.3280e-12, 2.3277e-12, 2.3240e-12, 2.3316e-12, 2.3310e-12,\n",
      "         2.3299e-12, 2.3257e-12, 2.3370e-12, 2.3355e-12, 2.3182e-12, 2.3224e-12,\n",
      "         2.3228e-12, 2.3093e-12, 2.2955e-12, 2.2792e-12, 2.2942e-12, 2.3098e-12,\n",
      "         2.3227e-12, 2.3296e-12, 2.3331e-12, 2.3412e-12, 2.3504e-12, 2.3547e-12,\n",
      "         2.3412e-12, 2.3322e-12, 2.3336e-12, 2.3443e-12, 2.3494e-12, 2.3445e-12,\n",
      "         2.3369e-12, 2.3378e-12, 2.3513e-12, 2.3408e-12, 2.3342e-12, 2.3165e-12,\n",
      "         2.3054e-12, 2.3090e-12, 2.3057e-12, 2.3075e-12, 2.3057e-12, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.1587e-12, 2.1611e-12, 2.1705e-12, 2.1646e-12, 2.1554e-12, 2.1492e-12,\n",
      "         2.1511e-12, 2.1443e-12, 2.1294e-12, 2.1074e-12, 2.0947e-12, 2.0972e-12,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       device='cuda:0')\n",
      "✅ Best model updated.\n",
      "\n",
      "🚀 Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:11<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[ 3.4162e-04, -4.3797e-04,  2.2092e-04, -8.5333e-04, -3.7112e-04,\n",
      "          2.1292e-04,  8.8401e-05, -9.6011e-04,  8.9230e-04, -4.6972e-05,\n",
      "         -4.3465e-04,  1.6028e-04,  1.5003e-04, -1.9299e-04, -1.7041e-04,\n",
      "          1.4603e-06,  6.2020e-05, -2.9534e-04,  3.2356e-04,  4.4915e-04,\n",
      "          3.0412e-04, -6.8359e-06,  4.2234e-04, -2.5702e-04,  4.2464e-05,\n",
      "          6.1751e-05,  3.5126e-05, -2.0496e-04, -6.9020e-04,  7.1943e-05,\n",
      "         -7.6093e-05, -1.0907e-04,  6.0609e-04, -2.9913e-04, -1.7012e-05,\n",
      "          4.3314e-04, -1.2012e-04, -3.0136e-04,  1.4850e-04, -6.7721e-04,\n",
      "          4.7234e-05, -4.0124e-04,  8.5559e-05, -4.6335e-04, -3.8563e-04,\n",
      "         -3.0380e-04,  2.5057e-04, -5.3898e-05, -1.5236e-04,  8.1574e-04,\n",
      "          5.7117e-04,  2.5840e-04,  5.1477e-04,  4.6602e-05,  1.9152e-05,\n",
      "          6.3508e-04,  1.1346e-04,  2.2251e-04, -3.1764e-04,  3.6599e-05,\n",
      "          2.6591e-04,  4.6803e-04, -2.2759e-04,  9.3216e-05,  1.5692e-04,\n",
      "         -4.6473e-06, -1.5144e-05,  3.1672e-04, -4.9286e-06, -6.8625e-05,\n",
      "          2.4520e-04,  2.2265e-04,  1.8906e-04,  2.0298e-04,  2.2644e-04,\n",
      "         -2.3842e-04, -6.9154e-05, -2.0051e-04, -1.1827e-04,  1.5753e-04,\n",
      "          2.5147e-04, -1.7757e-04, -1.6619e-05, -9.7705e-05, -9.4512e-05,\n",
      "          1.3819e-04, -3.8752e-05,  1.6581e-04, -3.3923e-05,  2.4352e-05,\n",
      "         -1.9401e-04, -5.6855e-04, -9.9806e-05,  1.1965e-04, -1.9950e-04,\n",
      "         -4.0429e-04, -3.7578e-05,  2.7854e-05, -2.4946e-04, -1.3847e-04,\n",
      "          7.4469e-06, -1.3498e-04, -2.8499e-04,  1.2242e-03, -1.0379e-03,\n",
      "          1.5322e-04, -1.8802e-04, -1.0090e-03, -1.0831e-05, -3.2378e-04,\n",
      "         -8.1056e-04,  1.2297e-04,  4.2639e-04, -3.7900e-04,  5.0106e-04,\n",
      "         -1.0645e-03, -2.5605e-04,  2.4993e-05, -9.8766e-04, -4.1786e-04,\n",
      "         -2.0846e-04, -4.7429e-04, -1.0624e-03, -2.5814e-04, -1.4994e-03,\n",
      "         -9.1286e-05, -2.0955e-04,  2.4005e-04, -9.3820e-04,  9.6110e-04,\n",
      "         -8.9735e-05, -9.8375e-04, -3.0451e-04, -3.4056e-04, -7.4185e-04,\n",
      "          1.1158e-04, -1.3109e-05, -2.3157e-04,  2.6437e-04,  1.0403e-04,\n",
      "          4.1970e-04, -6.4880e-05, -1.0977e-04, -3.3771e-04, -4.6719e-04,\n",
      "          2.1778e-04, -1.5438e-04,  2.6499e-04, -7.2972e-04,  1.3053e-04,\n",
      "          7.8132e-05, -4.9248e-05,  1.6499e-04,  2.0906e-04,  6.7092e-06,\n",
      "         -1.4829e-05, -2.6783e-04, -2.2989e-05, -9.0510e-05, -3.0946e-04,\n",
      "         -3.0828e-05,  1.4984e-04,  1.8922e-04, -2.3572e-04,  3.3596e-05,\n",
      "         -3.3695e-05,  9.4692e-05,  2.5490e-04,  4.3551e-05,  2.0755e-04,\n",
      "         -2.0355e-04, -1.9130e-04,  3.3274e-05,  3.5842e-04,  1.8574e-04,\n",
      "         -6.8886e-04,  3.0288e-04, -2.1506e-04, -9.3684e-04,  7.1632e-05,\n",
      "         -7.0156e-04, -9.2100e-05, -5.2188e-05,  1.9194e-04, -4.3519e-05,\n",
      "          1.3255e-03,  3.7323e-04, -4.2620e-04, -6.2557e-04,  3.0751e-04,\n",
      "          2.3462e-04,  2.8780e-04,  9.0549e-04, -1.3480e-03,  4.6880e-04,\n",
      "         -1.3819e-04, -5.8866e-04, -1.1387e-04,  5.1089e-04, -6.8191e-06,\n",
      "         -1.2156e-04, -1.0175e-03, -1.3809e-04, -1.2431e-03, -2.3478e-04,\n",
      "          2.1631e-04,  3.0133e-04,  3.8632e-04,  2.0510e-04,  2.3742e-04,\n",
      "         -1.7689e-04, -6.8262e-04,  9.3445e-05, -5.6361e-04,  3.3673e-04,\n",
      "          2.5530e-04, -5.3495e-04,  2.3132e-05, -6.0392e-04,  2.7983e-04,\n",
      "         -3.9163e-04, -3.2568e-05,  2.4941e-04,  3.3801e-04,  6.6418e-04,\n",
      "         -6.2322e-04, -7.6444e-04,  2.2723e-04,  6.8950e-05,  3.8955e-04,\n",
      "         -1.8794e-04, -1.6616e-04, -9.6314e-05, -4.0021e-04,  5.3805e-04,\n",
      "          2.1513e-04, -2.0076e-05,  3.1276e-04, -3.2520e-04, -4.0071e-04,\n",
      "         -1.4032e-04, -9.5470e-05, -2.1082e-04, -4.1896e-05, -1.2469e-04,\n",
      "         -1.2023e-04,  9.2626e-05,  3.8101e-05,  8.1493e-05, -4.1946e-04,\n",
      "          4.7750e-05,  2.0891e-04, -1.7267e-04, -3.6787e-05,  1.5047e-04,\n",
      "         -6.5516e-04,  1.6436e-04, -8.4624e-05, -4.8848e-06,  3.0338e-04,\n",
      "         -6.3365e-04,  6.4984e-04, -6.8470e-04, -1.0328e-03, -1.4553e-04,\n",
      "          7.7885e-04,  3.3258e-04, -5.8726e-04,  3.4328e-04, -1.4300e-03,\n",
      "          2.4649e-04, -2.2616e-05,  2.2435e-04,  4.6415e-04,  1.4819e-03,\n",
      "         -3.1636e-04,  1.1699e-03,  6.5370e-05, -4.8395e-05,  7.8211e-04,\n",
      "          2.3716e-04,  5.8577e-04, -1.2223e-03, -3.4755e-04,  3.1414e-06,\n",
      "          4.7270e-04, -4.5231e-04, -6.6991e-04,  5.5251e-04,  5.4442e-04,\n",
      "         -1.1126e-03,  3.1447e-05,  2.4521e-04,  1.0519e-03,  8.6389e-06,\n",
      "          8.7742e-05, -3.0456e-04,  1.4736e-04, -1.4703e-04, -1.7442e-04,\n",
      "          1.0651e-05, -1.9167e-05,  1.8606e-05,  4.2590e-04,  5.8059e-05,\n",
      "         -1.1267e-04,  5.6860e-04,  4.4195e-05,  2.2027e-04,  3.5557e-04,\n",
      "          4.5472e-04, -6.5682e-04,  3.5040e-04,  4.9522e-04,  3.7402e-05,\n",
      "          1.3115e-04, -8.8360e-05,  4.1408e-04, -7.8751e-05, -1.7245e-04,\n",
      "         -5.3961e-05, -1.4981e-03,  1.2388e-03, -5.9882e-04, -3.7882e-04,\n",
      "         -6.8691e-04,  2.5066e-04, -3.6760e-04, -9.5863e-04,  1.3153e-03,\n",
      "         -2.1410e-04,  6.3563e-04,  7.9574e-04, -4.6967e-05, -1.4219e-04,\n",
      "          6.9793e-06, -2.3497e-04,  7.2394e-04,  2.5065e-04, -7.7454e-05,\n",
      "         -1.3826e-04,  8.8415e-05,  3.4788e-04, -8.2543e-05, -3.9651e-04,\n",
      "         -3.8501e-06,  2.5948e-04, -3.0946e-05, -1.2447e-04,  1.2448e-04,\n",
      "         -9.3881e-05,  1.3844e-04,  2.4427e-04, -6.1218e-05, -3.9517e-04,\n",
      "          1.6222e-04, -1.9597e-05,  2.2143e-05,  1.3603e-04, -5.0352e-05,\n",
      "          9.8132e-05,  4.7496e-05, -6.4945e-05,  7.7162e-05,  2.0584e-04,\n",
      "          3.5580e-05, -3.3545e-04, -2.6608e-04, -1.1031e-04, -5.3723e-04,\n",
      "          1.2900e-04, -9.4853e-05,  4.7507e-05,  3.3533e-04, -7.6629e-05,\n",
      "         -2.0180e-04, -2.6435e-04,  3.3545e-05,  8.1064e-05, -5.4635e-04,\n",
      "         -5.1289e-04,  2.4390e-04, -3.9840e-04,  1.8011e-04,  1.2519e-04,\n",
      "         -1.6403e-04, -4.4804e-05,  1.9952e-04, -2.6114e-06,  4.0768e-04,\n",
      "         -1.6979e-04, -1.2013e-04,  2.7027e-04, -1.3537e-04, -3.3841e-04,\n",
      "         -1.9710e-05,  2.4236e-04, -5.2183e-04, -1.8638e-04,  2.7572e-05,\n",
      "          8.2987e-04,  5.0891e-04,  4.2416e-05, -1.3079e-04,  9.4492e-05,\n",
      "          5.5935e-04,  2.5570e-04,  3.2324e-04, -2.5366e-04,  7.2621e-05,\n",
      "          6.2328e-04,  3.6745e-04,  8.4491e-05, -2.3169e-05,  1.1570e-05,\n",
      "         -1.5259e-03, -1.7936e-04,  3.3960e-05,  5.6439e-04, -3.0246e-05,\n",
      "         -5.6760e-05,  1.1677e-03,  9.7303e-04,  9.7739e-05,  8.8604e-04,\n",
      "         -2.3505e-04,  7.5437e-05, -1.7586e-04, -8.8579e-05,  2.9052e-04,\n",
      "         -1.7888e-04,  4.2243e-05]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4009e-12, 1.3962e-12, 1.3933e-12,\n",
      "         1.3915e-12, 1.3903e-12, 1.3912e-12, 1.3902e-12, 1.3859e-12, 1.3874e-12,\n",
      "         1.3909e-12, 1.3857e-12, 1.3850e-12, 1.3902e-12, 1.3917e-12, 1.3937e-12,\n",
      "         1.3979e-12, 1.4026e-12, 1.4044e-12, 1.4092e-12, 1.4207e-12, 1.4272e-12,\n",
      "         1.4252e-12, 1.4181e-12, 1.4105e-12, 1.4107e-12, 1.4161e-12, 1.4183e-12,\n",
      "         1.4060e-12, 1.3920e-12, 1.3928e-12, 1.3898e-12, 1.3795e-12, 1.3703e-12,\n",
      "         1.3649e-12, 1.3653e-12, 1.3680e-12, 1.3644e-12, 1.3615e-12, 1.3619e-12,\n",
      "         1.3649e-12, 1.3709e-12, 1.3761e-12, 1.3867e-12, 1.3943e-12, 1.3851e-12,\n",
      "         1.3786e-12, 1.3891e-12, 1.4012e-12, 1.4061e-12, 1.4065e-12, 1.4165e-12,\n",
      "         1.4337e-12, 1.4504e-12, 1.4533e-12, 1.4497e-12, 1.4872e-12, 1.5482e-12,\n",
      "         1.5728e-12, 1.5767e-12, 1.5791e-12, 1.5860e-12, 1.5821e-12, 1.5808e-12,\n",
      "         1.6016e-12, 1.6052e-12, 1.5678e-12, 1.5428e-12, 1.5479e-12, 1.5582e-12,\n",
      "         1.5563e-12, 1.5450e-12, 1.5352e-12, 1.5427e-12, 1.5550e-12, 1.5749e-12,\n",
      "         1.5922e-12, 1.6005e-12, 1.6187e-12, 1.6249e-12, 1.6229e-12, 1.6194e-12,\n",
      "         1.6130e-12, 1.6024e-12, 1.6022e-12, 1.6048e-12, 1.6131e-12, 1.6256e-12,\n",
      "         1.6309e-12, 1.6431e-12, 1.6556e-12, 1.6630e-12, 1.6590e-12, 1.6598e-12,\n",
      "         1.6641e-12, 1.6636e-12, 1.6582e-12, 1.6527e-12, 1.6499e-12, 1.6477e-12,\n",
      "         1.6508e-12, 1.6629e-12, 1.6755e-12, 1.6959e-12, 1.7250e-12, 1.7326e-12,\n",
      "         1.7294e-12, 1.7328e-12, 1.7341e-12, 1.7343e-12, 1.7361e-12, 1.7425e-12,\n",
      "         1.7647e-12, 1.7807e-12, 1.7720e-12, 1.7785e-12, 1.7951e-12, 1.8016e-12,\n",
      "         1.7986e-12, 1.7957e-12, 1.7891e-12, 1.7876e-12, 1.7655e-12, 1.7299e-12,\n",
      "         1.7314e-12, 1.7437e-12, 1.7437e-12, 1.7387e-12, 1.7356e-12, 1.7349e-12,\n",
      "         1.7307e-12, 1.7324e-12, 1.7454e-12, 1.7465e-12, 1.7408e-12, 1.7347e-12,\n",
      "         1.7349e-12, 1.7323e-12, 1.7303e-12, 1.7277e-12, 1.7241e-12, 1.7439e-12,\n",
      "         1.7712e-12, 1.7735e-12, 1.7710e-12, 1.7856e-12, 1.8036e-12, 1.8043e-12,\n",
      "         1.7974e-12, 1.8004e-12, 1.8047e-12, 1.8048e-12, 1.8121e-12, 1.8195e-12,\n",
      "         1.8114e-12, 1.8077e-12, 1.8204e-12, 1.8281e-12, 1.8365e-12, 1.8360e-12,\n",
      "         1.8247e-12, 1.8282e-12, 1.8359e-12, 1.8386e-12, 1.8382e-12, 1.8390e-12,\n",
      "         1.8440e-12, 1.8523e-12, 1.8295e-12, 1.8009e-12, 1.8074e-12, 1.8031e-12,\n",
      "         1.7919e-12, 1.7904e-12, 1.8027e-12, 1.8078e-12, 1.8139e-12, 1.8383e-12,\n",
      "         1.8680e-12, 1.8840e-12, 1.8801e-12, 1.8696e-12, 1.8738e-12, 1.8853e-12,\n",
      "         1.8884e-12, 1.8822e-12, 1.8800e-12, 1.8611e-12, 1.8331e-12, 1.8293e-12,\n",
      "         1.8306e-12, 1.8380e-12, 1.8359e-12, 1.8367e-12, 1.8429e-12, 1.8388e-12,\n",
      "         1.8354e-12, 1.8431e-12, 1.8493e-12, 1.8493e-12, 1.8578e-12, 1.8743e-12,\n",
      "         1.9138e-12, 1.9448e-12, 1.9575e-12, 1.9883e-12, 2.0619e-12, 2.1453e-12,\n",
      "         2.1848e-12, 2.1992e-12, 2.2009e-12, 2.1765e-12, 2.1499e-12, 2.1804e-12,\n",
      "         2.2149e-12, 2.1731e-12, 2.0759e-12, 2.0304e-12, 2.0615e-12, 2.0851e-12,\n",
      "         2.0744e-12, 2.0500e-12, 2.0260e-12, 2.0186e-12, 2.0246e-12, 2.0603e-12,\n",
      "         2.0704e-12, 2.0577e-12, 2.0652e-12, 2.0656e-12, 2.0777e-12, 2.0917e-12,\n",
      "         2.0719e-12, 2.0617e-12, 2.0907e-12, 2.1366e-12, 2.1519e-12, 2.1316e-12,\n",
      "         2.1355e-12, 2.1733e-12, 2.1991e-12, 2.1989e-12, 2.1913e-12, 2.1703e-12,\n",
      "         2.1609e-12, 2.1486e-12, 2.1401e-12, 2.1362e-12, 2.1072e-12, 2.0570e-12,\n",
      "         2.0375e-12, 2.0422e-12, 2.0422e-12, 2.0301e-12, 2.0017e-12, 1.9862e-12,\n",
      "         1.9840e-12, 1.9737e-12, 1.9662e-12, 1.9558e-12, 1.9480e-12, 1.9402e-12,\n",
      "         1.9000e-12, 1.8564e-12, 1.8487e-12, 1.8491e-12, 1.8511e-12, 1.8483e-12,\n",
      "         1.8449e-12, 1.8418e-12, 1.8289e-12, 1.8184e-12, 1.8112e-12, 1.8043e-12,\n",
      "         1.7995e-12, 1.7956e-12, 1.8003e-12, 1.8055e-12, 1.7985e-12, 1.7918e-12,\n",
      "         1.7977e-12, 1.8236e-12, 1.8440e-12, 1.8431e-12, 1.8354e-12, 1.8278e-12,\n",
      "         1.8226e-12, 1.8174e-12, 1.8098e-12, 1.8115e-12, 1.8133e-12, 1.8089e-12,\n",
      "         1.8079e-12, 1.8069e-12, 1.8179e-12, 1.8394e-12, 1.8533e-12, 1.8458e-12,\n",
      "         1.8358e-12, 1.8540e-12, 1.8747e-12, 1.8730e-12, 1.8717e-12, 1.8647e-12,\n",
      "         1.8463e-12, 1.8355e-12, 1.8402e-12, 1.8455e-12, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.8170e-12, 1.8237e-12, 1.8339e-12, 1.8281e-12, 1.8267e-12,\n",
      "         1.8239e-12, 1.8371e-12, 1.8557e-12, 1.8644e-12, 1.8794e-12, 1.9071e-12,\n",
      "         1.9413e-12, 1.9419e-12, 1.9461e-12, 1.9822e-12, 2.0111e-12, 2.0148e-12,\n",
      "         2.0176e-12, 2.0288e-12, 2.0357e-12, 2.0653e-12, 2.1018e-12, 2.1516e-12,\n",
      "         2.2832e-12, 2.4441e-12, 2.5459e-12, 2.5625e-12, 2.5919e-12, 2.7091e-12,\n",
      "         2.7761e-12, 2.8111e-12, 2.9650e-12, 2.9970e-12, 2.8747e-12, 2.8115e-12,\n",
      "         2.8403e-12, 2.9013e-12, 2.8679e-12, 2.8583e-12, 2.9634e-12, 3.0069e-12,\n",
      "         3.0524e-12, 3.1450e-12, 3.1981e-12, 3.2530e-12, 3.3429e-12, 3.4194e-12,\n",
      "         3.4084e-12, 3.3081e-12, 3.2238e-12, 3.1834e-12, 3.1707e-12, 3.1518e-12,\n",
      "         3.1823e-12, 3.1909e-12, 3.1805e-12, 3.1974e-12, 3.2240e-12, 3.2327e-12]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Eval Batch 1/3 — OMNI2 Mask Sum: 164160.0 | GOES Mask Sum: 683824.0 | Density Mask Sum: 784.0\n",
      "⚠️ Low GOES coverage in this batch!\n",
      "🧪 Eval Batch 2/3 — OMNI2 Mask Sum: 164160.0 | GOES Mask Sum: 679068.0 | Density Mask Sum: 718.0\n",
      "⚠️ Low GOES coverage in this batch!\n",
      "🧪 Eval Batch 3/3 — OMNI2 Mask Sum: 82080.0 | GOES Mask Sum: 333536.0 | Density Mask Sum: 254.0\n",
      "⚠️ Low GOES coverage in this batch!\n",
      "\n",
      "📊 Epoch 2/20 — Train Loss: 0.0005848915637519289 | Val Loss: 0.0003590346605051309\n",
      "Preds: tensor([[ 4.3470e-04, -6.3501e-04,  3.4735e-04, -7.6108e-05, -5.4824e-04,\n",
      "          4.1937e-04, -1.2435e-04, -3.8436e-04,  1.0954e-03, -2.6990e-04,\n",
      "          1.2399e-04,  6.2231e-05,  1.7390e-04, -4.1629e-04, -2.8375e-04,\n",
      "          8.6901e-05, -1.7512e-04, -8.8902e-04,  6.9370e-04,  4.2580e-04,\n",
      "          4.2803e-04,  2.9121e-05,  8.6379e-04, -7.0258e-04, -3.5615e-04,\n",
      "          1.4111e-04,  1.1342e-04, -6.1767e-04, -9.6753e-04,  1.2809e-04,\n",
      "         -1.5374e-04, -2.5682e-04,  6.2377e-04, -7.5516e-04, -5.3991e-05,\n",
      "          8.1922e-04, -1.2978e-05, -5.7453e-04,  2.9135e-04, -1.0596e-03,\n",
      "         -1.5090e-04, -6.6447e-04,  1.7590e-04, -5.2863e-04, -7.7635e-04,\n",
      "         -3.4213e-04,  3.0292e-04,  1.0388e-04, -3.5418e-04,  1.1571e-03,\n",
      "          8.6508e-04,  3.0253e-04,  5.0149e-04, -1.3128e-05,  6.6217e-05,\n",
      "          3.9230e-04,  3.6169e-04,  2.0223e-04, -3.5426e-04,  8.5486e-05,\n",
      "          2.9740e-04,  1.4733e-04,  6.0023e-04,  3.2762e-05,  6.2853e-05,\n",
      "          3.0692e-04,  3.5033e-04, -1.7043e-04, -6.4995e-05, -1.4051e-04,\n",
      "         -2.4883e-04,  2.1924e-04,  1.9802e-05, -7.3521e-05, -8.9085e-05,\n",
      "          1.2586e-05,  1.1387e-04,  1.8712e-04, -9.8865e-05, -1.5806e-05,\n",
      "         -2.2424e-04,  1.5477e-04,  1.7895e-04,  8.6237e-05,  2.0708e-04,\n",
      "         -4.2047e-04,  1.0894e-04, -1.2570e-04, -7.6771e-05, -1.9717e-04,\n",
      "         -2.3920e-04, -4.2396e-04, -6.0732e-05, -1.9199e-04, -3.8946e-05,\n",
      "         -2.0936e-04, -1.0518e-04,  1.6022e-04,  1.1042e-04, -1.3857e-04,\n",
      "          1.0723e-04,  8.0856e-05, -1.7978e-04,  6.1477e-04, -9.9185e-04,\n",
      "          3.4643e-05, -2.6119e-05, -9.3645e-04,  9.4268e-05, -4.5637e-04,\n",
      "         -6.8434e-04, -6.2408e-05,  2.9004e-04,  2.0619e-04,  5.3687e-04,\n",
      "         -3.5007e-04, -8.6419e-05,  4.9604e-05, -2.3716e-04, -9.0811e-05,\n",
      "         -3.6066e-04, -1.7175e-05, -3.5686e-04,  9.5167e-06, -5.7914e-04,\n",
      "          4.0207e-05, -8.5077e-05,  1.5310e-04, -3.8683e-04,  7.8475e-04,\n",
      "          6.0157e-05, -7.0490e-04, -3.0175e-06, -1.2507e-04, -3.6347e-04,\n",
      "         -4.8860e-05, -4.7697e-05, -1.3791e-04,  2.2702e-04, -4.4560e-05,\n",
      "          5.3843e-05,  4.2226e-05,  3.8745e-05, -2.1151e-04, -1.4755e-04,\n",
      "          2.1998e-04, -4.8263e-05,  1.3942e-04, -6.3544e-04,  9.8720e-06,\n",
      "          4.7334e-05,  8.8448e-05,  2.8066e-05,  1.3015e-04,  2.6014e-04,\n",
      "          1.0971e-04, -1.8177e-04, -1.5300e-05,  2.3941e-05,  1.0790e-04,\n",
      "          1.1210e-04, -8.4400e-05,  1.7442e-05, -1.2402e-04,  1.7002e-05,\n",
      "         -1.2446e-05, -3.7011e-04,  1.7361e-04,  1.5890e-05, -2.6224e-05,\n",
      "         -1.7895e-04,  2.0290e-05,  6.0324e-05,  1.2398e-05, -4.4836e-05,\n",
      "         -2.1265e-04,  1.3382e-04,  1.9651e-06, -4.6268e-04,  2.6803e-06,\n",
      "         -5.8872e-04, -5.3195e-05,  2.8918e-07,  5.7349e-05,  1.7893e-04,\n",
      "          1.8385e-03, -5.9455e-05, -3.9802e-04, -2.8814e-04,  1.3119e-04,\n",
      "         -1.0531e-04, -1.6545e-04,  6.4835e-04, -1.2508e-03,  9.7608e-05,\n",
      "          2.0167e-05, -4.6145e-04, -1.4360e-04,  4.3256e-04,  1.4744e-04,\n",
      "          5.9735e-05, -8.0743e-04, -1.1875e-04, -1.2093e-03, -1.1988e-04,\n",
      "          8.9202e-06,  2.1367e-04,  5.1483e-04,  2.1849e-05, -2.6584e-04,\n",
      "          7.5427e-05, -5.2240e-04,  1.7802e-04, -1.4763e-05,  1.3713e-04,\n",
      "          3.9518e-04, -2.3135e-04,  3.0925e-04, -7.4970e-04,  1.1785e-04,\n",
      "         -2.3992e-04,  2.4995e-05,  3.0130e-05,  2.2188e-04, -7.0405e-05,\n",
      "         -1.2395e-04, -8.6331e-04,  1.0333e-04,  2.4147e-05,  4.4017e-04,\n",
      "          9.9415e-05, -8.7131e-05,  1.7308e-05, -5.7783e-05, -1.4672e-04,\n",
      "         -3.1413e-04,  6.5707e-05,  1.8573e-04, -2.0656e-04, -1.3876e-04,\n",
      "         -1.0380e-04, -2.4476e-04, -3.9250e-04,  3.4090e-04, -1.2717e-04,\n",
      "          1.7284e-04,  1.9812e-04,  8.1188e-05, -4.9192e-05,  9.4239e-05,\n",
      "         -1.7147e-05,  1.6636e-04,  1.7407e-04, -8.8479e-05, -1.4904e-04,\n",
      "         -1.6743e-04,  4.7248e-05,  1.1225e-04, -5.1556e-05,  4.7676e-05,\n",
      "          3.6283e-04,  7.4285e-05, -5.9481e-04, -9.2756e-04, -3.7590e-05,\n",
      "          3.2057e-04, -9.6150e-06,  2.2869e-04,  4.4927e-06, -9.4181e-04,\n",
      "          3.8516e-05,  1.9832e-04, -1.7059e-04,  3.3606e-05,  1.1394e-03,\n",
      "         -8.2796e-05,  1.1751e-03, -2.4558e-05, -1.6149e-06,  4.0200e-04,\n",
      "          2.7235e-04,  1.5225e-04, -5.9027e-04, -1.8245e-05,  5.9066e-05,\n",
      "          1.7901e-04, -1.1844e-04, -3.0659e-04,  1.5980e-04,  3.0501e-04,\n",
      "         -8.6443e-04,  3.1147e-05,  3.2887e-05,  3.8395e-04, -8.8933e-05,\n",
      "          3.1509e-04, -9.7481e-05,  1.4391e-05, -4.6049e-04, -1.8993e-04,\n",
      "          3.2013e-05,  8.9766e-05,  1.0754e-04,  1.3011e-04,  1.6370e-04,\n",
      "         -1.4367e-04, -1.1702e-04, -1.3683e-04, -6.3032e-04, -6.9127e-05,\n",
      "          2.4956e-04, -1.0855e-04, -9.7930e-05,  2.2709e-05,  5.1614e-06,\n",
      "         -1.1103e-04, -1.2920e-04,  6.5896e-05,  8.2966e-05,  7.2539e-05,\n",
      "         -8.7326e-05, -7.3663e-04,  3.5303e-04,  9.9181e-05,  2.5988e-04,\n",
      "         -2.6851e-04, -3.2034e-04, -2.9140e-04, -5.7428e-04,  9.5285e-04,\n",
      "         -4.3226e-04, -4.4693e-04,  3.9427e-04, -7.0481e-05,  3.5566e-04,\n",
      "          3.1904e-04,  8.3872e-05,  3.3406e-04, -8.0328e-05,  2.2255e-04,\n",
      "          5.4653e-05, -2.5287e-05,  8.4843e-05,  2.1396e-04, -1.2032e-04,\n",
      "          6.5105e-05,  1.5666e-04, -6.5364e-05,  6.8466e-04, -5.1270e-04,\n",
      "          2.7216e-04, -1.3816e-04,  9.3924e-07,  1.5946e-04, -7.1405e-06,\n",
      "         -1.4620e-05, -1.0521e-04,  4.4280e-04, -9.2924e-05,  1.1808e-04,\n",
      "         -1.3201e-04, -1.5712e-04,  1.0585e-05,  3.6551e-04, -1.0451e-04,\n",
      "         -5.8675e-04, -3.8329e-04, -1.6760e-04,  1.3987e-04, -4.9932e-04,\n",
      "          1.4245e-04, -3.6137e-05, -6.8035e-05, -1.3283e-04,  5.2026e-05,\n",
      "          1.7508e-04,  1.3303e-05,  3.5450e-04,  3.7729e-04, -2.6621e-04,\n",
      "          6.1214e-05, -3.6086e-04,  1.2442e-04, -2.8044e-04,  3.8210e-05,\n",
      "         -8.5942e-06, -6.8967e-05,  2.6999e-04,  4.7272e-05, -4.5639e-04,\n",
      "          1.9181e-04,  7.8373e-05,  9.1694e-05,  2.2297e-04,  4.8754e-05,\n",
      "         -5.3875e-04, -7.7303e-05, -5.9022e-05,  4.1067e-04, -1.2818e-04,\n",
      "         -1.4043e-04, -2.5520e-04, -4.6317e-04,  8.0366e-05,  6.2555e-05,\n",
      "          2.7893e-04,  5.1815e-05, -4.8559e-04,  3.0863e-04, -3.9885e-04,\n",
      "          3.7767e-05,  3.2192e-05,  8.8857e-05, -1.1267e-04,  1.1702e-04,\n",
      "         -8.0001e-06,  2.2560e-05,  3.7478e-04, -7.4309e-04,  3.1091e-04,\n",
      "          5.0783e-04,  1.1956e-03,  2.0272e-04, -4.6745e-05, -7.5957e-05,\n",
      "          9.7953e-05,  5.0304e-05,  2.2988e-04,  1.3948e-04, -3.9674e-05,\n",
      "         -4.1827e-04,  1.0605e-04]], device='cuda:0')\n",
      "Targets tensor([[2.7148e-12, 2.7233e-12, 2.7289e-12, 2.7087e-12, 2.7114e-12, 2.7205e-12,\n",
      "         2.7232e-12, 2.7230e-12, 2.7582e-12, 2.7302e-12, 2.7363e-12, 2.7476e-12,\n",
      "         2.7522e-12, 2.7243e-12, 2.7381e-12, 2.7521e-12, 2.7626e-12, 2.7216e-12,\n",
      "         2.6950e-12, 2.6917e-12, 2.6823e-12, 2.6827e-12, 2.6736e-12, 2.6690e-12,\n",
      "         2.6684e-12, 2.6975e-12, 2.7068e-12, 2.6855e-12, 2.7152e-12, 2.7047e-12,\n",
      "         2.7048e-12, 2.7180e-12, 2.7344e-12, 2.7506e-12, 2.7476e-12, 2.7309e-12,\n",
      "         2.7705e-12, 2.8143e-12, 2.8265e-12, 2.8291e-12, 2.8340e-12, 2.8104e-12,\n",
      "         2.8100e-12, 2.8360e-12, 2.8364e-12, 2.8380e-12, 2.8279e-12, 2.8103e-12,\n",
      "         2.8159e-12, 2.8057e-12, 2.8091e-12, 2.7990e-12, 2.7971e-12, 2.8002e-12,\n",
      "         2.7830e-12, 2.7680e-12, 2.7394e-12, 2.7465e-12, 2.7469e-12, 2.7542e-12,\n",
      "         2.7728e-12, 2.7516e-12, 2.7451e-12, 2.7441e-12, 2.7562e-12, 2.7782e-12,\n",
      "         2.7717e-12, 2.7698e-12, 2.7676e-12, 2.7969e-12, 2.7670e-12, 2.7421e-12,\n",
      "         2.7511e-12, 2.7713e-12, 2.7924e-12, 2.7953e-12, 2.7881e-12, 2.8010e-12,\n",
      "         2.7897e-12, 2.7860e-12, 2.7801e-12, 2.7817e-12, 2.7710e-12, 2.7285e-12,\n",
      "         2.6908e-12, 2.6978e-12, 2.7031e-12, 2.6827e-12, 2.6657e-12, 2.6559e-12,\n",
      "         2.6618e-12, 2.6343e-12, 2.6451e-12, 2.6589e-12, 2.6507e-12, 2.6459e-12,\n",
      "         2.6464e-12, 2.6547e-12, 2.6509e-12, 2.6163e-12, 2.6044e-12, 2.5844e-12,\n",
      "         2.5552e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.4223e-12, 2.4067e-12, 2.4343e-12, 2.4674e-12, 2.4672e-12,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4723e-12,\n",
      "         2.4679e-12, 2.4716e-12, 2.4694e-12, 2.4503e-12, 2.4312e-12, 2.4293e-12,\n",
      "         2.4102e-12, 2.4058e-12, 2.4001e-12, 2.3961e-12, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.3480e-12, 2.3683e-12, 2.3947e-12, 2.4130e-12, 2.4180e-12, 2.4109e-12,\n",
      "         2.4069e-12, 2.3628e-12, 2.3544e-12, 2.3593e-12, 2.3513e-12, 2.3225e-12,\n",
      "         2.3039e-12, 2.3010e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2264e-12, 2.2235e-12,\n",
      "         2.2265e-12, 2.2266e-12, 2.2201e-12, 2.2196e-12, 2.2227e-12, 2.2276e-12,\n",
      "         2.2029e-12, 2.1976e-12, 2.1928e-12, 2.2165e-12, 2.2343e-12, 2.2305e-12,\n",
      "         2.2265e-12, 2.2239e-12, 2.2443e-12, 2.2507e-12, 2.2438e-12, 2.2505e-12,\n",
      "         2.2805e-12, 2.2790e-12, 2.2798e-12, 2.2811e-12, 2.2847e-12, 2.2606e-12,\n",
      "         2.2538e-12, 2.2656e-12, 2.2675e-12, 2.2584e-12, 2.2374e-12, 2.2284e-12,\n",
      "         2.2254e-12, 2.2194e-12, 2.2078e-12, 2.1969e-12, 2.1955e-12, 2.1984e-12,\n",
      "         2.1924e-12, 2.1857e-12, 2.1890e-12, 2.1841e-12, 2.1793e-12, 2.1751e-12,\n",
      "         2.1883e-12, 2.1775e-12, 2.1924e-12, 2.1946e-12, 2.2013e-12, 2.1791e-12,\n",
      "         2.1857e-12, 2.1916e-12, 2.2010e-12, 2.1949e-12, 2.2195e-12, 2.2297e-12,\n",
      "         2.2359e-12, 2.2401e-12, 2.2362e-12, 2.2386e-12, 2.2455e-12, 2.2484e-12,\n",
      "         2.2484e-12, 2.2486e-12, 2.2761e-12, 2.3024e-12, 2.3055e-12, 2.3133e-12,\n",
      "         2.3300e-12, 2.3280e-12, 2.3277e-12, 2.3240e-12, 2.3316e-12, 2.3310e-12,\n",
      "         2.3299e-12, 2.3257e-12, 2.3370e-12, 2.3355e-12, 2.3182e-12, 2.3224e-12,\n",
      "         2.3228e-12, 2.3093e-12, 2.2955e-12, 2.2792e-12, 2.2942e-12, 2.3098e-12,\n",
      "         2.3227e-12, 2.3296e-12, 2.3331e-12, 2.3412e-12, 2.3504e-12, 2.3547e-12,\n",
      "         2.3412e-12, 2.3322e-12, 2.3336e-12, 2.3443e-12, 2.3494e-12, 2.3445e-12,\n",
      "         2.3369e-12, 2.3378e-12, 2.3513e-12, 2.3408e-12, 2.3342e-12, 2.3165e-12,\n",
      "         2.3054e-12, 2.3090e-12, 2.3057e-12, 2.3075e-12, 2.3057e-12, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.1587e-12, 2.1611e-12, 2.1705e-12, 2.1646e-12, 2.1554e-12, 2.1492e-12,\n",
      "         2.1511e-12, 2.1443e-12, 2.1294e-12, 2.1074e-12, 2.0947e-12, 2.0972e-12,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       device='cuda:0')\n",
      "✅ Best model updated.\n",
      "\n",
      "🚀 Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:11<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[-6.3445e-05, -1.1360e-04, -9.6907e-05, -9.4324e-06, -3.5752e-05,\n",
      "          1.2611e-04, -9.1456e-07,  3.7081e-05, -3.5630e-04, -5.2042e-05,\n",
      "          1.4446e-04, -2.5649e-04, -1.6347e-04,  3.2205e-04,  2.5554e-04,\n",
      "          9.4501e-05,  6.7333e-05,  3.0968e-04,  2.8174e-04,  4.6025e-04,\n",
      "         -2.7101e-06,  1.8232e-04, -2.1942e-04, -3.8178e-04,  1.5560e-04,\n",
      "         -1.5236e-04, -1.1110e-04, -1.3961e-04,  2.1156e-05, -2.1819e-05,\n",
      "          8.7284e-05, -2.6456e-04,  1.6244e-04, -1.2677e-04, -8.2012e-05,\n",
      "          8.2713e-05,  2.7551e-04,  4.2708e-04,  2.4854e-04,  4.9887e-05,\n",
      "         -4.0680e-05, -1.1949e-05, -2.3898e-04, -2.0158e-04, -3.2585e-05,\n",
      "         -5.4469e-05, -1.2624e-04, -2.3253e-04,  2.5329e-04, -5.3007e-04,\n",
      "          1.5652e-04, -1.1583e-04, -7.9488e-07,  6.4874e-05,  5.6277e-04,\n",
      "          7.6315e-04,  2.8513e-04,  1.2822e-04,  2.6803e-05,  5.2029e-05,\n",
      "          1.5033e-04, -4.9260e-06, -4.5978e-04, -9.1717e-05,  2.2740e-04,\n",
      "          5.5002e-05,  2.2659e-04, -4.5757e-05,  2.3966e-04,  1.4089e-04,\n",
      "          1.2262e-04, -1.3547e-05, -1.0476e-04,  1.2226e-05,  1.7317e-05,\n",
      "          1.1349e-05, -1.5404e-04, -1.2604e-04,  6.3330e-06,  3.8883e-06,\n",
      "         -1.9682e-05,  2.7658e-05,  1.0274e-04,  7.8569e-05,  2.0155e-04,\n",
      "         -7.8347e-05, -2.5404e-04,  3.0912e-04,  4.3683e-04,  1.3484e-04,\n",
      "          2.9357e-04, -1.9664e-04,  1.5149e-04, -1.3066e-05,  4.8216e-05,\n",
      "          7.6760e-06,  3.8921e-05, -8.0100e-04,  9.1456e-07, -3.4501e-04,\n",
      "          1.1392e-04, -5.8537e-04,  8.3833e-06, -3.0106e-04, -3.0405e-04,\n",
      "          1.8687e-04, -3.0367e-04,  5.0843e-05, -3.3407e-05, -9.4496e-05,\n",
      "         -5.5172e-06,  1.6145e-04, -2.4760e-05, -1.9382e-04,  2.1797e-04,\n",
      "          3.1192e-05, -1.8415e-04,  1.6337e-05,  2.6716e-04,  3.0301e-04,\n",
      "         -2.0583e-04,  2.8127e-04,  3.0663e-05, -3.3232e-04,  2.4418e-04,\n",
      "         -2.8039e-04,  2.6782e-04,  1.1981e-04, -1.1647e-04,  2.2558e-04,\n",
      "         -3.5626e-04, -1.1474e-04,  5.5645e-04,  1.9682e-04,  1.5201e-04,\n",
      "         -2.6144e-04,  5.5760e-04,  4.9695e-05,  1.4755e-04, -2.1639e-04,\n",
      "         -1.0603e-04,  4.8073e-04, -2.8550e-05, -3.5126e-05, -8.7511e-05,\n",
      "         -1.9737e-04, -9.3469e-05, -1.8776e-04,  1.1797e-04,  1.6504e-04,\n",
      "          3.9237e-05, -9.6602e-05,  1.1403e-04, -2.8373e-04,  4.8374e-04,\n",
      "         -2.6398e-04,  1.2124e-04, -3.3627e-04,  4.2250e-04, -7.7154e-05,\n",
      "          2.9603e-05, -9.4509e-05, -1.1247e-03, -2.3804e-04, -8.7835e-05,\n",
      "          1.8647e-04,  3.8178e-05,  4.0155e-04,  1.7900e-04, -1.1629e-04,\n",
      "          2.2674e-04, -9.4058e-05,  5.5281e-05,  8.9195e-05, -5.3581e-04,\n",
      "         -1.0159e-04,  4.3382e-04, -8.4559e-05, -1.1675e-04, -2.2966e-04,\n",
      "         -4.6548e-05, -2.0886e-04,  1.1147e-04, -5.2074e-04,  7.1527e-05,\n",
      "          1.5963e-06,  1.4610e-05,  7.5721e-05, -4.2299e-05,  1.1694e-05,\n",
      "         -1.1948e-03,  9.0627e-05,  2.2082e-04, -2.5798e-04,  3.2769e-04,\n",
      "         -5.3154e-04, -1.4044e-05,  5.9494e-04, -7.5587e-04,  2.7828e-04,\n",
      "          7.1463e-04, -3.7681e-04,  7.7888e-05, -5.9010e-05, -2.9718e-04,\n",
      "         -3.2686e-04, -9.0897e-07,  1.4605e-04, -1.3304e-04,  9.2518e-04,\n",
      "          2.5190e-04,  5.2106e-04,  3.6752e-04, -1.8820e-04,  1.1292e-04,\n",
      "         -3.2027e-05, -4.2413e-04, -7.8068e-07, -4.8885e-04,  9.5455e-05,\n",
      "          1.2446e-04,  2.4656e-04,  4.5674e-04,  5.1292e-05,  3.7539e-04,\n",
      "          2.8268e-04, -8.0892e-05, -1.6893e-04,  1.3804e-04, -8.9221e-07,\n",
      "         -1.0577e-03,  1.2353e-04, -1.0326e-03, -3.0707e-04, -4.3287e-04,\n",
      "          4.6713e-04, -3.6861e-04, -7.8516e-05,  1.4993e-04, -2.6430e-04,\n",
      "          1.7370e-04, -2.4839e-04, -2.7922e-04, -1.5082e-04, -2.1546e-04,\n",
      "         -3.2306e-04, -5.6121e-05, -2.8780e-04,  3.2025e-04, -7.2576e-05,\n",
      "         -5.3749e-04,  1.6640e-04, -3.0739e-04, -3.1740e-04, -1.8925e-04,\n",
      "         -1.3317e-04,  6.8714e-04, -4.3633e-04, -4.8388e-04,  3.0571e-05,\n",
      "          7.8000e-05,  3.2937e-04,  1.3672e-04,  7.3243e-05,  2.4449e-05,\n",
      "         -2.7968e-04,  6.3311e-06,  1.8629e-05, -7.1843e-05,  1.9687e-04,\n",
      "         -2.6537e-04, -1.0228e-04, -1.0620e-04,  6.0814e-05,  1.0309e-04,\n",
      "         -2.8417e-04,  2.3680e-05,  3.0964e-04, -6.5882e-06,  7.5902e-05,\n",
      "          1.5592e-04, -1.1799e-04, -9.0423e-05,  2.7011e-04,  2.0571e-04,\n",
      "          1.6663e-04,  1.2635e-04,  2.1009e-04, -2.8066e-04, -1.2026e-04,\n",
      "          3.7966e-04,  3.1516e-06,  1.3662e-04, -6.1495e-06, -7.2998e-05,\n",
      "          3.9762e-05, -4.6724e-04, -5.3541e-05, -5.6529e-05,  1.5246e-05,\n",
      "          1.7551e-04,  1.8376e-04, -2.1551e-04,  2.5575e-04, -1.1305e-04,\n",
      "         -2.5054e-05, -2.5561e-04,  9.0579e-05,  4.4981e-04,  5.4329e-05,\n",
      "         -5.2550e-04,  9.2993e-05,  1.9992e-04,  1.5790e-04,  3.4401e-04,\n",
      "         -5.2322e-04, -5.2908e-05,  7.8212e-05,  5.7349e-05,  2.1070e-05,\n",
      "         -3.0569e-04,  2.7016e-04,  5.8835e-04, -4.6185e-05,  1.5156e-04,\n",
      "          3.6702e-05, -3.3023e-04,  8.3078e-05,  6.9272e-05,  3.5024e-04,\n",
      "          2.6398e-04, -2.6771e-05, -3.0312e-05,  5.6064e-05,  2.2184e-04,\n",
      "          5.3451e-04,  6.9171e-05,  9.3322e-05,  4.6623e-04, -7.5810e-07,\n",
      "          9.6275e-05, -1.3561e-04,  4.0337e-05, -4.3561e-04, -2.9789e-04,\n",
      "          6.0070e-06, -2.5642e-04,  6.7146e-04, -2.5491e-04,  2.7042e-04,\n",
      "          8.1658e-05,  6.5880e-04,  3.6232e-04, -1.4120e-04, -6.8655e-05,\n",
      "          6.8773e-05, -1.4067e-04, -1.4345e-04, -4.0365e-05,  3.4478e-05,\n",
      "         -2.7627e-04,  9.2097e-05, -7.4874e-05,  1.1085e-05,  1.4010e-04,\n",
      "          2.8660e-04,  3.1655e-04, -2.4610e-04,  2.0231e-04,  5.5471e-05,\n",
      "          4.3005e-05, -2.7029e-05, -2.9677e-04, -3.4748e-04, -6.2682e-05,\n",
      "         -1.0082e-04,  1.0923e-05, -9.8010e-04,  3.1356e-04, -2.7543e-04,\n",
      "         -1.6174e-04,  6.1824e-04,  5.5991e-04,  8.3944e-05,  7.3590e-04,\n",
      "          4.5545e-04, -1.7963e-03, -9.4903e-04,  1.9526e-04,  8.3864e-05,\n",
      "         -3.0087e-04,  5.9625e-04, -1.3552e-04,  2.7443e-04, -2.4924e-04,\n",
      "         -6.6254e-06,  5.2762e-04,  2.9660e-04,  2.8953e-05, -8.9945e-05,\n",
      "          3.4874e-05, -6.2251e-05, -3.5673e-05, -3.2071e-04,  7.7847e-05,\n",
      "         -2.6584e-05,  4.7570e-04,  5.7443e-04, -1.8388e-05, -3.7958e-04,\n",
      "          4.9889e-04,  2.0043e-04,  7.2904e-06, -5.0709e-05, -1.8617e-04,\n",
      "          2.0787e-04,  4.8449e-05,  9.3838e-05, -5.3964e-04,  1.2470e-04,\n",
      "          2.6832e-04, -1.0235e-04,  2.3786e-04,  1.1927e-04,  1.2918e-04,\n",
      "          5.5656e-06,  1.3031e-04,  1.3287e-04,  9.0316e-05, -3.3083e-04,\n",
      "          3.0248e-05, -1.1469e-04]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[1.9602e-12, 1.9647e-12, 1.9593e-12, 1.9443e-12, 1.9117e-12, 1.9222e-12,\n",
      "         1.9262e-12, 1.9224e-12, 1.9300e-12, 1.9354e-12, 1.9384e-12, 1.9543e-12,\n",
      "         1.9640e-12, 2.0033e-12, 2.0476e-12, 2.0619e-12, 2.0595e-12, 2.0500e-12,\n",
      "         2.0631e-12, 2.0664e-12, 2.0611e-12, 2.0554e-12, 2.0563e-12, 2.0076e-12,\n",
      "         2.0353e-12, 2.0359e-12, 2.0430e-12, 2.0320e-12, 2.0440e-12, 2.0434e-12,\n",
      "         2.0342e-12, 2.0274e-12, 2.0427e-12, 2.0158e-12, 2.0348e-12, 2.0515e-12,\n",
      "         2.0489e-12, 2.0295e-12, 2.0259e-12, 2.0244e-12, 2.0198e-12, 2.0068e-12,\n",
      "         1.9965e-12, 1.9944e-12, 1.9799e-12, 1.9734e-12, 1.9620e-12, 1.9588e-12,\n",
      "         1.9553e-12, 1.9660e-12, 1.9727e-12, 2.0135e-12, 2.0116e-12, 2.0125e-12,\n",
      "         1.9996e-12, 1.9985e-12, 1.9917e-12, 1.9905e-12, 1.9875e-12, 1.9986e-12,\n",
      "         2.0118e-12, 2.0309e-12, 2.0354e-12, 2.0353e-12, 2.0376e-12, 2.0478e-12,\n",
      "         2.0491e-12, 2.0460e-12, 2.0475e-12, 2.0342e-12, 2.0047e-12, 1.9957e-12,\n",
      "         1.9975e-12, 1.9932e-12, 1.9724e-12, 1.9577e-12, 1.9516e-12, 1.9547e-12,\n",
      "         1.9500e-12, 1.9450e-12, 1.9278e-12, 1.9264e-12, 1.9148e-12, 1.9136e-12,\n",
      "         1.9090e-12, 1.9045e-12, 1.9084e-12, 1.9014e-12, 1.9049e-12, 1.9120e-12,\n",
      "         1.9124e-12, 1.9109e-12, 1.9314e-12, 1.9458e-12, 1.9493e-12, 1.9428e-12,\n",
      "         1.9392e-12, 1.9450e-12, 1.9294e-12, 1.9392e-12, 1.9524e-12, 1.9642e-12,\n",
      "         1.9571e-12, 1.9564e-12, 1.9525e-12, 1.9451e-12, 1.9403e-12, 1.9284e-12,\n",
      "         1.9091e-12, 1.9106e-12, 1.9108e-12, 1.9006e-12, 1.9013e-12, 1.8968e-12,\n",
      "         1.8946e-12, 1.8941e-12, 1.8900e-12, 1.8912e-12, 1.8717e-12, 1.8628e-12,\n",
      "         1.8623e-12, 1.8704e-12, 1.8663e-12, 1.8603e-12, 1.8675e-12, 1.8665e-12,\n",
      "         1.8651e-12, 1.8576e-12, 1.8516e-12, 1.8698e-12, 1.8971e-12, 1.9056e-12,\n",
      "         1.9139e-12, 1.9121e-12, 1.9466e-12, 1.9800e-12, 1.9952e-12, 2.0084e-12,\n",
      "         2.0190e-12, 2.0038e-12, 1.9989e-12, 2.0110e-12, 2.0181e-12, 2.0127e-12,\n",
      "         2.0103e-12, 2.0066e-12, 2.0257e-12, 2.0293e-12, 2.0146e-12, 2.0066e-12,\n",
      "         2.0054e-12, 2.0167e-12, 2.0274e-12, 2.0462e-12, 2.0470e-12, 2.0411e-12,\n",
      "         2.0441e-12, 2.0318e-12, 2.0425e-12, 2.0474e-12, 2.0434e-12, 2.0397e-12,\n",
      "         2.0382e-12, 1.9931e-12, 2.0213e-12, 2.0199e-12, 2.0309e-12, 2.0318e-12,\n",
      "         2.0836e-12, 2.0876e-12, 2.0751e-12, 2.0694e-12, 2.0694e-12, 2.0769e-12,\n",
      "         2.0849e-12, 2.1073e-12, 2.1226e-12, 2.0937e-12, 2.0950e-12, 2.1070e-12,\n",
      "         2.1092e-12, 2.0942e-12, 2.1468e-12, 2.1603e-12, 2.1705e-12, 2.1666e-12,\n",
      "         2.1620e-12, 2.1266e-12, 2.1203e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Eval Batch 1/3 — OMNI2 Mask Sum: 164160.0 | GOES Mask Sum: 683824.0 | Density Mask Sum: 784.0\n",
      "⚠️ Low GOES coverage in this batch!\n",
      "🧪 Eval Batch 2/3 — OMNI2 Mask Sum: 164160.0 | GOES Mask Sum: 679068.0 | Density Mask Sum: 718.0\n",
      "⚠️ Low GOES coverage in this batch!\n",
      "🧪 Eval Batch 3/3 — OMNI2 Mask Sum: 82080.0 | GOES Mask Sum: 333536.0 | Density Mask Sum: 254.0\n",
      "⚠️ Low GOES coverage in this batch!\n",
      "\n",
      "📊 Epoch 3/20 — Train Loss: 0.0003173446387639463 | Val Loss: 0.0004077698298109074\n",
      "Preds: tensor([[-7.4923e-05,  3.8303e-05, -2.5476e-04, -4.5741e-05,  2.6779e-04,\n",
      "         -1.1458e-04, -2.4416e-05,  6.8052e-05,  2.7750e-05, -1.9160e-04,\n",
      "         -3.7843e-04,  2.0465e-04,  1.5336e-04, -6.6070e-04, -2.5076e-04,\n",
      "         -1.4329e-04,  2.8004e-05,  7.2408e-05, -3.6089e-04, -2.0764e-04,\n",
      "          2.9523e-05,  1.0661e-04, -2.4312e-04,  2.3801e-04, -1.8357e-04,\n",
      "          1.3560e-04, -2.8005e-04, -1.0522e-05, -3.9084e-04, -1.8222e-04,\n",
      "          1.7397e-04,  3.0462e-04, -1.6634e-04,  8.3978e-05, -2.8610e-06,\n",
      "          2.8522e-04,  7.1259e-05, -5.1713e-04, -1.5518e-04, -5.4849e-04,\n",
      "          3.3884e-04, -6.5163e-04, -4.7619e-05, -2.8877e-04,  3.7424e-05,\n",
      "          1.8371e-04,  2.5259e-04, -9.7435e-06, -3.0999e-04, -2.3323e-04,\n",
      "          7.3884e-05,  1.3147e-04,  7.2209e-05, -1.5409e-04, -1.0740e-03,\n",
      "          2.1066e-04, -2.8690e-04, -1.1350e-04,  3.9563e-06, -1.9185e-04,\n",
      "         -3.3748e-04, -1.7462e-04, -3.9058e-04,  4.2066e-05,  1.1876e-05,\n",
      "         -2.5946e-04, -3.0185e-04, -2.4803e-04, -1.4061e-04,  1.0699e-05,\n",
      "         -2.3860e-04, -2.0523e-05,  1.3259e-04,  1.3811e-04, -1.0887e-04,\n",
      "         -1.1116e-04,  2.9033e-04, -8.2238e-05, -4.5959e-05,  9.3829e-05,\n",
      "          4.3353e-05, -4.4422e-05, -2.5868e-04, -7.0542e-05, -3.0337e-04,\n",
      "         -5.5231e-05,  3.9060e-04, -5.2419e-04, -1.0247e-03, -2.8238e-06,\n",
      "         -3.1824e-04,  2.3625e-04, -3.6106e-04,  1.1308e-04, -1.0778e-04,\n",
      "          3.7214e-05, -6.4596e-05,  1.5619e-03, -7.9261e-05,  3.3303e-04,\n",
      "          6.1728e-05,  1.0289e-03,  4.3018e-05,  1.2631e-04,  4.8041e-04,\n",
      "          2.6960e-04, -2.8859e-04, -1.3053e-04, -8.3479e-05,  1.2146e-04,\n",
      "          1.2557e-04, -2.0242e-04,  4.8229e-05,  2.8899e-04,  1.3318e-05,\n",
      "         -2.1636e-04,  2.5937e-04, -1.5786e-05, -3.1848e-05, -4.3316e-04,\n",
      "          1.6658e-04, -4.5114e-04,  5.9769e-05,  7.6148e-04,  2.8038e-05,\n",
      "          3.9604e-04, -2.3502e-04, -5.5863e-04, -5.6863e-05, -5.4207e-04,\n",
      "          1.9971e-04, -9.0010e-05, -9.6866e-04, -1.7658e-04, -1.8399e-04,\n",
      "          6.8049e-04, -9.2636e-04,  5.6338e-05, -9.0702e-05,  2.8845e-04,\n",
      "          1.9037e-04, -8.7298e-04,  3.0236e-04,  9.3911e-05, -1.7412e-04,\n",
      "          1.5923e-04,  1.5890e-04, -4.1770e-05,  1.4229e-05, -4.3701e-04,\n",
      "         -8.4963e-05,  1.4452e-05, -1.8846e-04,  4.0959e-04, -1.0960e-03,\n",
      "          2.3462e-04, -2.5202e-05,  5.8021e-04, -8.4142e-04,  1.6432e-04,\n",
      "         -1.3093e-04,  1.2133e-04,  2.0904e-04,  6.8677e-04, -2.1392e-06,\n",
      "         -4.9303e-04,  1.7095e-04, -3.4683e-04, -5.6059e-04,  1.4743e-04,\n",
      "         -4.9071e-04,  3.1976e-04,  3.3781e-05,  1.5609e-06,  4.5349e-04,\n",
      "          5.8501e-04, -4.8078e-04,  3.1920e-04,  7.4079e-05,  9.1833e-04,\n",
      "          1.8639e-04,  6.4176e-05, -5.9880e-04,  7.0666e-04, -3.5162e-04,\n",
      "         -3.8505e-05,  2.8551e-04,  9.7631e-06,  2.4476e-04,  3.3906e-04,\n",
      "         -2.1622e-03, -1.2223e-05,  4.8890e-04, -4.7596e-04,  7.3784e-04,\n",
      "         -6.4029e-04,  2.5887e-05,  1.1225e-03, -1.0043e-03,  4.3837e-04,\n",
      "          1.2636e-03, -5.9772e-04,  4.3591e-05, -1.5131e-04, -5.2643e-04,\n",
      "         -6.7498e-04, -4.2414e-05,  1.3720e-04, -2.2297e-04,  1.2340e-03,\n",
      "          5.3245e-04,  9.1047e-04,  4.0168e-04, -3.4235e-04,  2.8858e-04,\n",
      "          8.9797e-05, -5.5015e-04,  5.7168e-04, -9.0845e-04,  2.2103e-05,\n",
      "          1.9991e-04,  7.0900e-04,  5.4073e-04,  8.7578e-05,  2.8345e-04,\n",
      "          2.7075e-04, -1.4880e-04, -8.4233e-05,  2.6430e-04, -1.8234e-04,\n",
      "         -1.8379e-03,  4.6309e-05, -1.6223e-03, -3.9127e-04, -7.3858e-04,\n",
      "          5.3569e-04, -3.6978e-04,  9.6494e-05,  1.7641e-04, -4.8129e-04,\n",
      "          2.9747e-04, -1.9061e-04, -4.3487e-04, -5.1120e-04, -2.6922e-04,\n",
      "         -5.2089e-04, -1.2016e-04, -5.2634e-04,  4.2915e-04, -4.3292e-05,\n",
      "         -6.9225e-04,  3.9695e-04, -3.8708e-04, -4.4235e-04, -3.1907e-04,\n",
      "         -4.0986e-04,  1.2196e-03, -6.3379e-04, -6.4996e-04,  1.3145e-04,\n",
      "          1.1250e-04,  6.5407e-04,  2.9923e-04,  2.8229e-04,  2.2463e-04,\n",
      "         -6.1070e-04, -1.1791e-04,  1.1409e-04, -1.7176e-04,  3.1657e-04,\n",
      "         -4.9568e-04, -1.0827e-04, -1.6056e-04,  1.0384e-04,  1.0044e-04,\n",
      "         -6.5794e-05,  3.2643e-06,  7.4890e-04,  1.0613e-04, -6.8148e-05,\n",
      "          2.5498e-04, -4.5733e-06, -4.4488e-04,  5.6220e-04,  7.6613e-05,\n",
      "          2.4911e-04,  2.3927e-04,  3.0222e-04, -4.5698e-04, -6.4308e-05,\n",
      "          4.0478e-04, -6.9922e-05,  2.2579e-04,  1.0401e-04, -2.3272e-04,\n",
      "          1.6593e-04, -5.4705e-04,  1.8483e-05, -1.0720e-04, -1.8906e-04,\n",
      "         -5.2109e-05,  3.0483e-04, -4.4636e-04,  1.4615e-04, -2.7519e-04,\n",
      "          2.1998e-04, -3.2247e-04, -1.1637e-04,  5.5398e-04,  1.6812e-04,\n",
      "         -6.3114e-04,  2.4197e-04, -4.5758e-05,  2.1950e-04,  6.7768e-04,\n",
      "         -1.0422e-03,  1.5628e-05,  3.7487e-05,  3.1425e-04, -2.3761e-04,\n",
      "         -5.5219e-04,  2.4661e-04,  4.1440e-04,  2.3295e-04,  3.0715e-04,\n",
      "          1.4639e-05, -6.8078e-04,  7.3761e-05, -7.0905e-05,  2.8829e-04,\n",
      "          3.9270e-04, -1.4658e-04, -9.3645e-05,  4.0304e-04,  3.1139e-04,\n",
      "          4.6046e-04,  2.5404e-04, -3.0655e-05,  2.6768e-04, -1.7579e-04,\n",
      "          1.6644e-04, -6.4833e-05,  3.8881e-05, -3.3481e-04, -4.7469e-04,\n",
      "          2.3092e-04, -5.0241e-05,  7.8185e-04, -2.6116e-04,  2.5548e-04,\n",
      "          1.5311e-04,  7.6495e-04,  3.3044e-04, -1.3539e-04, -3.7793e-04,\n",
      "         -2.4315e-04, -1.3185e-04, -2.4385e-04, -1.2374e-04, -1.3024e-05,\n",
      "         -4.6111e-04,  2.7847e-04, -4.4567e-05, -3.2159e-05,  8.2051e-05,\n",
      "          5.6553e-04,  2.5903e-04, -2.2920e-04,  2.7266e-04,  3.2431e-04,\n",
      "          3.4811e-04, -4.3313e-04, -4.0609e-04, -6.3755e-04, -1.7320e-04,\n",
      "         -1.8852e-04, -6.7096e-05, -1.5231e-03,  6.5159e-04, -2.8626e-04,\n",
      "         -3.3290e-04,  1.1725e-03,  6.1451e-04,  1.3846e-04,  1.2080e-03,\n",
      "          9.6618e-04, -2.3571e-03, -1.0107e-03,  6.5146e-04,  4.3134e-04,\n",
      "         -8.6797e-05,  5.4149e-04,  2.5225e-04,  5.2729e-04, -1.7006e-04,\n",
      "          8.1101e-05,  1.1681e-03, -5.6624e-07,  2.2782e-04, -1.9836e-04,\n",
      "         -2.9391e-04, -1.6201e-04,  2.4129e-04, -5.7580e-04,  1.5901e-04,\n",
      "          1.2058e-04,  7.9130e-04,  4.4846e-04,  4.2741e-06, -4.1371e-04,\n",
      "          3.1094e-04,  5.6367e-04, -6.0344e-05, -8.1379e-06, -3.6962e-04,\n",
      "          1.5219e-04, -2.9992e-04, -1.7419e-05, -5.8840e-04,  1.6800e-04,\n",
      "          2.7073e-04, -1.1608e-04,  9.0966e-05,  1.1134e-04,  2.1416e-04,\n",
      "         -9.0174e-05,  1.9754e-04, -5.6349e-05,  1.3130e-04, -1.3576e-04,\n",
      "          2.5707e-04,  4.9001e-05]], device='cuda:0')\n",
      "Targets tensor([[2.7148e-12, 2.7233e-12, 2.7289e-12, 2.7087e-12, 2.7114e-12, 2.7205e-12,\n",
      "         2.7232e-12, 2.7230e-12, 2.7582e-12, 2.7302e-12, 2.7363e-12, 2.7476e-12,\n",
      "         2.7522e-12, 2.7243e-12, 2.7381e-12, 2.7521e-12, 2.7626e-12, 2.7216e-12,\n",
      "         2.6950e-12, 2.6917e-12, 2.6823e-12, 2.6827e-12, 2.6736e-12, 2.6690e-12,\n",
      "         2.6684e-12, 2.6975e-12, 2.7068e-12, 2.6855e-12, 2.7152e-12, 2.7047e-12,\n",
      "         2.7048e-12, 2.7180e-12, 2.7344e-12, 2.7506e-12, 2.7476e-12, 2.7309e-12,\n",
      "         2.7705e-12, 2.8143e-12, 2.8265e-12, 2.8291e-12, 2.8340e-12, 2.8104e-12,\n",
      "         2.8100e-12, 2.8360e-12, 2.8364e-12, 2.8380e-12, 2.8279e-12, 2.8103e-12,\n",
      "         2.8159e-12, 2.8057e-12, 2.8091e-12, 2.7990e-12, 2.7971e-12, 2.8002e-12,\n",
      "         2.7830e-12, 2.7680e-12, 2.7394e-12, 2.7465e-12, 2.7469e-12, 2.7542e-12,\n",
      "         2.7728e-12, 2.7516e-12, 2.7451e-12, 2.7441e-12, 2.7562e-12, 2.7782e-12,\n",
      "         2.7717e-12, 2.7698e-12, 2.7676e-12, 2.7969e-12, 2.7670e-12, 2.7421e-12,\n",
      "         2.7511e-12, 2.7713e-12, 2.7924e-12, 2.7953e-12, 2.7881e-12, 2.8010e-12,\n",
      "         2.7897e-12, 2.7860e-12, 2.7801e-12, 2.7817e-12, 2.7710e-12, 2.7285e-12,\n",
      "         2.6908e-12, 2.6978e-12, 2.7031e-12, 2.6827e-12, 2.6657e-12, 2.6559e-12,\n",
      "         2.6618e-12, 2.6343e-12, 2.6451e-12, 2.6589e-12, 2.6507e-12, 2.6459e-12,\n",
      "         2.6464e-12, 2.6547e-12, 2.6509e-12, 2.6163e-12, 2.6044e-12, 2.5844e-12,\n",
      "         2.5552e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.4223e-12, 2.4067e-12, 2.4343e-12, 2.4674e-12, 2.4672e-12,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4723e-12,\n",
      "         2.4679e-12, 2.4716e-12, 2.4694e-12, 2.4503e-12, 2.4312e-12, 2.4293e-12,\n",
      "         2.4102e-12, 2.4058e-12, 2.4001e-12, 2.3961e-12, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.3480e-12, 2.3683e-12, 2.3947e-12, 2.4130e-12, 2.4180e-12, 2.4109e-12,\n",
      "         2.4069e-12, 2.3628e-12, 2.3544e-12, 2.3593e-12, 2.3513e-12, 2.3225e-12,\n",
      "         2.3039e-12, 2.3010e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2264e-12, 2.2235e-12,\n",
      "         2.2265e-12, 2.2266e-12, 2.2201e-12, 2.2196e-12, 2.2227e-12, 2.2276e-12,\n",
      "         2.2029e-12, 2.1976e-12, 2.1928e-12, 2.2165e-12, 2.2343e-12, 2.2305e-12,\n",
      "         2.2265e-12, 2.2239e-12, 2.2443e-12, 2.2507e-12, 2.2438e-12, 2.2505e-12,\n",
      "         2.2805e-12, 2.2790e-12, 2.2798e-12, 2.2811e-12, 2.2847e-12, 2.2606e-12,\n",
      "         2.2538e-12, 2.2656e-12, 2.2675e-12, 2.2584e-12, 2.2374e-12, 2.2284e-12,\n",
      "         2.2254e-12, 2.2194e-12, 2.2078e-12, 2.1969e-12, 2.1955e-12, 2.1984e-12,\n",
      "         2.1924e-12, 2.1857e-12, 2.1890e-12, 2.1841e-12, 2.1793e-12, 2.1751e-12,\n",
      "         2.1883e-12, 2.1775e-12, 2.1924e-12, 2.1946e-12, 2.2013e-12, 2.1791e-12,\n",
      "         2.1857e-12, 2.1916e-12, 2.2010e-12, 2.1949e-12, 2.2195e-12, 2.2297e-12,\n",
      "         2.2359e-12, 2.2401e-12, 2.2362e-12, 2.2386e-12, 2.2455e-12, 2.2484e-12,\n",
      "         2.2484e-12, 2.2486e-12, 2.2761e-12, 2.3024e-12, 2.3055e-12, 2.3133e-12,\n",
      "         2.3300e-12, 2.3280e-12, 2.3277e-12, 2.3240e-12, 2.3316e-12, 2.3310e-12,\n",
      "         2.3299e-12, 2.3257e-12, 2.3370e-12, 2.3355e-12, 2.3182e-12, 2.3224e-12,\n",
      "         2.3228e-12, 2.3093e-12, 2.2955e-12, 2.2792e-12, 2.2942e-12, 2.3098e-12,\n",
      "         2.3227e-12, 2.3296e-12, 2.3331e-12, 2.3412e-12, 2.3504e-12, 2.3547e-12,\n",
      "         2.3412e-12, 2.3322e-12, 2.3336e-12, 2.3443e-12, 2.3494e-12, 2.3445e-12,\n",
      "         2.3369e-12, 2.3378e-12, 2.3513e-12, 2.3408e-12, 2.3342e-12, 2.3165e-12,\n",
      "         2.3054e-12, 2.3090e-12, 2.3057e-12, 2.3075e-12, 2.3057e-12, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.1587e-12, 2.1611e-12, 2.1705e-12, 2.1646e-12, 2.1554e-12, 2.1492e-12,\n",
      "         2.1511e-12, 2.1443e-12, 2.1294e-12, 2.1074e-12, 2.0947e-12, 2.0972e-12,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       device='cuda:0')\n",
      "\n",
      "🚀 Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 45/48 [00:10<00:00,  4.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_storm_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_states_normalized\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mtrain_storm_transformer\u001b[39m\u001b[34m(initial_states_df, num_epochs, batch_size, lr, device)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# if (omni2_mask.any(dim=-1).sum(dim=1) == 0).any() or (goes_mask.any(dim=-1).sum(dim=1) == 0).any():\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m#     print(\"⚠️ Skipping batch with fully masked inputs\")\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m#     continue\u001b[39;00m\n\u001b[32m     67\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m#print (preds)\u001b[39;00m\n\u001b[32m     70\u001b[39m loss = masked_mse_loss(preds, density, density_mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mSTORMTransformer.forward\u001b[39m\u001b[34m(self, static_input, omni2_seq, goes_seq, omni2_mask, goes_mask)\u001b[39m\n\u001b[32m     61\u001b[39m static_embed = \u001b[38;5;28mself\u001b[39m.static_encoder(static_input)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m#print(\"static embed\", static_embed)\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m#static_embed = self.static_encoder(static_input)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m omni2_embed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43momni2_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43momni2_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m omni2_embed = \u001b[38;5;28mself\u001b[39m.omni2_pos(omni2_embed)\n\u001b[32m     67\u001b[39m omni2_key_mask = (~omni2_mask.bool()).any(dim=-\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m omni2_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_storm_transformer(initial_states_normalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "runpod_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
