{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3026e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.transforms as transformers\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import math\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c6da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "omni2_scaler = joblib.load(\"omni2_scaler.gz\") \n",
    "goes_scaler = joblib.load(\"goes_scaler.gz\") \n",
    "initial_states_scaler = joblib.load(\"initial_states_scaler.gz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab2ed623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.000e+03,  1.550e+02,  0.000e+00,  2.277e+03,  5.100e+01,\n",
       "        4.500e+01,  9.000e+00,  1.000e+00,  1.600e+00,  6.000e-01,\n",
       "       -8.510e+01,  4.000e-01, -1.660e+01, -1.740e+01, -4.520e+01,\n",
       "       -1.750e+01, -4.530e+01,  0.000e+00,  3.000e-01,  0.000e+00,\n",
       "        1.000e-01,  1.000e-01,  6.772e+03,  5.000e-01,  3.240e+02,\n",
       "       -1.300e+01, -1.050e+01,  8.000e-03,  0.000e+00,  0.000e+00,\n",
       "        0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  2.700e-01,\n",
       "       -2.296e+01,  0.000e+00,  1.200e+00,  1.200e+00,  1.200e-03,\n",
       "        3.000e+00,  1.130e+02, -3.000e+02,  2.000e+00,  1.524e+02,\n",
       "        3.000e+01, -1.164e+03, -1.500e+01, -7.700e+00,  8.363e-03,\n",
       "        3.600e-01,  3.400e-01,  3.400e-01,  3.200e-01,  1.800e-01,\n",
       "        1.000e-01, -1.000e+00])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omni2_scaler.data_min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b475574",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states = []\n",
    "\n",
    "path = \"input_data/\"\n",
    "\n",
    "for dir, sub_dir, files in os.walk(path):\n",
    "    for file in sorted(files):\n",
    "        #print(file)\n",
    "        temp = pd.read_csv((path+file),index_col=None, header=0)\n",
    "        initial_states.append(temp)\n",
    "\n",
    "initial_states_df = pd.concat(initial_states,axis=0,ignore_index=True)\n",
    "\n",
    "initial_states_norm_df = np.where(initial_states_df.iloc[:,2:] > 1e+10,0.0, initial_states_df.iloc[:,2:])\n",
    "\n",
    "initial_states_scaler = MinMaxScaler()\n",
    "initial_states_scaler_values = initial_states_scaler.fit(initial_states_norm_df)\n",
    "\n",
    "initial_states_normalized = initial_states_scaler_values.transform(initial_states_df.iloc[:,2:].values)\n",
    "\n",
    "initial_states_normalized = np.where(initial_states_normalized >=1, 0.99,initial_states_normalized)\n",
    "\n",
    "initial_states_normalized = pd.concat([initial_states_df['File ID'],pd.DataFrame(initial_states_normalized)],axis=1)\n",
    "\n",
    "# hold = initial_states_df\n",
    "# x = initial_states_df.iloc[:,2:].values\n",
    "# x = normalize(x,norm='l2')\n",
    "# hold = pd.concat([hold['File ID'],pd.DataFrame(x)],axis=1)\n",
    "# initial_states_normalized = hold\n",
    "# #'2000-08-02 04:50:33'\n",
    "# timestamps = initial_states_df['Timestamp']\n",
    "# #initial_states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e980523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullDatasetPT(Dataset):\n",
    "    def __init__(self, initial_states_df, pt_dir='data/new_processed/pt_files'):\n",
    "        self.data = initial_states_df.reset_index(drop=True)\n",
    "        self.pt_dir = pt_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        file_id = str(int(row['File ID'])).zfill(5)\n",
    "        pt_path = os.path.join(self.pt_dir, f\"{file_id}.pt\")\n",
    "\n",
    "        if not os.path.exists(pt_path):\n",
    "            raise FileNotFoundError(f\".pt file not found for File ID: {file_id}\")\n",
    "\n",
    "        static_input = torch.tensor(row.drop(\"File ID\").fillna(0.0).values, dtype=torch.float32)\n",
    "        pt_data = torch.load(pt_path)\n",
    "        \n",
    "        #print (pt_data)\n",
    "        return (\n",
    "            static_input,\n",
    "            pt_data[\"density\"],\n",
    "            pt_data[\"density_mask\"],\n",
    "            pt_data[\"goes\"],\n",
    "            pt_data[\"goes_mask\"],\n",
    "            pt_data[\"omni2\"],\n",
    "            pt_data[\"omni2_mask\"]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd2593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Positional Encoding for Sequences\n",
    "# -----------------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=4320):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000.0) / d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# -----------------------------------\n",
    "# STORMTransformer with Feature Mask Concatenation (No Downsampling)\n",
    "# -----------------------------------\n",
    "class STORMTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 static_dim=9,\n",
    "                 omni2_dim=57,\n",
    "                 goes_dim=42,\n",
    "                 d_model=128,\n",
    "                 output_len=432,\n",
    "                 nhead=8,\n",
    "                 num_layers=4,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "\n",
    "        # Inputs are doubled due to feature-mask concatenation\n",
    "        self.omni2_proj = nn.Linear(omni2_dim * 2, d_model)\n",
    "        self.goes_proj = nn.Linear(goes_dim * 2, d_model)\n",
    "\n",
    "        self.omni2_pos = PositionalEncoding(d_model)\n",
    "        self.goes_pos = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.omni2_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.goes_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # self.fusion = nn.Sequential(\n",
    "        #     nn.Linear(d_model * 3, 256),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(dropout),\n",
    "        #     nn.Linear(256, output_len)\n",
    "        # )\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256,360),\n",
    "            nn.BatchNorm1d(360),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(360, output_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, static_input, omni2_seq, goes_seq, omni2_mask=None, goes_mask=None):\n",
    "        B = static_input.size(0)\n",
    "\n",
    "        # ----- Static Embedding -----\n",
    "        #print(\"static input\",static_input)\n",
    "        static_embed = self.static_encoder(static_input)\n",
    "        #print(\"static embed\", static_embed)\n",
    "\n",
    "        # ----- OMNI2 -----\n",
    "        if omni2_mask is not None:\n",
    "            omni2_cat = torch.cat([omni2_seq, omni2_mask], dim=-1)  # [B, T, 2D]\n",
    "        else:\n",
    "            omni2_cat = omni2_seq\n",
    "        omni2_embed = self.omni2_proj(omni2_cat)\n",
    "        omni2_embed = self.omni2_pos(omni2_embed)\n",
    "        omni2_out = self.omni2_encoder(omni2_embed)  # ⬅️ No key mask\n",
    "        omni2_summary = omni2_out.mean(dim=1)\n",
    "\n",
    "        # ----- GOES Downsampling to 8640 -----\n",
    "        if goes_seq.shape[1] > 4320:\n",
    "            step = goes_seq.shape[1] // 4320\n",
    "            goes_seq = goes_seq[:, ::step, :]\n",
    "            goes_mask = goes_mask[:, ::step, :] if goes_mask is not None else None\n",
    "\n",
    "        if goes_mask is not None:\n",
    "            goes_cat = torch.cat([goes_seq, goes_mask], dim=-1)  # [B, T, 2D]\n",
    "        else:\n",
    "            goes_cat = goes_seq\n",
    "        goes_embed = self.goes_proj(goes_cat)\n",
    "        goes_embed = self.goes_pos(goes_embed)\n",
    "        goes_out = self.goes_encoder(goes_embed)  # ⬅️ No key mask\n",
    "        goes_summary = goes_out.mean(dim=1)\n",
    "\n",
    "        # print(\"static\",static_embed)\n",
    "        # print(\"omni2\",omni2_summary)\n",
    "        # print(\"goes\",goes_summary)\n",
    "\n",
    "        # ----- Fusion -----\n",
    "        combined = torch.cat((static_embed, omni2_summary, goes_summary), dim=-1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "# -----------------------------------\n",
    "# Masked MSE Loss\n",
    "# -----------------------------------\n",
    "def masked_mse_loss(preds, targets, mask, eps=1e-8):\n",
    "    # preds = torch.nan_to_num(preds, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    # targets = torch.nan_to_num(targets, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    # loss = (preds - targets) ** 2 * mask\n",
    "    # return loss.sum() / (mask.sum() + eps)\n",
    "    diff = (targets - preds) * mask\n",
    "    sq = torch.square(diff)\n",
    "    sum = torch.sum(sq)\n",
    "    N = torch.sum(mask)\n",
    "    # print(sum)\n",
    "    # print(N)\n",
    "    loss = torch.sqrt((sum/N))\n",
    "    return loss\n",
    "\n",
    "# -----------------------------------\n",
    "# Full Training Loop with FullDataset\n",
    "# -----------------------------------\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7e5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_storm_transformer(initial_states_df, num_epochs=100, batch_size=16, lr=1e-5, device=None):\n",
    "    # from full_dataset import FullDataset\n",
    "    # from storm_transformer import STORMTransformer, masked_mse_loss\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # 🔀 Train/validation split\n",
    "    train_df, val_df = train_test_split(initial_states_df[0:8112], test_size=0.05, random_state=42)\n",
    "\n",
    "    train_dataset = FullDatasetPT(train_df)\n",
    "    val_dataset = FullDatasetPT(val_df)\n",
    "\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True, )\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "\n",
    "    model = STORMTransformer().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    checkpoint_path = \"checkpoints/storm_last.pt\"\n",
    "    best_model_path = \"checkpoints/storm_best.pt\"\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    # 🔁 Resume support\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"🔁 Resuming from checkpoint: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint.get('epoch', 0)\n",
    "        best_val_loss = checkpoint.get('val_loss', float(\"inf\"))\n",
    "\n",
    "    # 🚀 Training loop\n",
    "    \n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        print(f\"\\n🚀 Epoch {epoch + 1}/{num_epochs}\")\n",
    "        #start_load = time.time()\n",
    "        for batch in tqdm(train_loader):\n",
    "            \n",
    "            static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = batch\n",
    "            #nd_load = time.time()\n",
    "            global omni2_out\n",
    "            omni2_out = omni2\n",
    "            \n",
    "            static_input = static_input.to(device)\n",
    "            density = density.to(device)\n",
    "            density_mask = density_mask.to(device)\n",
    "            goes = goes.to(device)\n",
    "            goes_mask = goes_mask.to(device)\n",
    "            omni2 = omni2.to(device)\n",
    "            omni2_mask = omni2_mask.to(device)\n",
    "            # print (\"static\",static_input)\n",
    "            # print (\"dens\",density)\n",
    "            # print (\"goes\",goes)\n",
    "            # print (\"omni2\",omni2)\n",
    "\n",
    "            # if (omni2_mask.any(dim=-1).sum(dim=1) == 0).any() or (goes_mask.any(dim=-1).sum(dim=1) == 0).any():\n",
    "            #     print(\"⚠️ Skipping batch with fully masked inputs\")\n",
    "            #     continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "            # print (preds)\n",
    "            # print (\"------------------Preds--------------------\",len(preds))\n",
    "            # print (\"Preds:\", preds)\n",
    "            # print (\"Targets\",density)\n",
    "            #print (preds)\n",
    "            loss = masked_mse_loss(preds, density, density_mask)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            #end_batch = time.time()\n",
    "\n",
    "            # print (\"Load time:\", end_load - start_load )\n",
    "            # print (\"Calc time:\", end_batch - end_load)\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        print (\"Preds:\", preds)\n",
    "        print (\"Targets\",density)\n",
    "        \n",
    "        # 🧪 Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = batch\n",
    "                \n",
    "\n",
    "                static_input = static_input.to(device)\n",
    "                density = density.to(device)\n",
    "                density_mask = density_mask.to(device)\n",
    "                goes = goes.to(device)\n",
    "                goes_mask = goes_mask.to(device)\n",
    "                omni2 = omni2.to(device)\n",
    "                omni2_mask = omni2_mask.to(device)\n",
    "\n",
    "                if (omni2_mask.any(dim=-1).sum(dim=1) == 0).any() or (goes_mask.any(dim=-1).sum(dim=1) == 0).any():\n",
    "                    continue\n",
    "\n",
    "                preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "                \n",
    "                loss = masked_mse_loss(preds, density, density_mask)\n",
    "                #print (\"loss\",loss,\"-------------------\")\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # 🧠 Mask diagnostics\n",
    "                goes_mask_sum = goes_mask.sum().item()\n",
    "                omni2_mask_sum = omni2_mask.sum().item()\n",
    "                density_mask_sum = density_mask.sum().item()\n",
    "\n",
    "                print(f\"🧪 Eval Batch {batch_idx+1}/{len(val_loader)} — \"\n",
    "                      f\"OMNI2 Mask Sum: {omni2_mask_sum} | \"\n",
    "                      f\"GOES Mask Sum: {goes_mask_sum} | \"\n",
    "                      f\"Density Mask Sum: {density_mask_sum}\")\n",
    "\n",
    "                # ⚠️ Alert if any mask has < 10% coverage\n",
    "                if omni2_mask_sum < 0.1 * omni2_mask.numel():\n",
    "                    print(\"⚠️ Low OMNI2 coverage in this batch!\")\n",
    "                if goes_mask_sum < 0.1 * goes_mask.numel():\n",
    "                    print(\"⚠️ Low GOES coverage in this batch!\")\n",
    "                if density_mask_sum < 0.1 * density_mask.numel():\n",
    "                    print(\"⚠️ Low density mask coverage in this batch!\")\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print (\"Preds:\", preds)\n",
    "        print (\"Targets\",density)\n",
    "        print(\"-------------------------------------------\")\n",
    "        print(f\"\\n📊 Epoch {epoch+1}/{num_epochs} — \"\n",
    "              f\"Train Loss: {avg_train_loss} | Val Loss: {avg_val_loss}\")\n",
    "        \n",
    "        \n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "\n",
    "        # 💾 Save full checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': avg_val_loss\n",
    "        }, checkpoint_path)\n",
    "\n",
    "        # 💎 Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), f\"checkpoints/epoch{epoch}.pt\")\n",
    "            print(\"✅ Best model updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f393f7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Resuming from checkpoint: checkpoints/storm_last.pt\n",
      "\n",
      "🚀 Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [10:36<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[-3.5316e-06, -1.6176e-06,  3.5268e-05,  ..., -7.5151e-05,\n",
      "          3.0170e-06,  1.6824e-05],\n",
      "        [-3.5316e-06, -1.6176e-06,  3.5268e-05,  ..., -7.5151e-05,\n",
      "          3.0170e-06,  1.6824e-05],\n",
      "        [-3.5316e-06, -1.6176e-06,  3.5268e-05,  ..., -7.5151e-05,\n",
      "          3.0170e-06,  1.6824e-05],\n",
      "        ...,\n",
      "        [-3.5316e-06, -1.6176e-06,  3.5268e-05,  ..., -7.5151e-05,\n",
      "          3.0170e-06,  1.6824e-05],\n",
      "        [-3.5316e-06, -1.6176e-06,  3.5268e-05,  ..., -7.5151e-05,\n",
      "          3.0170e-06,  1.6824e-05],\n",
      "        [-3.5316e-06, -1.6176e-06,  3.5268e-05,  ..., -7.5151e-05,\n",
      "          3.0170e-06,  1.6824e-05]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[2.5025e-12, 2.4971e-12, 2.4794e-12,  ..., 2.2223e-12, 2.2103e-12,\n",
      "         2.1908e-12],\n",
      "        [2.5089e-13, 2.4738e-13, 2.3532e-13,  ..., 1.5317e-13, 1.5665e-13,\n",
      "         1.6073e-13],\n",
      "        [3.9850e-14, 3.9678e-14, 3.9931e-14,  ..., 4.1768e-14, 4.1275e-14,\n",
      "         4.0817e-14],\n",
      "        ...,\n",
      "        [2.0094e-12, 1.9983e-12, 2.0053e-12,  ..., 2.1086e-12, 2.1199e-12,\n",
      "         2.1352e-12],\n",
      "        [1.8044e-12, 1.7846e-12, 1.7676e-12,  ..., 1.9887e-12, 2.0033e-12,\n",
      "         1.9992e-12],\n",
      "        [3.6922e-13, 3.6684e-13, 3.6274e-13,  ..., 1.8311e-13, 1.8140e-13,\n",
      "         1.8035e-13]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Eval Batch 26/26 — OMNI2 Mask Sum: 492480.0 | GOES Mask Sum: 2937816.0 | Density Mask Sum: 2592.0\n",
      "\n",
      "📊 Epoch 55/100 — Train Loss: 5.007954866086042e-05 | Val Loss: 1.54186133071422e-06\n",
      "Preds: tensor([[ 8.4562e-06, -8.7251e-07, -1.5957e-05,  ...,  5.7931e-05,\n",
      "          1.1090e-05, -2.9224e-05],\n",
      "        [ 8.4562e-06, -8.7251e-07, -1.5957e-05,  ...,  5.7931e-05,\n",
      "          1.1090e-05, -2.9224e-05],\n",
      "        [ 8.4562e-06, -8.7251e-07, -1.5957e-05,  ...,  5.7931e-05,\n",
      "          1.1090e-05, -2.9224e-05],\n",
      "        [ 8.4562e-06, -8.7251e-07, -1.5957e-05,  ...,  5.7931e-05,\n",
      "          1.1090e-05, -2.9224e-05],\n",
      "        [ 8.4562e-06, -8.7251e-07, -1.5957e-05,  ...,  5.7931e-05,\n",
      "          1.1090e-05, -2.9224e-05],\n",
      "        [ 8.4562e-06, -8.7251e-07, -1.5957e-05,  ...,  5.7931e-05,\n",
      "          1.1090e-05, -2.9224e-05]], device='cuda:0')\n",
      "Targets tensor([[4.4862e-14, 4.4614e-14, 4.4473e-14,  ..., 4.3594e-14, 4.3997e-14,\n",
      "         4.4936e-14],\n",
      "        [2.5604e-13, 2.5200e-13, 2.4636e-13,  ..., 1.3770e-13, 1.4635e-13,\n",
      "         1.5376e-13],\n",
      "        [5.1611e-12, 5.1743e-12, 5.1893e-12,  ..., 4.7765e-12, 4.7810e-12,\n",
      "         4.7847e-12],\n",
      "        [1.1828e-12, 1.1794e-12, 1.1814e-12,  ..., 8.5150e-13, 8.3358e-13,\n",
      "         8.3713e-13],\n",
      "        [1.5139e-13, 1.4443e-13, 1.3670e-13,  ..., 1.4753e-13, 1.5153e-13,\n",
      "         1.4713e-13],\n",
      "        [5.6139e-12, 5.6438e-12, 5.6751e-12,  ..., 5.9039e-12, 5.8779e-12,\n",
      "         5.8388e-12]], device='cuda:0')\n",
      "✅ Best model updated.\n",
      "\n",
      "🚀 Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [10:27<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[ 3.0367e-05,  2.1676e-05,  9.8661e-09,  ...,  1.2013e-10,\n",
      "         -8.7031e-10, -1.0579e-10],\n",
      "        [ 3.0367e-05,  2.1676e-05,  9.8661e-09,  ...,  1.2013e-10,\n",
      "         -8.7031e-10, -1.0579e-10],\n",
      "        [ 3.0367e-05,  2.1676e-05,  9.8661e-09,  ...,  1.2013e-10,\n",
      "         -8.7031e-10, -1.0579e-10],\n",
      "        ...,\n",
      "        [ 3.0367e-05,  2.1676e-05,  9.8661e-09,  ...,  1.2013e-10,\n",
      "         -8.7031e-10, -1.0579e-10],\n",
      "        [ 3.0367e-05,  2.1676e-05,  9.8661e-09,  ...,  1.2013e-10,\n",
      "         -8.7031e-10, -1.0579e-10],\n",
      "        [ 3.0367e-05,  2.1676e-05,  9.8661e-09,  ...,  1.2013e-10,\n",
      "         -8.7031e-10, -1.0579e-10]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[1.1246e-12, 1.1225e-12, 1.1291e-12,  ..., 1.3210e-12, 1.3197e-12,\n",
      "         1.3094e-12],\n",
      "        [2.9357e-12, 2.9342e-12, 2.9368e-12,  ..., 3.8434e-12, 3.8283e-12,\n",
      "         3.8272e-12],\n",
      "        [7.3486e-14, 7.3367e-14, 7.2901e-14,  ..., 6.5407e-14, 6.5757e-14,\n",
      "         6.5433e-14],\n",
      "        ...,\n",
      "        [1.8239e-12, 1.8325e-12, 1.8337e-12,  ..., 1.7608e-12, 1.7548e-12,\n",
      "         1.7698e-12],\n",
      "        [1.9890e-13, 2.0235e-13, 2.0028e-13,  ..., 2.2980e-13, 2.2964e-13,\n",
      "         2.3294e-13],\n",
      "        [5.5874e-13, 5.6138e-13, 5.5598e-13,  ..., 4.1066e-13, 4.1371e-13,\n",
      "         4.1321e-13]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Eval Batch 26/26 — OMNI2 Mask Sum: 492480.0 | GOES Mask Sum: 2937816.0 | Density Mask Sum: 2592.0\n",
      "\n",
      "📊 Epoch 56/100 — Train Loss: 4.010501279518843e-05 | Val Loss: 1.7845048625111724e-06\n",
      "Preds: tensor([[ 1.0512e-04,  3.0023e-05,  4.4553e-08,  ...,  7.7815e-09,\n",
      "         -4.1697e-08, -1.1815e-10],\n",
      "        [ 1.0512e-04,  3.0023e-05,  4.4553e-08,  ...,  7.7815e-09,\n",
      "         -4.1697e-08, -1.1815e-10],\n",
      "        [ 1.0512e-04,  3.0023e-05,  4.4553e-08,  ...,  7.7815e-09,\n",
      "         -4.1697e-08, -1.1815e-10],\n",
      "        [ 1.0512e-04,  3.0023e-05,  4.4553e-08,  ...,  7.7815e-09,\n",
      "         -4.1697e-08, -1.1815e-10],\n",
      "        [ 1.0512e-04,  3.0023e-05,  4.4553e-08,  ...,  7.7815e-09,\n",
      "         -4.1697e-08, -1.1815e-10],\n",
      "        [ 1.0512e-04,  3.0023e-05,  4.4553e-08,  ...,  7.7815e-09,\n",
      "         -4.1697e-08, -1.1815e-10]], device='cuda:0')\n",
      "Targets tensor([[4.4862e-14, 4.4614e-14, 4.4473e-14,  ..., 4.3594e-14, 4.3997e-14,\n",
      "         4.4936e-14],\n",
      "        [2.5604e-13, 2.5200e-13, 2.4636e-13,  ..., 1.3770e-13, 1.4635e-13,\n",
      "         1.5376e-13],\n",
      "        [5.1611e-12, 5.1743e-12, 5.1893e-12,  ..., 4.7765e-12, 4.7810e-12,\n",
      "         4.7847e-12],\n",
      "        [1.1828e-12, 1.1794e-12, 1.1814e-12,  ..., 8.5150e-13, 8.3358e-13,\n",
      "         8.3713e-13],\n",
      "        [1.5139e-13, 1.4443e-13, 1.3670e-13,  ..., 1.4753e-13, 1.5153e-13,\n",
      "         1.4713e-13],\n",
      "        [5.6139e-12, 5.6438e-12, 5.6751e-12,  ..., 5.9039e-12, 5.8779e-12,\n",
      "         5.8388e-12]], device='cuda:0')\n",
      "\n",
      "🚀 Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [10:38<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[ 2.0779e-12, -1.4456e-10,  2.6863e-05,  ...,  2.0711e-06,\n",
      "          1.6401e-13,  2.2870e-11],\n",
      "        [ 2.0779e-12, -1.4456e-10,  2.6863e-05,  ...,  2.0711e-06,\n",
      "          1.6401e-13,  2.2870e-11],\n",
      "        [ 2.0779e-12, -1.4456e-10,  2.6863e-05,  ...,  2.0711e-06,\n",
      "          1.6401e-13,  2.2870e-11],\n",
      "        ...,\n",
      "        [ 2.0779e-12, -1.4456e-10,  2.6863e-05,  ...,  2.0711e-06,\n",
      "          1.6401e-13,  2.2870e-11],\n",
      "        [ 2.0779e-12, -1.4456e-10,  2.6863e-05,  ...,  2.0711e-06,\n",
      "          1.6401e-13,  2.2870e-11],\n",
      "        [ 2.0779e-12, -1.4456e-10,  2.6863e-05,  ...,  2.0711e-06,\n",
      "          1.6401e-13,  2.2870e-11]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[1.6811e-12, 1.6908e-12, 1.6995e-12,  ..., 1.8781e-12, 1.8642e-12,\n",
      "         1.8620e-12],\n",
      "        [0.0000e+00, 0.0000e+00, 1.1128e-13,  ..., 9.3501e-14, 9.3720e-14,\n",
      "         9.3006e-14],\n",
      "        [1.9912e-13, 1.9735e-13, 2.0074e-13,  ..., 3.5839e-13, 3.6086e-13,\n",
      "         3.6130e-13],\n",
      "        ...,\n",
      "        [1.9299e-12, 1.9437e-12, 1.9615e-12,  ..., 2.2233e-12, 2.2352e-12,\n",
      "         2.2512e-12],\n",
      "        [1.6373e-12, 1.6478e-12, 1.6578e-12,  ..., 1.9526e-12, 1.9411e-12,\n",
      "         1.9261e-12],\n",
      "        [2.3813e-12, 2.3719e-12, 2.3623e-12,  ..., 1.9380e-12, 1.9446e-12,\n",
      "         1.9606e-12]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Eval Batch 26/26 — OMNI2 Mask Sum: 492480.0 | GOES Mask Sum: 2937816.0 | Density Mask Sum: 2592.0\n",
      "\n",
      "📊 Epoch 57/100 — Train Loss: 4.152396734703923e-05 | Val Loss: 1.338299905630545e-06\n",
      "Preds: tensor([[-3.4966e-12, -1.2845e-10, -3.6174e-05,  ..., -2.6071e-06,\n",
      "         -6.3200e-13,  6.5546e-11],\n",
      "        [-3.4966e-12, -1.2845e-10, -3.6174e-05,  ..., -2.6071e-06,\n",
      "         -6.3200e-13,  6.5546e-11],\n",
      "        [-3.4966e-12, -1.2845e-10, -3.6174e-05,  ..., -2.6071e-06,\n",
      "         -6.3200e-13,  6.5546e-11],\n",
      "        [-3.4966e-12, -1.2845e-10, -3.6174e-05,  ..., -2.6071e-06,\n",
      "         -6.3200e-13,  6.5546e-11],\n",
      "        [-3.4966e-12, -1.2845e-10, -3.6174e-05,  ..., -2.6071e-06,\n",
      "         -6.3200e-13,  6.5546e-11],\n",
      "        [-3.4966e-12, -1.2845e-10, -3.6174e-05,  ..., -2.6071e-06,\n",
      "         -6.3200e-13,  6.5546e-11]], device='cuda:0')\n",
      "Targets tensor([[4.4862e-14, 4.4614e-14, 4.4473e-14,  ..., 4.3594e-14, 4.3997e-14,\n",
      "         4.4936e-14],\n",
      "        [2.5604e-13, 2.5200e-13, 2.4636e-13,  ..., 1.3770e-13, 1.4635e-13,\n",
      "         1.5376e-13],\n",
      "        [5.1611e-12, 5.1743e-12, 5.1893e-12,  ..., 4.7765e-12, 4.7810e-12,\n",
      "         4.7847e-12],\n",
      "        [1.1828e-12, 1.1794e-12, 1.1814e-12,  ..., 8.5150e-13, 8.3358e-13,\n",
      "         8.3713e-13],\n",
      "        [1.5139e-13, 1.4443e-13, 1.3670e-13,  ..., 1.4753e-13, 1.5153e-13,\n",
      "         1.4713e-13],\n",
      "        [5.6139e-12, 5.6438e-12, 5.6751e-12,  ..., 5.9039e-12, 5.8779e-12,\n",
      "         5.8388e-12]], device='cuda:0')\n",
      "✅ Best model updated.\n",
      "\n",
      "🚀 Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [11:40<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[ 5.2249e-12,  3.2832e-12, -4.1971e-07,  ...,  1.0438e-10,\n",
      "          4.6512e-09, -1.7781e-12],\n",
      "        [ 5.2249e-12,  3.2832e-12, -4.1971e-07,  ...,  1.0438e-10,\n",
      "          4.6512e-09, -1.7781e-12],\n",
      "        [ 5.2249e-12,  3.2832e-12, -4.1971e-07,  ...,  1.0438e-10,\n",
      "          4.6512e-09, -1.7781e-12],\n",
      "        ...,\n",
      "        [ 5.2249e-12,  3.2832e-12, -4.1971e-07,  ...,  1.0438e-10,\n",
      "          4.6512e-09, -1.7781e-12],\n",
      "        [ 5.2249e-12,  3.2832e-12, -4.1971e-07,  ...,  1.0438e-10,\n",
      "          4.6512e-09, -1.7781e-12],\n",
      "        [ 5.2249e-12,  3.2832e-12, -4.1971e-07,  ...,  1.0438e-10,\n",
      "          4.6512e-09, -1.7781e-12]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[1.9725e-12, 1.9596e-12, 1.9630e-12,  ..., 1.5673e-12, 1.5709e-12,\n",
      "         1.5605e-12],\n",
      "        [7.0491e-12, 6.9721e-12, 6.9790e-12,  ..., 5.6933e-12, 5.6626e-12,\n",
      "         5.6456e-12],\n",
      "        [6.0201e-13, 5.9181e-13, 5.9217e-13,  ..., 8.5445e-13, 8.3713e-13,\n",
      "         8.3087e-13],\n",
      "        ...,\n",
      "        [1.5037e-12, 1.4994e-12, 1.4964e-12,  ..., 1.2350e-12, 1.2276e-12,\n",
      "         1.2336e-12],\n",
      "        [1.3784e-12, 1.3807e-12, 1.3791e-12,  ..., 1.5000e-12, 1.5307e-12,\n",
      "         1.5939e-12],\n",
      "        [5.5113e-13, 5.4540e-13, 5.3303e-13,  ..., 4.1233e-13, 4.0741e-13,\n",
      "         4.0218e-13]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Eval Batch 26/26 — OMNI2 Mask Sum: 492480.0 | GOES Mask Sum: 2937816.0 | Density Mask Sum: 2592.0\n",
      "\n",
      "📊 Epoch 58/100 — Train Loss: 4.373963074009316e-05 | Val Loss: 1.7226965820345167e-06\n",
      "Preds: tensor([[ 3.5531e-11,  3.1201e-13,  8.3283e-07,  ..., -1.1547e-10,\n",
      "         -2.6463e-08,  2.5776e-12],\n",
      "        [ 3.5531e-11,  3.1201e-13,  8.3283e-07,  ..., -1.1547e-10,\n",
      "         -2.6463e-08,  2.5776e-12],\n",
      "        [ 3.5531e-11,  3.1201e-13,  8.3283e-07,  ..., -1.1547e-10,\n",
      "         -2.6463e-08,  2.5776e-12],\n",
      "        [ 3.5531e-11,  3.1201e-13,  8.3283e-07,  ..., -1.1547e-10,\n",
      "         -2.6463e-08,  2.5776e-12],\n",
      "        [ 3.5531e-11,  3.1201e-13,  8.3283e-07,  ..., -1.1547e-10,\n",
      "         -2.6463e-08,  2.5776e-12],\n",
      "        [ 3.5531e-11,  3.1201e-13,  8.3283e-07,  ..., -1.1547e-10,\n",
      "         -2.6463e-08,  2.5776e-12]], device='cuda:0')\n",
      "Targets tensor([[4.4862e-14, 4.4614e-14, 4.4473e-14,  ..., 4.3594e-14, 4.3997e-14,\n",
      "         4.4936e-14],\n",
      "        [2.5604e-13, 2.5200e-13, 2.4636e-13,  ..., 1.3770e-13, 1.4635e-13,\n",
      "         1.5376e-13],\n",
      "        [5.1611e-12, 5.1743e-12, 5.1893e-12,  ..., 4.7765e-12, 4.7810e-12,\n",
      "         4.7847e-12],\n",
      "        [1.1828e-12, 1.1794e-12, 1.1814e-12,  ..., 8.5150e-13, 8.3358e-13,\n",
      "         8.3713e-13],\n",
      "        [1.5139e-13, 1.4443e-13, 1.3670e-13,  ..., 1.4753e-13, 1.5153e-13,\n",
      "         1.4713e-13],\n",
      "        [5.6139e-12, 5.6438e-12, 5.6751e-12,  ..., 5.9039e-12, 5.8779e-12,\n",
      "         5.8388e-12]], device='cuda:0')\n",
      "\n",
      "🚀 Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [11:36<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[-1.0985e-11, -1.5293e-11, -6.3798e-10,  ..., -1.5607e-07,\n",
      "          9.1072e-12, -2.7382e-04],\n",
      "        [-1.0985e-11, -1.5293e-11, -6.3798e-10,  ..., -1.5607e-07,\n",
      "          9.1072e-12, -2.7382e-04],\n",
      "        [-1.0985e-11, -1.5293e-11, -6.3798e-10,  ..., -1.5607e-07,\n",
      "          9.1072e-12, -2.7382e-04],\n",
      "        ...,\n",
      "        [-1.0985e-11, -1.5293e-11, -6.3798e-10,  ..., -1.5607e-07,\n",
      "          9.1072e-12, -2.7382e-04],\n",
      "        [-1.0985e-11, -1.5293e-11, -6.3798e-10,  ..., -1.5607e-07,\n",
      "          9.1072e-12, -2.7382e-04],\n",
      "        [-1.0985e-11, -1.5293e-11, -6.3798e-10,  ..., -1.5607e-07,\n",
      "          9.1072e-12, -2.7382e-04]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[6.7335e-13, 6.7986e-13, 6.7992e-13,  ..., 5.2204e-13, 5.2113e-13,\n",
      "         5.2052e-13],\n",
      "        [6.6036e-13, 6.5810e-13, 6.6213e-13,  ..., 6.1570e-13, 6.0826e-13,\n",
      "         6.0905e-13],\n",
      "        [7.9057e-14, 7.9076e-14, 7.8099e-14,  ..., 5.6202e-14, 5.7382e-14,\n",
      "         5.7855e-14],\n",
      "        ...,\n",
      "        [3.0697e-12, 3.0651e-12, 3.0710e-12,  ..., 3.6817e-12, 3.6684e-12,\n",
      "         3.6668e-12],\n",
      "        [1.5946e-12, 1.5989e-12, 1.5877e-12,  ..., 2.2621e-12, 2.2602e-12,\n",
      "         2.2534e-12],\n",
      "        [8.4682e-13, 8.5013e-13, 8.4207e-13,  ..., 9.6276e-13, 9.5799e-13,\n",
      "         9.7884e-13]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Eval Batch 26/26 — OMNI2 Mask Sum: 492480.0 | GOES Mask Sum: 2937816.0 | Density Mask Sum: 2592.0\n",
      "\n",
      "📊 Epoch 59/100 — Train Loss: 4.268707819003443e-05 | Val Loss: 1.475283939865991e-06\n",
      "Preds: tensor([[ 8.3873e-12,  1.3181e-12,  1.5478e-10,  ...,  3.0631e-06,\n",
      "         -3.1061e-13, -5.6588e-05],\n",
      "        [ 8.3873e-12,  1.3181e-12,  1.5478e-10,  ...,  3.0631e-06,\n",
      "         -3.1061e-13, -5.6588e-05],\n",
      "        [ 8.3873e-12,  1.3181e-12,  1.5478e-10,  ...,  3.0631e-06,\n",
      "         -3.1061e-13, -5.6588e-05],\n",
      "        [ 8.3873e-12,  1.3181e-12,  1.5478e-10,  ...,  3.0631e-06,\n",
      "         -3.1061e-13, -5.6588e-05],\n",
      "        [ 8.3873e-12,  1.3181e-12,  1.5478e-10,  ...,  3.0631e-06,\n",
      "         -3.1061e-13, -5.6588e-05],\n",
      "        [ 8.3873e-12,  1.3181e-12,  1.5478e-10,  ...,  3.0631e-06,\n",
      "         -3.1061e-13, -5.6588e-05]], device='cuda:0')\n",
      "Targets tensor([[4.4862e-14, 4.4614e-14, 4.4473e-14,  ..., 4.3594e-14, 4.3997e-14,\n",
      "         4.4936e-14],\n",
      "        [2.5604e-13, 2.5200e-13, 2.4636e-13,  ..., 1.3770e-13, 1.4635e-13,\n",
      "         1.5376e-13],\n",
      "        [5.1611e-12, 5.1743e-12, 5.1893e-12,  ..., 4.7765e-12, 4.7810e-12,\n",
      "         4.7847e-12],\n",
      "        [1.1828e-12, 1.1794e-12, 1.1814e-12,  ..., 8.5150e-13, 8.3358e-13,\n",
      "         8.3713e-13],\n",
      "        [1.5139e-13, 1.4443e-13, 1.3670e-13,  ..., 1.4753e-13, 1.5153e-13,\n",
      "         1.4713e-13],\n",
      "        [5.6139e-12, 5.6438e-12, 5.6751e-12,  ..., 5.9039e-12, 5.8779e-12,\n",
      "         5.8388e-12]], device='cuda:0')\n",
      "\n",
      "🚀 Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [10:32<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[-4.7483e-07,  4.3177e-12,  1.1229e-05,  ..., -1.9140e-11,\n",
      "         -6.4577e-06,  8.3682e-05],\n",
      "        [-4.7483e-07,  4.3177e-12,  1.1229e-05,  ..., -1.9140e-11,\n",
      "         -6.4577e-06,  8.3682e-05],\n",
      "        [-4.7483e-07,  4.3177e-12,  1.1229e-05,  ..., -1.9140e-11,\n",
      "         -6.4577e-06,  8.3682e-05],\n",
      "        ...,\n",
      "        [-4.7483e-07,  4.3177e-12,  1.1229e-05,  ..., -1.9140e-11,\n",
      "         -6.4577e-06,  8.3682e-05],\n",
      "        [-4.7483e-07,  4.3177e-12,  1.1229e-05,  ..., -1.9140e-11,\n",
      "         -6.4577e-06,  8.3682e-05],\n",
      "        [-4.7483e-07,  4.3177e-12,  1.1229e-05,  ..., -1.9140e-11,\n",
      "         -6.4577e-06,  8.3682e-05]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[2.2845e-12, 2.2824e-12, 2.2822e-12,  ..., 2.2606e-12, 2.2649e-12,\n",
      "         2.2700e-12],\n",
      "        [4.9319e-13, 4.9739e-13, 4.9370e-13,  ..., 6.2399e-13, 6.2028e-13,\n",
      "         6.2255e-13],\n",
      "        [4.1049e-14, 4.1207e-14, 4.1051e-14,  ..., 4.3869e-14, 4.4330e-14,\n",
      "         4.5563e-14],\n",
      "        ...,\n",
      "        [1.1199e-13, 1.1140e-13, 1.1063e-13,  ..., 1.5422e-13, 1.5497e-13,\n",
      "         1.5625e-13],\n",
      "        [1.1093e-12, 1.1138e-12, 1.1174e-12,  ..., 1.3192e-12, 1.3375e-12,\n",
      "         1.3413e-12],\n",
      "        [8.1675e-12, 8.2478e-12, 8.2392e-12,  ..., 7.1632e-12, 7.1215e-12,\n",
      "         7.0104e-12]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Eval Batch 26/26 — OMNI2 Mask Sum: 492480.0 | GOES Mask Sum: 2937816.0 | Density Mask Sum: 2592.0\n",
      "\n",
      "📊 Epoch 60/100 — Train Loss: 4.265885413153975e-05 | Val Loss: 1.475090427377906e-06\n",
      "Preds: tensor([[ 3.7885e-07,  5.5605e-12, -1.5094e-05,  ..., -1.5534e-11,\n",
      "          1.3663e-05, -2.2944e-05],\n",
      "        [ 3.7885e-07,  5.5605e-12, -1.5094e-05,  ..., -1.5534e-11,\n",
      "          1.3663e-05, -2.2944e-05],\n",
      "        [ 3.7885e-07,  5.5605e-12, -1.5094e-05,  ..., -1.5534e-11,\n",
      "          1.3663e-05, -2.2944e-05],\n",
      "        [ 3.7885e-07,  5.5605e-12, -1.5094e-05,  ..., -1.5534e-11,\n",
      "          1.3663e-05, -2.2944e-05],\n",
      "        [ 3.7885e-07,  5.5605e-12, -1.5094e-05,  ..., -1.5534e-11,\n",
      "          1.3663e-05, -2.2944e-05],\n",
      "        [ 3.7885e-07,  5.5605e-12, -1.5094e-05,  ..., -1.5534e-11,\n",
      "          1.3663e-05, -2.2944e-05]], device='cuda:0')\n",
      "Targets tensor([[4.4862e-14, 4.4614e-14, 4.4473e-14,  ..., 4.3594e-14, 4.3997e-14,\n",
      "         4.4936e-14],\n",
      "        [2.5604e-13, 2.5200e-13, 2.4636e-13,  ..., 1.3770e-13, 1.4635e-13,\n",
      "         1.5376e-13],\n",
      "        [5.1611e-12, 5.1743e-12, 5.1893e-12,  ..., 4.7765e-12, 4.7810e-12,\n",
      "         4.7847e-12],\n",
      "        [1.1828e-12, 1.1794e-12, 1.1814e-12,  ..., 8.5150e-13, 8.3358e-13,\n",
      "         8.3713e-13],\n",
      "        [1.5139e-13, 1.4443e-13, 1.3670e-13,  ..., 1.4753e-13, 1.5153e-13,\n",
      "         1.4713e-13],\n",
      "        [5.6139e-12, 5.6438e-12, 5.6751e-12,  ..., 5.9039e-12, 5.8779e-12,\n",
      "         5.8388e-12]], device='cuda:0')\n",
      "\n",
      "🚀 Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 293/482 [06:32<04:13,  1.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_storm_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_states_normalized\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mtrain_storm_transformer\u001b[39m\u001b[34m(initial_states_df, num_epochs, batch_size, lr, device)\u001b[39m\n\u001b[32m     83\u001b[39m loss.backward()\n\u001b[32m     84\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m total_train_loss += loss.item()\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m#end_batch = time.time()\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# print (\"Load time:\", end_load - start_load )\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# print (\"Calc time:\", end_batch - end_load)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/optim/adam.py:244\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    232\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    234\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    235\u001b[39m         group,\n\u001b[32m    236\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m         state_steps,\n\u001b[32m    242\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/optim/adam.py:876\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    874\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/optim/adam.py:685\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    682\u001b[39m     torch._foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt)\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    684\u001b[39m     bias_correction1 = [\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m         \u001b[32m1\u001b[39m - beta1 ** \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[32m    686\u001b[39m     ]\n\u001b[32m    687\u001b[39m     bias_correction2 = [\n\u001b[32m    688\u001b[39m         \u001b[32m1\u001b[39m - beta2 ** _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[32m    689\u001b[39m     ]\n\u001b[32m    691\u001b[39m     step_size = _stack_if_compiling([(lr / bc) * -\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/optim/optimizer.py:106\u001b[39m, in \u001b[36m_get_value\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_storm_transformer(initial_states_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05500b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7c6865174f50>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "omni2_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "runpod_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
