{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3026e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.transforms as transformers\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import math\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b475574",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states = []\n",
    "\n",
    "path = \"input_data/\"\n",
    "\n",
    "for dir, sub_dir, files in os.walk(path):\n",
    "    for file in sorted(files):\n",
    "        #print(file)\n",
    "        temp = pd.read_csv((path+file),index_col=None, header=0)\n",
    "        initial_states.append(temp)\n",
    "\n",
    "initial_states_df = pd.concat(initial_states,axis=0,ignore_index=True)\n",
    "\n",
    "hold = initial_states_df\n",
    "x = initial_states_df.iloc[:,2:].values\n",
    "x = normalize(x,norm='l2')\n",
    "hold = pd.concat([hold['File ID'],pd.DataFrame(x)],axis=1)\n",
    "initial_states_normalized = hold\n",
    "#'2000-08-02 04:50:33'\n",
    "timestamps = initial_states_df['Timestamp']\n",
    "#initial_states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e980523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullDatasetPT(Dataset):\n",
    "    def __init__(self, initial_states_df, pt_dir='data/processed/pt_files'):\n",
    "        self.data = initial_states_df.reset_index(drop=True)\n",
    "        self.pt_dir = pt_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        file_id = str(int(row['File ID'])).zfill(5)\n",
    "        pt_path = os.path.join(self.pt_dir, f\"{file_id}.pt\")\n",
    "\n",
    "        if not os.path.exists(pt_path):\n",
    "            raise FileNotFoundError(f\".pt file not found for File ID: {file_id}\")\n",
    "\n",
    "        static_input = torch.tensor(row.drop(\"File ID\").fillna(0.0).values, dtype=torch.float32)\n",
    "        pt_data = torch.load(pt_path)\n",
    "\n",
    "        return (\n",
    "            static_input,\n",
    "            pt_data[\"density\"],\n",
    "            pt_data[\"density_mask\"],\n",
    "            pt_data[\"goes\"],\n",
    "            pt_data[\"goes_mask\"],\n",
    "            pt_data[\"omni2\"],\n",
    "            pt_data[\"omni2_mask\"]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd2593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Positional Encoding for Sequences\n",
    "# -----------------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=4320):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000.0) / d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# -----------------------------------\n",
    "# STORMTransformer with Feature Mask Concatenation (No Downsampling)\n",
    "# -----------------------------------\n",
    "class STORMTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 static_dim=9,\n",
    "                 omni2_dim=57,\n",
    "                 goes_dim=42,\n",
    "                 d_model=128,\n",
    "                 output_len=432,\n",
    "                 nhead=8,\n",
    "                 num_layers=4,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "\n",
    "        # Inputs are doubled due to feature-mask concatenation\n",
    "        self.omni2_proj = nn.Linear(omni2_dim * 2, d_model)\n",
    "        self.goes_proj = nn.Linear(goes_dim * 2, d_model)\n",
    "\n",
    "        self.omni2_pos = PositionalEncoding(d_model)\n",
    "        self.goes_pos = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.omni2_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.goes_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # self.fusion = nn.Sequential(\n",
    "        #     nn.Linear(d_model * 3, 256),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(dropout),\n",
    "        #     nn.Linear(256, output_len)\n",
    "        # )\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256,360),\n",
    "            nn.BatchNorm1d(360),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(360, output_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, static_input, omni2_seq, goes_seq, omni2_mask=None, goes_mask=None):\n",
    "        B = static_input.size(0)\n",
    "\n",
    "        # ----- Static Embedding -----\n",
    "        static_embed = self.static_encoder(static_input)\n",
    "\n",
    "        # ----- OMNI2 -----\n",
    "        if omni2_mask is not None:\n",
    "            omni2_cat = torch.cat([omni2_seq, omni2_mask], dim=-1)  # [B, T, 2D]\n",
    "        else:\n",
    "            omni2_cat = omni2_seq\n",
    "        omni2_embed = self.omni2_proj(omni2_cat)\n",
    "        omni2_embed = self.omni2_pos(omni2_embed)\n",
    "        omni2_out = self.omni2_encoder(omni2_embed)  # ‚¨ÖÔ∏è No key mask\n",
    "        omni2_summary = omni2_out.mean(dim=1)\n",
    "\n",
    "        # ----- GOES Downsampling to 8640 -----\n",
    "        if goes_seq.shape[1] > 4320:\n",
    "            step = goes_seq.shape[1] // 4320\n",
    "            goes_seq = goes_seq[:, ::step, :]\n",
    "            goes_mask = goes_mask[:, ::step, :] if goes_mask is not None else None\n",
    "\n",
    "        if goes_mask is not None:\n",
    "            goes_cat = torch.cat([goes_seq, goes_mask], dim=-1)  # [B, T, 2D]\n",
    "        else:\n",
    "            goes_cat = goes_seq\n",
    "        goes_embed = self.goes_proj(goes_cat)\n",
    "        goes_embed = self.goes_pos(goes_embed)\n",
    "        goes_out = self.goes_encoder(goes_embed)  # ‚¨ÖÔ∏è No key mask\n",
    "        goes_summary = goes_out.mean(dim=1)\n",
    "\n",
    "        # ----- Fusion -----\n",
    "        combined = torch.cat((static_embed, omni2_summary, goes_summary), dim=-1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "# -----------------------------------\n",
    "# Masked MSE Loss\n",
    "# -----------------------------------\n",
    "def masked_mse_loss(preds, targets, mask, eps=1e-8):\n",
    "    # preds = torch.nan_to_num(preds, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    # targets = torch.nan_to_num(targets, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    # loss = (preds - targets) ** 2 * mask\n",
    "    # return loss.sum() / (mask.sum() + eps)\n",
    "    diff = (targets - preds) * mask\n",
    "    sq = torch.square(diff)\n",
    "    sum = torch.sum(sq)\n",
    "    N = torch.sum(mask)\n",
    "    # print(sum)\n",
    "    # print(N)\n",
    "    loss = torch.sqrt((sum/N))\n",
    "    return loss\n",
    "\n",
    "# -----------------------------------\n",
    "# Full Training Loop with FullDataset\n",
    "# -----------------------------------\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c7e5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_storm_transformer(initial_states_df, num_epochs=100, batch_size=16, lr=1e-4, device=None):\n",
    "    # from full_dataset import FullDataset\n",
    "    # from storm_transformer import STORMTransformer, masked_mse_loss\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # üîÄ Train/validation split\n",
    "    train_df, val_df = train_test_split(initial_states_df[0:8112], test_size=0.05, random_state=42)\n",
    "\n",
    "    train_dataset = FullDatasetPT(train_df)\n",
    "    val_dataset = FullDatasetPT(val_df)\n",
    "\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True, )\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "\n",
    "    model = STORMTransformer().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    checkpoint_path = \"checkpoints/storm_last.pt\"\n",
    "    best_model_path = \"checkpoints/storm_best.pt\"\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    # üîÅ Resume support\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"üîÅ Resuming from checkpoint: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint.get('epoch', 0)\n",
    "        best_val_loss = checkpoint.get('val_loss', float(\"inf\"))\n",
    "\n",
    "    # üöÄ Training loop\n",
    "    \n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        print(f\"\\nüöÄ Epoch {epoch + 1}/{num_epochs}\")\n",
    "        #start_load = time.time()\n",
    "        for batch in tqdm(train_loader):\n",
    "            static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = batch\n",
    "            #nd_load = time.time()\n",
    "\n",
    "            static_input = static_input.to(device)\n",
    "            density = density.to(device)\n",
    "            density_mask = density_mask.to(device)\n",
    "            goes = goes.to(device)\n",
    "            goes_mask = goes_mask.to(device)\n",
    "            omni2 = omni2.to(device)\n",
    "            omni2_mask = omni2_mask.to(device)\n",
    "\n",
    "            # if (omni2_mask.any(dim=-1).sum(dim=1) == 0).any() or (goes_mask.any(dim=-1).sum(dim=1) == 0).any():\n",
    "            #     print(\"‚ö†Ô∏è Skipping batch with fully masked inputs\")\n",
    "            #     continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "            # print (\"Preds:\", preds)\n",
    "            # print (\"Targets\",density)\n",
    "            #print (preds)\n",
    "            loss = masked_mse_loss(preds, density, density_mask)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            #end_batch = time.time()\n",
    "\n",
    "            # print (\"Load time:\", end_load - start_load )\n",
    "            # print (\"Calc time:\", end_batch - end_load)\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        print (\"Preds:\", preds)\n",
    "        print (\"Targets\",density)\n",
    "\n",
    "        # üß™ Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = batch\n",
    "\n",
    "                static_input = static_input.to(device)\n",
    "                density = density.to(device)\n",
    "                density_mask = density_mask.to(device)\n",
    "                goes = goes.to(device)\n",
    "                goes_mask = goes_mask.to(device)\n",
    "                omni2 = omni2.to(device)\n",
    "                omni2_mask = omni2_mask.to(device)\n",
    "\n",
    "                if (omni2_mask.any(dim=-1).sum(dim=1) == 0).any() or (goes_mask.any(dim=-1).sum(dim=1) == 0).any():\n",
    "                    continue\n",
    "\n",
    "                preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "                loss = masked_mse_loss(preds, density, density_mask)\n",
    "                #print (\"loss\",loss,\"-------------------\")\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # üß† Mask diagnostics\n",
    "                goes_mask_sum = goes_mask.sum().item()\n",
    "                omni2_mask_sum = omni2_mask.sum().item()\n",
    "                density_mask_sum = density_mask.sum().item()\n",
    "\n",
    "                print(f\"üß™ Eval Batch {batch_idx+1}/{len(val_loader)} ‚Äî \"\n",
    "                      f\"OMNI2 Mask Sum: {omni2_mask_sum} | \"\n",
    "                      f\"GOES Mask Sum: {goes_mask_sum} | \"\n",
    "                      f\"Density Mask Sum: {density_mask_sum}\")\n",
    "\n",
    "                # ‚ö†Ô∏è Alert if any mask has < 10% coverage\n",
    "                if omni2_mask_sum < 0.1 * omni2_mask.numel():\n",
    "                    print(\"‚ö†Ô∏è Low OMNI2 coverage in this batch!\")\n",
    "                if goes_mask_sum < 0.1 * goes_mask.numel():\n",
    "                    print(\"‚ö†Ô∏è Low GOES coverage in this batch!\")\n",
    "                if density_mask_sum < 0.1 * density_mask.numel():\n",
    "                    print(\"‚ö†Ô∏è Low density mask coverage in this batch!\")\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"\\nüìä Epoch {epoch+1}/{num_epochs} ‚Äî \"\n",
    "              f\"Train Loss: {avg_train_loss} | Val Loss: {avg_val_loss}\")\n",
    "        \n",
    "        print (\"Preds:\", preds)\n",
    "        print (\"Targets\",density)\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "\n",
    "        # üíæ Save full checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': avg_val_loss\n",
    "        }, checkpoint_path)\n",
    "\n",
    "        # üíé Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), f\"checkpoints/epoch{epoch}.pt\")\n",
    "            print(\"‚úÖ Best model updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f393f7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Resuming from checkpoint: checkpoints/storm_last.pt\n",
      "\n",
      "üöÄ Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 482/482 [09:53<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[ 2.3265e-06, -5.3633e-09, -1.6582e-08,  ..., -3.3427e-07,\n",
      "         -1.4046e-04, -1.0738e-04],\n",
      "        [ 2.3265e-06, -5.3633e-09, -1.6582e-08,  ..., -3.3427e-07,\n",
      "         -1.4046e-04, -1.0738e-04],\n",
      "        [ 2.3265e-06, -5.3633e-09, -1.6582e-08,  ..., -3.3427e-07,\n",
      "         -1.4046e-04, -1.0738e-04],\n",
      "        ...,\n",
      "        [ 2.3265e-06, -5.3633e-09, -1.6582e-08,  ..., -3.3427e-07,\n",
      "         -1.4046e-04, -1.0738e-04],\n",
      "        [ 2.3265e-06, -5.3633e-09, -1.6582e-08,  ..., -3.3427e-07,\n",
      "         -1.4046e-04, -1.0738e-04],\n",
      "        [ 2.3265e-06, -5.3633e-09, -1.6582e-08,  ..., -3.3427e-07,\n",
      "         -1.4046e-04, -1.0738e-04]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[2.5025e-12, 2.4971e-12, 2.4794e-12,  ..., 2.2223e-12, 2.2103e-12,\n",
      "         2.1908e-12],\n",
      "        [2.5089e-13, 2.4738e-13, 2.3532e-13,  ..., 1.5317e-13, 1.5665e-13,\n",
      "         1.6073e-13],\n",
      "        [3.9850e-14, 3.9678e-14, 3.9931e-14,  ..., 4.1768e-14, 4.1275e-14,\n",
      "         4.0817e-14],\n",
      "        ...,\n",
      "        [2.0094e-12, 1.9983e-12, 2.0053e-12,  ..., 2.1086e-12, 2.1199e-12,\n",
      "         2.1352e-12],\n",
      "        [1.8044e-12, 1.7846e-12, 1.7676e-12,  ..., 1.9887e-12, 2.0033e-12,\n",
      "         1.9992e-12],\n",
      "        [3.6922e-13, 3.6684e-13, 3.6274e-13,  ..., 1.8311e-13, 1.8140e-13,\n",
      "         1.8035e-13]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Eval Batch 26/26 ‚Äî OMNI2 Mask Sum: 492480.0 | GOES Mask Sum: 2937816.0 | Density Mask Sum: 2592.0\n",
      "\n",
      "üìä Epoch 49/100 ‚Äî Train Loss: 0.002417708924368673 | Val Loss: 6.043646359243072e-05\n",
      "Preds: tensor([[ 1.9414e-07,  3.5270e-08,  1.1203e-08,  ...,  3.4790e-07,\n",
      "          1.8851e-04, -2.8156e-05],\n",
      "        [ 1.9414e-07,  3.5270e-08,  1.1203e-08,  ...,  3.4790e-07,\n",
      "          1.8851e-04, -2.8156e-05],\n",
      "        [ 1.9414e-07,  3.5270e-08,  1.1203e-08,  ...,  3.4790e-07,\n",
      "          1.8851e-04, -2.8156e-05],\n",
      "        [ 1.9414e-07,  3.5270e-08,  1.1203e-08,  ...,  3.4790e-07,\n",
      "          1.8851e-04, -2.8156e-05],\n",
      "        [ 1.9414e-07,  3.5270e-08,  1.1203e-08,  ...,  3.4790e-07,\n",
      "          1.8851e-04, -2.8156e-05],\n",
      "        [ 1.9414e-07,  3.5270e-08,  1.1203e-08,  ...,  3.4790e-07,\n",
      "          1.8851e-04, -2.8156e-05]], device='cuda:0')\n",
      "Targets tensor([[4.4862e-14, 4.4614e-14, 4.4473e-14,  ..., 4.3594e-14, 4.3997e-14,\n",
      "         4.4936e-14],\n",
      "        [2.5604e-13, 2.5200e-13, 2.4636e-13,  ..., 1.3770e-13, 1.4635e-13,\n",
      "         1.5376e-13],\n",
      "        [5.1611e-12, 5.1743e-12, 5.1893e-12,  ..., 4.7765e-12, 4.7810e-12,\n",
      "         4.7847e-12],\n",
      "        [1.1828e-12, 1.1794e-12, 1.1814e-12,  ..., 8.5150e-13, 8.3358e-13,\n",
      "         8.3713e-13],\n",
      "        [1.5139e-13, 1.4443e-13, 1.3670e-13,  ..., 1.4753e-13, 1.5153e-13,\n",
      "         1.4713e-13],\n",
      "        [5.6139e-12, 5.6438e-12, 5.6751e-12,  ..., 5.9039e-12, 5.8779e-12,\n",
      "         5.8388e-12]], device='cuda:0')\n",
      "\n",
      "üöÄ Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 482/482 [09:51<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[ 1.8771e-04, -1.0736e-07,  9.2092e-06,  ...,  5.6571e-04,\n",
      "         -2.6376e-07,  3.1027e-05],\n",
      "        [ 1.8771e-04, -1.0736e-07,  9.2092e-06,  ...,  5.6571e-04,\n",
      "         -2.6376e-07,  3.1027e-05],\n",
      "        [ 1.8771e-04, -1.0736e-07,  9.2092e-06,  ...,  5.6571e-04,\n",
      "         -2.6376e-07,  3.1027e-05],\n",
      "        ...,\n",
      "        [ 1.8771e-04, -1.0736e-07,  9.2092e-06,  ...,  5.6571e-04,\n",
      "         -2.6376e-07,  3.1027e-05],\n",
      "        [ 1.8771e-04, -1.0736e-07,  9.2092e-06,  ...,  5.6571e-04,\n",
      "         -2.6376e-07,  3.1027e-05],\n",
      "        [ 1.8771e-04, -1.0736e-07,  9.2092e-06,  ...,  5.6571e-04,\n",
      "         -2.6376e-07,  3.1027e-05]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[1.1246e-12, 1.1225e-12, 1.1291e-12,  ..., 1.3210e-12, 1.3197e-12,\n",
      "         1.3094e-12],\n",
      "        [2.9357e-12, 2.9342e-12, 2.9368e-12,  ..., 3.8434e-12, 3.8283e-12,\n",
      "         3.8272e-12],\n",
      "        [7.3486e-14, 7.3367e-14, 7.2901e-14,  ..., 6.5407e-14, 6.5757e-14,\n",
      "         6.5433e-14],\n",
      "        ...,\n",
      "        [1.8239e-12, 1.8325e-12, 1.8337e-12,  ..., 1.7608e-12, 1.7548e-12,\n",
      "         1.7698e-12],\n",
      "        [1.9890e-13, 2.0235e-13, 2.0028e-13,  ..., 2.2980e-13, 2.2964e-13,\n",
      "         2.3294e-13],\n",
      "        [5.5874e-13, 5.6138e-13, 5.5598e-13,  ..., 4.1066e-13, 4.1371e-13,\n",
      "         4.1321e-13]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Eval Batch 26/26 ‚Äî OMNI2 Mask Sum: 492480.0 | GOES Mask Sum: 2937816.0 | Density Mask Sum: 2592.0\n",
      "\n",
      "üìä Epoch 50/100 ‚Äî Train Loss: 0.0019986364433514842 | Val Loss: 7.209267306069915e-05\n",
      "Preds: tensor([[-2.8804e-04,  9.1942e-08, -1.1362e-05,  ..., -5.8239e-04,\n",
      "          2.0854e-07, -1.0114e-04],\n",
      "        [-2.8804e-04,  9.1942e-08, -1.1362e-05,  ..., -5.8239e-04,\n",
      "          2.0854e-07, -1.0114e-04],\n",
      "        [-2.8804e-04,  9.1942e-08, -1.1362e-05,  ..., -5.8239e-04,\n",
      "          2.0854e-07, -1.0114e-04],\n",
      "        [-2.8804e-04,  9.1942e-08, -1.1362e-05,  ..., -5.8239e-04,\n",
      "          2.0854e-07, -1.0114e-04],\n",
      "        [-2.8804e-04,  9.1942e-08, -1.1362e-05,  ..., -5.8239e-04,\n",
      "          2.0854e-07, -1.0114e-04],\n",
      "        [-2.8804e-04,  9.1942e-08, -1.1362e-05,  ..., -5.8239e-04,\n",
      "          2.0854e-07, -1.0114e-04]], device='cuda:0')\n",
      "Targets tensor([[4.4862e-14, 4.4614e-14, 4.4473e-14,  ..., 4.3594e-14, 4.3997e-14,\n",
      "         4.4936e-14],\n",
      "        [2.5604e-13, 2.5200e-13, 2.4636e-13,  ..., 1.3770e-13, 1.4635e-13,\n",
      "         1.5376e-13],\n",
      "        [5.1611e-12, 5.1743e-12, 5.1893e-12,  ..., 4.7765e-12, 4.7810e-12,\n",
      "         4.7847e-12],\n",
      "        [1.1828e-12, 1.1794e-12, 1.1814e-12,  ..., 8.5150e-13, 8.3358e-13,\n",
      "         8.3713e-13],\n",
      "        [1.5139e-13, 1.4443e-13, 1.3670e-13,  ..., 1.4753e-13, 1.5153e-13,\n",
      "         1.4713e-13],\n",
      "        [5.6139e-12, 5.6438e-12, 5.6751e-12,  ..., 5.9039e-12, 5.8779e-12,\n",
      "         5.8388e-12]], device='cuda:0')\n",
      "\n",
      "üöÄ Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 482/482 [09:53<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[ 1.9683e-03, -1.0872e-11,  4.8848e-04,  ...,  5.8848e-07,\n",
      "         -1.3799e-11,  1.4515e-07],\n",
      "        [ 1.9683e-03, -1.0872e-11,  4.8848e-04,  ...,  5.8848e-07,\n",
      "         -1.3799e-11,  1.4515e-07],\n",
      "        [ 1.9683e-03, -1.0872e-11,  4.8848e-04,  ...,  5.8848e-07,\n",
      "         -1.3799e-11,  1.4515e-07],\n",
      "        ...,\n",
      "        [ 1.9683e-03, -1.0872e-11,  4.8848e-04,  ...,  5.8848e-07,\n",
      "         -1.3799e-11,  1.4515e-07],\n",
      "        [ 1.9683e-03, -1.0872e-11,  4.8848e-04,  ...,  5.8848e-07,\n",
      "         -1.3799e-11,  1.4515e-07],\n",
      "        [ 1.9683e-03, -1.0872e-11,  4.8848e-04,  ...,  5.8848e-07,\n",
      "         -1.3799e-11,  1.4515e-07]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Targets tensor([[1.6811e-12, 1.6908e-12, 1.6995e-12,  ..., 1.8781e-12, 1.8642e-12,\n",
      "         1.8620e-12],\n",
      "        [0.0000e+00, 0.0000e+00, 1.1128e-13,  ..., 9.3501e-14, 9.3720e-14,\n",
      "         9.3006e-14],\n",
      "        [1.9912e-13, 1.9735e-13, 2.0074e-13,  ..., 3.5839e-13, 3.6086e-13,\n",
      "         3.6130e-13],\n",
      "        ...,\n",
      "        [1.9299e-12, 1.9437e-12, 1.9615e-12,  ..., 2.2233e-12, 2.2352e-12,\n",
      "         2.2512e-12],\n",
      "        [1.6373e-12, 1.6478e-12, 1.6578e-12,  ..., 1.9526e-12, 1.9411e-12,\n",
      "         1.9261e-12],\n",
      "        [2.3813e-12, 2.3719e-12, 2.3623e-12,  ..., 1.9380e-12, 1.9446e-12,\n",
      "         1.9606e-12]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Eval Batch 26/26 ‚Äî OMNI2 Mask Sum: 492480.0 | GOES Mask Sum: 2937816.0 | Density Mask Sum: 2592.0\n",
      "\n",
      "üìä Epoch 51/100 ‚Äî Train Loss: 0.0021143126994887314 | Val Loss: 0.00010808909204430305\n",
      "Preds: tensor([[-1.3614e-03, -2.9666e-11, -1.3412e-05,  ..., -2.1639e-06,\n",
      "          1.1848e-11, -1.4201e-07],\n",
      "        [-1.3614e-03, -2.9666e-11, -1.3412e-05,  ..., -2.1639e-06,\n",
      "          1.1848e-11, -1.4201e-07],\n",
      "        [-1.3614e-03, -2.9666e-11, -1.3412e-05,  ..., -2.1639e-06,\n",
      "          1.1848e-11, -1.4201e-07],\n",
      "        [-1.3614e-03, -2.9666e-11, -1.3412e-05,  ..., -2.1639e-06,\n",
      "          1.1848e-11, -1.4201e-07],\n",
      "        [-1.3614e-03, -2.9666e-11, -1.3412e-05,  ..., -2.1639e-06,\n",
      "          1.1848e-11, -1.4201e-07],\n",
      "        [-1.3614e-03, -2.9666e-11, -1.3412e-05,  ..., -2.1639e-06,\n",
      "          1.1848e-11, -1.4201e-07]], device='cuda:0')\n",
      "Targets tensor([[4.4862e-14, 4.4614e-14, 4.4473e-14,  ..., 4.3594e-14, 4.3997e-14,\n",
      "         4.4936e-14],\n",
      "        [2.5604e-13, 2.5200e-13, 2.4636e-13,  ..., 1.3770e-13, 1.4635e-13,\n",
      "         1.5376e-13],\n",
      "        [5.1611e-12, 5.1743e-12, 5.1893e-12,  ..., 4.7765e-12, 4.7810e-12,\n",
      "         4.7847e-12],\n",
      "        [1.1828e-12, 1.1794e-12, 1.1814e-12,  ..., 8.5150e-13, 8.3358e-13,\n",
      "         8.3713e-13],\n",
      "        [1.5139e-13, 1.4443e-13, 1.3670e-13,  ..., 1.4753e-13, 1.5153e-13,\n",
      "         1.4713e-13],\n",
      "        [5.6139e-12, 5.6438e-12, 5.6751e-12,  ..., 5.9039e-12, 5.8779e-12,\n",
      "         5.8388e-12]], device='cuda:0')\n",
      "\n",
      "üöÄ Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|‚ñà         | 53/482 [01:15<10:07,  1.42s/it] \n",
      "Exception in thread Thread-125 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 59, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 35, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/multiprocessing/connection.py\", line 519, in Client\n",
      "    c = SocketClient(address)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_storm_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_states_normalized\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mtrain_storm_transformer\u001b[39m\u001b[34m(initial_states_df, num_epochs, batch_size, lr, device)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müöÄ Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m#start_load = time.time()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#nd_load = time.time()\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1458\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1461\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1410\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1408\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1409\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1410\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1411\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1412\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1251\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1239\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1248\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1254\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1256\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_storm_transformer(initial_states_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05500b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe25efef290>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_loss_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "runpod_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
