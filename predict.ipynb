{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee09069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.transforms as transformers\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import math\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f440e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "omni2_scaler = joblib.load(\"omni2_scaler.gz\") \n",
    "goes_scaler = joblib.load(\"goes_scaler.gz\") \n",
    "initial_states_scaler = joblib.load(\"initial_states_scaler.gz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "289e0e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>File ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-08-02 04:50:33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800022</td>\n",
       "      <td>0.410931</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.400407</td>\n",
       "      <td>0.714733</td>\n",
       "      <td>0.284494</td>\n",
       "      <td>0.745053</td>\n",
       "      <td>0.326270</td>\n",
       "      <td>0.895052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-08-03 19:51:01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799765</td>\n",
       "      <td>0.410666</td>\n",
       "      <td>0.015691</td>\n",
       "      <td>0.398725</td>\n",
       "      <td>0.695626</td>\n",
       "      <td>0.303640</td>\n",
       "      <td>0.743967</td>\n",
       "      <td>0.695028</td>\n",
       "      <td>0.889269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-08-05 05:40:05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.770871</td>\n",
       "      <td>0.435522</td>\n",
       "      <td>0.013965</td>\n",
       "      <td>0.397176</td>\n",
       "      <td>0.679259</td>\n",
       "      <td>0.319940</td>\n",
       "      <td>0.610945</td>\n",
       "      <td>0.790582</td>\n",
       "      <td>0.904985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-08-06 05:02:20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.770750</td>\n",
       "      <td>0.437655</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>0.396165</td>\n",
       "      <td>0.669874</td>\n",
       "      <td>0.329406</td>\n",
       "      <td>0.569862</td>\n",
       "      <td>0.812033</td>\n",
       "      <td>0.902606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-08-08 20:54:57</td>\n",
       "      <td>4</td>\n",
       "      <td>0.769970</td>\n",
       "      <td>0.442368</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.393378</td>\n",
       "      <td>0.635436</td>\n",
       "      <td>0.363969</td>\n",
       "      <td>0.450618</td>\n",
       "      <td>0.137236</td>\n",
       "      <td>0.899777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>2019-12-25 00:00:00</td>\n",
       "      <td>8114</td>\n",
       "      <td>0.535067</td>\n",
       "      <td>0.607103</td>\n",
       "      <td>0.159052</td>\n",
       "      <td>0.284968</td>\n",
       "      <td>0.668307</td>\n",
       "      <td>0.521740</td>\n",
       "      <td>0.890529</td>\n",
       "      <td>0.801062</td>\n",
       "      <td>0.851842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>2019-12-27 00:00:00</td>\n",
       "      <td>8115</td>\n",
       "      <td>0.690987</td>\n",
       "      <td>0.229441</td>\n",
       "      <td>0.847954</td>\n",
       "      <td>0.277111</td>\n",
       "      <td>0.423743</td>\n",
       "      <td>0.628984</td>\n",
       "      <td>0.613536</td>\n",
       "      <td>0.776649</td>\n",
       "      <td>0.835652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>2019-12-28 00:00:00</td>\n",
       "      <td>8116</td>\n",
       "      <td>0.711425</td>\n",
       "      <td>0.203270</td>\n",
       "      <td>0.936350</td>\n",
       "      <td>0.269214</td>\n",
       "      <td>0.120393</td>\n",
       "      <td>0.364463</td>\n",
       "      <td>0.523885</td>\n",
       "      <td>0.269405</td>\n",
       "      <td>0.837877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8117</th>\n",
       "      <td>2019-12-30 00:00:00</td>\n",
       "      <td>8117</td>\n",
       "      <td>0.575161</td>\n",
       "      <td>0.506746</td>\n",
       "      <td>0.338160</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.890747</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>0.801671</td>\n",
       "      <td>0.252504</td>\n",
       "      <td>0.847061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>2019-12-31 00:00:00</td>\n",
       "      <td>8118</td>\n",
       "      <td>0.514594</td>\n",
       "      <td>0.950478</td>\n",
       "      <td>0.066051</td>\n",
       "      <td>0.257084</td>\n",
       "      <td>0.276716</td>\n",
       "      <td>0.502326</td>\n",
       "      <td>0.060708</td>\n",
       "      <td>0.723779</td>\n",
       "      <td>0.888823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8119 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  File ID         0         1         2         3  \\\n",
       "0     2000-08-02 04:50:33        0  0.800022  0.410931  0.015596  0.400407   \n",
       "1     2000-08-03 19:51:01        1  0.799765  0.410666  0.015691  0.398725   \n",
       "2     2000-08-05 05:40:05        2  0.770871  0.435522  0.013965  0.397176   \n",
       "3     2000-08-06 05:02:20        3  0.770750  0.437655  0.013863  0.396165   \n",
       "4     2000-08-08 20:54:57        4  0.769970  0.442368  0.012990  0.393378   \n",
       "...                   ...      ...       ...       ...       ...       ...   \n",
       "8114  2019-12-25 00:00:00     8114  0.535067  0.607103  0.159052  0.284968   \n",
       "8115  2019-12-27 00:00:00     8115  0.690987  0.229441  0.847954  0.277111   \n",
       "8116  2019-12-28 00:00:00     8116  0.711425  0.203270  0.936350  0.269214   \n",
       "8117  2019-12-30 00:00:00     8117  0.575161  0.506746  0.338160  0.257812   \n",
       "8118  2019-12-31 00:00:00     8118  0.514594  0.950478  0.066051  0.257084   \n",
       "\n",
       "             4         5         6         7         8  \n",
       "0     0.714733  0.284494  0.745053  0.326270  0.895052  \n",
       "1     0.695626  0.303640  0.743967  0.695028  0.889269  \n",
       "2     0.679259  0.319940  0.610945  0.790582  0.904985  \n",
       "3     0.669874  0.329406  0.569862  0.812033  0.902606  \n",
       "4     0.635436  0.363969  0.450618  0.137236  0.899777  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "8114  0.668307  0.521740  0.890529  0.801062  0.851842  \n",
       "8115  0.423743  0.628984  0.613536  0.776649  0.835652  \n",
       "8116  0.120393  0.364463  0.523885  0.269405  0.837877  \n",
       "8117  0.890747  0.457447  0.801671  0.252504  0.847061  \n",
       "8118  0.276716  0.502326  0.060708  0.723779  0.888823  \n",
       "\n",
       "[8119 rows x 11 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_states = []\n",
    "\n",
    "path = \"input_data/\"\n",
    "\n",
    "for dir, sub_dir, files in os.walk(path):\n",
    "    for file in sorted(files):\n",
    "        #print(file)\n",
    "        temp = pd.read_csv((path+file),index_col=None, header=0)\n",
    "        initial_states.append(temp)\n",
    "\n",
    "initial_states_df = pd.concat(initial_states,axis=0,ignore_index=True)\n",
    "\n",
    "initial_states_norm_df = np.where(initial_states_df.iloc[:,2:] > 1e+10,0.0, initial_states_df.iloc[:,2:])\n",
    "\n",
    "initial_states_scaler = MinMaxScaler()\n",
    "initial_states_scaler_values = initial_states_scaler.fit(initial_states_norm_df)\n",
    "\n",
    "initial_states_normalized = initial_states_scaler_values.transform(initial_states_df.iloc[:,2:].values)\n",
    "\n",
    "initial_states_normalized = np.where(initial_states_normalized >=1, 0.99,initial_states_normalized)\n",
    "\n",
    "initial_states_normalized = pd.concat([initial_states_df['Timestamp'],initial_states_df['File ID'],pd.DataFrame(initial_states_normalized)],axis=1)\n",
    "\n",
    "initial_states_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3363f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullDataset(Dataset):\n",
    "    def __init__(self, initial_states_df, density_length=432, goes_length=86400, omni2_length=1440, density_dir='data/dataset/test/sat_density', goes_dir=\"data/dataset/test/goes\",\n",
    "                 omni2_dir=\"data/dataset/test/omni2\"):\n",
    "        self.data = initial_states_df.reset_index(drop=True)\n",
    "        self.density_dir = density_dir\n",
    "        self.goes_dir = goes_dir\n",
    "        self.omni2_dir = omni2_dir\n",
    "        self.density_length = density_length\n",
    "        self.goes_length = goes_length\n",
    "        self.omni2_length = omni2_length\n",
    "        #self.timestamps = initial_states_df['Timestamps']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        ts = row['Timestamp']\n",
    "        #print (ts)\n",
    "        static_input = row.drop('Timestamp')\n",
    "        static_input = torch.tensor(row.drop('File ID').fillna(0.0).values, dtype=torch.float32)\n",
    "        print (static_input)\n",
    "        \n",
    "        file_id = str(int(row['File ID'])).zfill(5)\n",
    "        \n",
    "        density_file = glob.glob(os.path.join(self.density_dir, f\"*-{file_id}-*.csv\"))\n",
    "        goes_file = glob.glob(os.path.join(self.goes_dir, f\"*-{file_id}-*.csv\"))\n",
    "        omni2_file = glob.glob(os.path.join(self.omni2_dir, f\"*-{file_id}-*.csv\"))\n",
    "\n",
    "        pos = len(self.density_dir)+1\n",
    "        density_sat = density_file[0][pos:pos+6]\n",
    "\n",
    "        density_df = ((pd.read_csv(density_file[0])))\n",
    "        density_df['Orbit Mean Density (kg/m^3)'] = np.where(density_df['Orbit Mean Density (kg/m^3)']>=1,np.nan,density_df['Orbit Mean Density (kg/m^3)'])\n",
    "        if density_df.shape[0] > self.density_length:\n",
    "            density_df = density_df[:self.density_length]\n",
    "        elif density_df.shape[0] < self.density_length:\n",
    "            padding = pd.DataFrame(np.empty((self.density_length-density_df.shape[0],2)),columns=density_df.columns)\n",
    "            padding[:] = np.nan\n",
    "            density_df = pd.concat((density_df,padding),ignore_index=True)\n",
    "        density_df_mask = (pd.notnull(density_df)).astype(int)\n",
    "        density_tensor = torch.tensor(density_df['Orbit Mean Density (kg/m^3)'].fillna(0.0).values, dtype=torch.float32)\n",
    "        density_df_mask_tensor = torch.tensor(density_df_mask.iloc[:,1].values, dtype=torch.float32)\n",
    "        density_stacked = torch.stack((density_tensor,density_df_mask_tensor))\n",
    "\n",
    "        goes_df = pd.read_csv(goes_file[0])\n",
    "        if goes_df.shape[0] > self.goes_length:\n",
    "            goes_df = goes_df[goes_df.shape[0]-self.goes_length:goes_df.shape[0]]\n",
    "        elif goes_df.shape[0] < self.goes_length:\n",
    "            padding = pd.DataFrame(np.empty((self.goes_length-goes_df.shape[0],43)),columns=goes_df.columns)\n",
    "            padding[:] = np.nan\n",
    "            goes_df = pd.concat((padding,goes_df),ignore_index=True)\n",
    "        goes_mask = (~pd.isnull(goes_df)).astype(int)\n",
    "        goes_valid_mask = ((goes_df['xrsa_flag'] == 0.0) & (goes_df['xrsb_flag'] == 0.0)).astype(int)\n",
    "        goes_mask = goes_mask.mul(goes_valid_mask.values,axis=0)\n",
    "        goes_tensor = torch.tensor(normalize(goes_df.iloc[:, 1:].fillna(0.0).values, norm='l2'), dtype=torch.float32)\n",
    "        goes_mask_tensor = torch.tensor(goes_mask.iloc[:, 1:].values, dtype=torch.float32)\n",
    "        #goes_stacked = torch.stack((goes_tensor,goes_mask_tensor))\n",
    "        \n",
    "        omni2_df = pd.read_csv(omni2_file[0])\n",
    "        if omni2_df.shape[0] > self.omni2_length:\n",
    "            omni2_df = omni2_df[omni2_df.shape[0]-self.omni2_length:omni2_df.shape[0]]\n",
    "        elif goes_df.shape[0] < self.omni2_length:\n",
    "            padding = pd.DataFrame(np.empty((self.omni2_length-omni2_df.shape[0],58)),columns=omni2_df.columns)\n",
    "            padding[:] = np.nan\n",
    "            omni2_df = pd.concat((padding,omni2_df),ignore_index=True)\n",
    "        omni2_tensor = torch.tensor(normalize(omni2_df.iloc[:, :57].fillna(0.0).values.astype(float), norm='l2'), dtype=torch.float32)\n",
    "        omni2_mask = (~pd.isnull(omni2_df)).astype(int)\n",
    "        omni2_mask_tensor = torch.tensor(omni2_mask.iloc[:, :57].values, dtype=torch.float32) \n",
    "        omni2_stacked = torch.stack((omni2_tensor,omni2_mask_tensor))\n",
    "\n",
    "        return static_input, density_tensor, density_df_mask_tensor, goes_tensor, goes_mask_tensor, omni2_tensor, omni2_mask_tensor, ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61137100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Positional Encoding for Sequences\n",
    "# -----------------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=4320):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000.0) / d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# -----------------------------------\n",
    "# STORMTransformer with Feature Mask Concatenation (No Downsampling)\n",
    "# -----------------------------------\n",
    "class STORMTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 static_dim=9,\n",
    "                 omni2_dim=57,\n",
    "                 goes_dim=42,\n",
    "                 d_model=128,\n",
    "                 output_len=432,\n",
    "                 nhead=8,\n",
    "                 num_layers=4,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "\n",
    "        # Inputs are doubled due to feature-mask concatenation\n",
    "        self.omni2_proj = nn.Linear(omni2_dim * 2, d_model)\n",
    "        self.goes_proj = nn.Linear(goes_dim * 2, d_model)\n",
    "\n",
    "        self.omni2_pos = PositionalEncoding(d_model)\n",
    "        self.goes_pos = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.omni2_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.goes_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # self.fusion = nn.Sequential(\n",
    "        #     nn.Linear(d_model * 3, 256),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(dropout),\n",
    "        #     nn.Linear(256, output_len)\n",
    "        # )\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256,360),\n",
    "            nn.BatchNorm1d(360),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(360, output_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, static_input, omni2_seq, goes_seq, omni2_mask=None, goes_mask=None):\n",
    "        B = static_input.size(0)\n",
    "\n",
    "        # ----- Static Embedding -----\n",
    "        #print(\"static input\",static_input)\n",
    "        static_embed = self.static_encoder(static_input)\n",
    "        #print(\"static embed\", static_embed)\n",
    "\n",
    "        # ----- OMNI2 -----\n",
    "        if omni2_mask is not None:\n",
    "            omni2_cat = torch.cat([omni2_seq, omni2_mask], dim=-1)  # [B, T, 2D]\n",
    "        else:\n",
    "            omni2_cat = omni2_seq\n",
    "        omni2_embed = self.omni2_proj(omni2_cat)\n",
    "        omni2_embed = self.omni2_pos(omni2_embed)\n",
    "        omni2_out = self.omni2_encoder(omni2_embed)  # ⬅️ No key mask\n",
    "        omni2_summary = omni2_out.mean(dim=1)\n",
    "\n",
    "        # ----- GOES Downsampling to 8640 -----\n",
    "        if goes_seq.shape[1] > 4320:\n",
    "            step = goes_seq.shape[1] // 4320\n",
    "            goes_seq = goes_seq[:, ::step, :]\n",
    "            goes_mask = goes_mask[:, ::step, :] if goes_mask is not None else None\n",
    "\n",
    "        if goes_mask is not None:\n",
    "            goes_cat = torch.cat([goes_seq, goes_mask], dim=-1)  # [B, T, 2D]\n",
    "        else:\n",
    "            goes_cat = goes_seq\n",
    "        goes_embed = self.goes_proj(goes_cat)\n",
    "        goes_embed = self.goes_pos(goes_embed)\n",
    "        goes_out = self.goes_encoder(goes_embed)  # ⬅️ No key mask\n",
    "        goes_summary = goes_out.mean(dim=1)\n",
    "\n",
    "        # print(\"static\",static_embed)\n",
    "        # print(\"omni2\",omni2_summary)\n",
    "        # print(\"goes\",goes_summary)\n",
    "\n",
    "        # ----- Fusion -----\n",
    "        combined = torch.cat((static_embed, omni2_summary, goes_summary), dim=-1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "# -----------------------------------\n",
    "# Masked MSE Loss\n",
    "# -----------------------------------\n",
    "def masked_mse_loss(preds, targets, mask, eps=1e-8):\n",
    "    # preds = torch.nan_to_num(preds, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    # targets = torch.nan_to_num(targets, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    # loss = (preds - targets) ** 2 * mask\n",
    "    # return loss.sum() / (mask.sum() + eps)\n",
    "    diff = (targets - preds) * mask\n",
    "    sq = torch.square(diff)\n",
    "    sum = torch.sum(sq)\n",
    "    N = torch.sum(mask)\n",
    "    # print(sum)\n",
    "    # print(N)\n",
    "    loss = torch.sqrt((sum/N))\n",
    "    return loss\n",
    "\n",
    "# -----------------------------------\n",
    "# Full Training Loop with FullDataset\n",
    "# -----------------------------------\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee49d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(initial_states_df, batch_size=16, device=None):\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    \n",
    "\n",
    "    test_dataset = FullDataset(initial_states_df)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, )\n",
    "    \n",
    "    model = STORMTransformer().to(device)\n",
    "    model.load_state_dict(torch.load('epoch56.pt', weights_only=True))\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask, ts = batch\n",
    "            \n",
    "            static_input = static_input.to(device)\n",
    "            density = density.to(device)\n",
    "            density_mask = density_mask.to(device)\n",
    "            goes = goes.to(device)\n",
    "            goes_mask = goes_mask.to(device)\n",
    "            omni2 = omni2.to(device)\n",
    "            omni2_mask = omni2_mask.to(device)\n",
    "            preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "            print (preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1da440f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardrit/app/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/508 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/508 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ardrit/app/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ardrit/app/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_7240/67470720.py\", line 21, in __getitem__\n    static_input = torch.tensor(row.drop('File ID').fillna(0.0).values, dtype=torch.float32)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_states_normalized\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(initial_states_df, num_epochs, batch_size, lr, device)\u001b[39m\n\u001b[32m     19\u001b[39m model.eval()\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1480\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1478\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task_info[idx]\n\u001b[32m   1479\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1480\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1505\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1503\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1505\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/.venv/lib/python3.12/site-packages/torch/_utils.py:733\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mTypeError\u001b[39m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ardrit/app/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ardrit/app/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_7240/67470720.py\", line 21, in __getitem__\n    static_input = torch.tensor(row.drop('File ID').fillna(0.0).values, dtype=torch.float32)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.\n"
     ]
    }
   ],
   "source": [
    "predict(initial_states_normalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
