{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.transforms as transformers\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import math\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000_to_02284-initial_states.csv\n",
      "02285_to_02357-initial_states.csv\n",
      "02358_to_04264-initial_states.csv\n",
      "04265_to_05570-initial_states.csv\n",
      "05571_to_05614-initial_states.csv\n",
      "05615_to_06671-initial_states.csv\n",
      "06672_to_08118-initial_states.csv\n"
     ]
    }
   ],
   "source": [
    "initial_states = []\n",
    "\n",
    "for dir, sub_dir, files in os.walk(\"input_data/\"):\n",
    "    for file in sorted(files):\n",
    "        print(file)\n",
    "        temp = pd.read_csv((\"input_data/\"+file),index_col=None, header=0)\n",
    "        initial_states.append(temp)\n",
    "#(initial_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states_df = pd.concat(initial_states,axis=0,ignore_index=True)\n",
    "#initial_states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold = initial_states_df\n",
    "x = initial_states_df.iloc[:,2:].values\n",
    "x = normalize(x,norm='l2')\n",
    "hold = pd.concat([hold['File ID'],pd.DataFrame(x)],axis=1)\n",
    "initial_states_normalized = hold\n",
    "#initial_states_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_states_normalized['File ID'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_states_normalized = ((initial_states_df.iloc[:,2:] - initial_states_df.iloc[:,2:].mean())/initial_states_df.iloc[:,2:].std())\n",
    "#initial_states_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(initial_states_normalized, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StaticToFixedLengthTargetDataset(Dataset):\n",
    "    def __init__(self, initial_states_df, targets_dir=\"data/dataset/test/sat_density\", desired_len=432):\n",
    "        self.data = initial_states_df.reset_index(drop=True)\n",
    "        self.targets_dir = targets_dir\n",
    "        self.desired_len = desired_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        static_input = torch.tensor(row.drop('File ID').values, dtype=torch.float32)\n",
    "        file_id = str(row['File ID']).zfill(5)  # Ensure it's 5 characters with leading zeros if needed\n",
    "\n",
    "        # Correct filename pattern: 6-char satellite code + '-' + File ID + '-'\n",
    "        pattern = os.path.join(self.targets_dir, f\"??????-{file_id}-*.csv\")\n",
    "        matched_files = glob.glob(pattern)\n",
    "\n",
    "        if len(matched_files) == 0:\n",
    "            raise FileNotFoundError(f\"No target file found for File ID {file_id}\")\n",
    "        elif len(matched_files) > 1:\n",
    "            raise RuntimeError(f\"Multiple files matched for File ID {file_id}: {matched_files}\")\n",
    "\n",
    "        target_path = matched_files[0]\n",
    "\n",
    "        # Load and process the target file\n",
    "        target_df = pd.read_csv(target_path)\n",
    "        density = target_df.iloc[:, 1].values\n",
    "        actual_len = len(density)\n",
    "\n",
    "        padded = torch.zeros(self.desired_len, dtype=torch.float32)\n",
    "        mask = torch.zeros(self.desired_len, dtype=torch.bool)\n",
    "\n",
    "        if actual_len >= self.desired_len:\n",
    "            padded[:] = torch.tensor(density[:self.desired_len], dtype=torch.float32)\n",
    "            mask[:] = 1\n",
    "        else:\n",
    "            padded[:actual_len] = torch.tensor(density, dtype=torch.float32)\n",
    "            mask[:actual_len] = 1\n",
    "\n",
    "        return static_input, padded, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitialStateEmbedder(nn.Module):\n",
    "    def __init__(self, input_dim=9, embedding_dim=128):\n",
    "        super(InitialStateEmbedder, self).__init__()\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 9)\n",
    "        return self.embed(x)  # output: (batch_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InitialStateEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epoch = 5 #iterations over all data\n",
    "train_losses, val_losses = [],[]\n",
    "\n",
    "model = testModel()\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc='Train loop'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes initial_states_normalized has 8119 rows\n",
    "num_samples = initial_states_normalized.shape[0]  # should be 8119\n",
    "output_dim = 3  # Predicting 3-day densities\n",
    "\n",
    "np.random.seed(1)\n",
    "# Simulate some dummy values (can be random or zeros)\n",
    "target_values = pd.DataFrame(np.random.randn(num_samples, output_dim), columns=['day_1', 'day_2', 'day_3'])\n",
    "\n",
    "# --- Step 2: Convert to Tensors ---\n",
    "X = torch.tensor(initial_states_normalized.values, dtype=torch.float32)  # shape: (8119, 9)\n",
    "y = torch.tensor(target_values.values, dtype=torch.float32)              # shape: (8119, 3)\n",
    "\n",
    "# --- Step 3: Create Dataset and Dataloader ---\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# --- Step 4: Define Model ---\n",
    "class InitialStateEmbedder(nn.Module):\n",
    "    def __init__(self, input_dim=9, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "embedding_dim = 128\n",
    "\n",
    "embedder = InitialStateEmbedder(input_dim=input_dim, embedding_dim=embedding_dim).to(device)\n",
    "regressor = nn.Linear(embedding_dim, output_dim).to(device)\n",
    "model = nn.Sequential(embedder, regressor).to(device)\n",
    "\n",
    "\n",
    "# --- Step 5: Training Setup ---\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --- Step 6: Training Loop ---\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for xb, yb in (dataloader):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {epoch_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28021.69140625\n",
      "14363.4453125\n",
      "14090.5\n",
      "36620.46484375\n",
      "5777.41455078125\n",
      "19455.025390625\n",
      "21918.533203125\n",
      "17455.666015625\n",
      "9195.009765625\n",
      "11026.693359375\n",
      "10261.505859375\n",
      "13063.8623046875\n",
      "24919.052734375\n",
      "21758.896484375\n",
      "26406.052734375\n",
      "28172.142578125\n",
      "20175.396484375\n",
      "12272.025390625\n",
      "26948.126953125\n",
      "17732.1484375\n",
      "9222.9208984375\n",
      "21868.943359375\n",
      "14417.9111328125\n",
      "20033.720703125\n",
      "9644.40234375\n",
      "21626.513671875\n",
      "25434.49609375\n",
      "12749.986328125\n",
      "17761.0234375\n",
      "14656.7451171875\n",
      "12758.6923828125\n",
      "10766.94921875\n",
      "27642.2890625\n",
      "13528.1611328125\n",
      "19931.908203125\n",
      "22102.392578125\n",
      "11143.6962890625\n",
      "11000.3994140625\n",
      "24376.427734375\n",
      "28503.533203125\n",
      "28824.07421875\n",
      "11837.4580078125\n",
      "14904.0009765625\n",
      "15849.8310546875\n",
      "24148.212890625\n",
      "21173.578125\n",
      "12422.90234375\n",
      "24034.279296875\n",
      "31939.107421875\n",
      "18433.171875\n",
      "27821.67578125\n",
      "14767.837890625\n",
      "25433.240234375\n",
      "24150.580078125\n",
      "13648.037109375\n",
      "23455.94140625\n",
      "6841.58642578125\n",
      "13320.1806640625\n",
      "15932.8212890625\n",
      "6432.7685546875\n",
      "12198.787109375\n",
      "14764.3271484375\n",
      "16360.794921875\n",
      "18337.201171875\n",
      "11488.205078125\n",
      "15825.783203125\n",
      "33594.8046875\n",
      "15186.4951171875\n",
      "7270.458984375\n",
      "13206.2470703125\n",
      "16177.970703125\n",
      "14771.9677734375\n",
      "14521.15234375\n",
      "13564.6455078125\n",
      "3427.829345703125\n",
      "32325.41796875\n",
      "11480.294921875\n",
      "17534.0546875\n",
      "8713.6474609375\n",
      "17625.029296875\n",
      "17700.19140625\n",
      "9939.189453125\n",
      "12844.9560546875\n",
      "20134.845703125\n",
      "19357.3671875\n",
      "15749.064453125\n",
      "4574.97021484375\n",
      "18677.75390625\n",
      "20601.638671875\n",
      "17482.5234375\n",
      "18387.65234375\n",
      "18545.146484375\n",
      "13184.439453125\n",
      "15585.7861328125\n",
      "25329.107421875\n",
      "10997.8486328125\n",
      "16847.259765625\n",
      "14123.6171875\n",
      "23378.298828125\n",
      "17114.392578125\n",
      "24503.48046875\n",
      "30666.740234375\n",
      "27293.376953125\n",
      "21497.3046875\n",
      "14422.013671875\n",
      "16925.591796875\n",
      "6566.974609375\n",
      "15382.3544921875\n",
      "17617.271484375\n",
      "10921.9404296875\n",
      "18604.90234375\n",
      "31148.302734375\n",
      "23795.30078125\n",
      "19626.373046875\n",
      "22990.150390625\n",
      "7569.24462890625\n",
      "7934.36865234375\n",
      "15052.595703125\n",
      "13108.4267578125\n",
      "8929.5517578125\n",
      "20599.568359375\n",
      "9806.42578125\n",
      "9701.7236328125\n",
      "27363.283203125\n",
      "20872.7890625\n",
      "15371.599609375\n",
      "22137.4375\n",
      "Epoch 1/5 - Loss: 17508.0024 - Time per epoch: 54.3982\n",
      "19072.40234375\n",
      "18532.748046875\n",
      "13813.60546875\n",
      "26750.2421875\n",
      "23961.27734375\n",
      "12499.7021484375\n",
      "12530.177734375\n",
      "14179.328125\n",
      "13789.943359375\n",
      "29005.591796875\n",
      "8742.90234375\n",
      "10959.1875\n",
      "12231.3173828125\n",
      "9891.0634765625\n",
      "30098.998046875\n",
      "21095.349609375\n",
      "19965.498046875\n",
      "22918.6796875\n",
      "11611.28515625\n",
      "9008.93359375\n",
      "16908.97265625\n",
      "11174.7548828125\n",
      "9012.146484375\n",
      "19048.861328125\n",
      "22440.693359375\n",
      "23982.111328125\n",
      "10426.44140625\n",
      "14881.017578125\n",
      "22400.662109375\n",
      "11806.7099609375\n",
      "9391.751953125\n",
      "11636.6083984375\n",
      "17238.44140625\n",
      "14086.642578125\n",
      "21637.1015625\n",
      "14084.7275390625\n",
      "18475.39453125\n",
      "16058.9482421875\n",
      "27643.849609375\n",
      "10719.6865234375\n",
      "27915.767578125\n",
      "9035.5400390625\n",
      "10325.2880859375\n",
      "19575.060546875\n",
      "10017.4931640625\n",
      "35079.67578125\n",
      "17683.89453125\n",
      "27401.88671875\n",
      "11684.388671875\n",
      "13714.150390625\n",
      "6074.55908203125\n",
      "13820.2841796875\n",
      "20440.908203125\n",
      "30548.384765625\n",
      "10852.3779296875\n",
      "18848.677734375\n",
      "14692.1552734375\n",
      "26419.4140625\n",
      "22205.02734375\n",
      "15887.33984375\n",
      "14622.7080078125\n",
      "10021.5185546875\n",
      "12689.4345703125\n",
      "24300.568359375\n",
      "9325.9755859375\n",
      "21657.314453125\n",
      "19177.794921875\n",
      "21542.611328125\n",
      "9867.0712890625\n",
      "14643.1416015625\n",
      "17736.921875\n",
      "9363.6435546875\n",
      "20414.2890625\n",
      "16057.2998046875\n",
      "25618.296875\n",
      "16937.384765625\n",
      "23246.09765625\n",
      "16630.19921875\n",
      "13216.7158203125\n",
      "15388.9541015625\n",
      "16901.56640625\n",
      "18168.158203125\n",
      "28086.541015625\n",
      "20884.560546875\n",
      "6891.9248046875\n",
      "10144.9521484375\n",
      "12245.0576171875\n",
      "15034.9521484375\n",
      "16545.423828125\n",
      "27940.833984375\n",
      "11963.84375\n",
      "7185.88525390625\n",
      "21966.53515625\n",
      "10734.4853515625\n",
      "22527.59765625\n",
      "28449.189453125\n",
      "13380.255859375\n",
      "14557.033203125\n",
      "13200.9765625\n",
      "22006.248046875\n",
      "18566.984375\n",
      "18785.8515625\n",
      "31507.453125\n",
      "12608.90234375\n",
      "11534.8125\n",
      "18066.5546875\n",
      "29054.20703125\n",
      "12706.4599609375\n",
      "22678.615234375\n",
      "14634.0927734375\n",
      "24401.619140625\n",
      "16027.2509765625\n",
      "18884.974609375\n",
      "13957.7353515625\n",
      "19111.17578125\n",
      "20521.046875\n",
      "17934.212890625\n",
      "21048.32421875\n",
      "9720.4951171875\n",
      "25625.541015625\n",
      "12275.3056640625\n",
      "19890.380859375\n",
      "15187.3935546875\n",
      "25472.2890625\n",
      "17123.599609375\n",
      "25162.3515625\n",
      "16114.85546875\n",
      "Epoch 2/5 - Loss: 17368.6022 - Time per epoch: 53.3599\n",
      "18190.84375\n",
      "20511.009765625\n",
      "14686.9912109375\n",
      "16563.8046875\n",
      "18440.189453125\n",
      "8314.6640625\n",
      "12485.5830078125\n",
      "20387.173828125\n",
      "21237.796875\n",
      "15359.732421875\n",
      "12057.28515625\n",
      "24626.443359375\n",
      "22652.521484375\n",
      "11225.9072265625\n",
      "19490.517578125\n",
      "8939.4169921875\n",
      "10565.8310546875\n",
      "12138.97265625\n",
      "25490.37109375\n",
      "14467.9560546875\n",
      "11131.7939453125\n",
      "9532.30078125\n",
      "20091.564453125\n",
      "11660.6025390625\n",
      "22588.490234375\n",
      "26768.724609375\n",
      "11624.107421875\n",
      "7593.83544921875\n",
      "17489.90234375\n",
      "23467.841796875\n",
      "9806.3837890625\n",
      "18327.4140625\n",
      "13194.5185546875\n",
      "18591.955078125\n",
      "7012.93408203125\n",
      "24669.486328125\n",
      "14851.8486328125\n",
      "23404.59765625\n",
      "20736.7890625\n",
      "23028.8671875\n",
      "14800.8427734375\n",
      "12063.8349609375\n",
      "21679.16015625\n",
      "18397.751953125\n",
      "30585.798828125\n",
      "23388.732421875\n",
      "23952.486328125\n",
      "15411.4384765625\n",
      "15646.6875\n",
      "21042.474609375\n",
      "16497.87890625\n",
      "24583.189453125\n",
      "9354.572265625\n",
      "8974.6650390625\n",
      "17954.740234375\n",
      "9625.6220703125\n",
      "16300.623046875\n",
      "26340.150390625\n",
      "6335.66015625\n",
      "11656.7685546875\n",
      "10335.6806640625\n",
      "6053.91845703125\n",
      "18886.326171875\n",
      "12330.373046875\n",
      "21991.31640625\n",
      "29625.53515625\n",
      "7296.37744140625\n",
      "27507.767578125\n",
      "22363.087890625\n",
      "38534.578125\n",
      "13240.748046875\n",
      "14467.142578125\n",
      "10008.193359375\n",
      "21216.3515625\n",
      "37600.27734375\n",
      "9205.8046875\n",
      "15582.1875\n",
      "13176.0\n",
      "17192.1640625\n",
      "36593.37890625\n",
      "21917.1015625\n",
      "22301.11328125\n",
      "18204.443359375\n",
      "10309.0205078125\n",
      "8393.7998046875\n",
      "9310.8095703125\n",
      "19058.048828125\n",
      "20949.19921875\n",
      "14191.095703125\n",
      "11113.833984375\n",
      "24455.919921875\n",
      "12428.8359375\n",
      "10684.626953125\n",
      "21174.798828125\n",
      "22145.341796875\n",
      "15879.02734375\n",
      "11947.939453125\n",
      "17880.451171875\n",
      "17221.45703125\n",
      "13648.0556640625\n",
      "37783.13671875\n",
      "29183.607421875\n",
      "16544.759765625\n",
      "14413.8330078125\n",
      "33110.47265625\n",
      "21175.365234375\n",
      "21957.025390625\n",
      "13294.7109375\n",
      "18635.8125\n",
      "8840.7060546875\n",
      "18879.314453125\n",
      "9794.66796875\n",
      "25580.689453125\n",
      "16861.49609375\n",
      "20656.59765625\n",
      "27121.5859375\n",
      "10846.9658203125\n",
      "21203.369140625\n",
      "13075.162109375\n",
      "21477.189453125\n",
      "21854.2890625\n",
      "13510.0263671875\n",
      "12109.7587890625\n",
      "14034.94921875\n",
      "7204.4052734375\n",
      "16307.181640625\n",
      "3750.24365234375\n",
      "Epoch 3/5 - Loss: 17351.4134 - Time per epoch: 54.3783\n",
      "13291.72265625\n",
      "14079.4404296875\n",
      "8837.0068359375\n",
      "17700.9296875\n",
      "16177.599609375\n",
      "16445.310546875\n",
      "10370.3349609375\n",
      "15095.26171875\n",
      "10523.416015625\n",
      "28803.5234375\n",
      "23636.4765625\n",
      "13861.1943359375\n",
      "11755.8857421875\n",
      "32493.765625\n",
      "19779.59765625\n",
      "8653.578125\n",
      "26496.623046875\n",
      "19833.912109375\n",
      "13814.685546875\n",
      "18143.517578125\n",
      "7245.93408203125\n",
      "10050.9560546875\n",
      "24537.0\n",
      "14746.126953125\n",
      "15364.501953125\n",
      "11287.2353515625\n",
      "21549.3359375\n",
      "11549.533203125\n",
      "15885.5712890625\n",
      "13148.3212890625\n",
      "11916.4873046875\n",
      "9287.185546875\n",
      "14155.46484375\n",
      "12567.2216796875\n",
      "9214.9443359375\n",
      "19067.08203125\n",
      "25168.8046875\n",
      "18874.400390625\n",
      "35347.00390625\n",
      "24814.5390625\n",
      "35347.453125\n",
      "16070.0556640625\n",
      "16790.4921875\n",
      "17717.81640625\n",
      "20507.041015625\n",
      "5737.34814453125\n",
      "18281.673828125\n",
      "7495.4375\n",
      "25460.009765625\n",
      "11944.5302734375\n",
      "28322.44140625\n",
      "20805.041015625\n",
      "12069.7822265625\n",
      "13122.375\n",
      "26617.619140625\n",
      "17889.103515625\n",
      "16288.4609375\n",
      "11578.63671875\n",
      "14603.2451171875\n",
      "16284.66015625\n",
      "2545.42724609375\n",
      "24812.7265625\n",
      "17771.5703125\n",
      "17942.77734375\n",
      "23323.15625\n",
      "14643.64453125\n",
      "6154.09130859375\n",
      "6025.486328125\n",
      "18173.412109375\n",
      "12653.623046875\n",
      "11239.064453125\n",
      "17239.365234375\n",
      "18686.599609375\n",
      "15449.5322265625\n",
      "19462.115234375\n",
      "21343.75390625\n",
      "16405.63671875\n",
      "8875.375\n",
      "15033.810546875\n",
      "12396.8017578125\n",
      "15434.2734375\n",
      "14219.7158203125\n",
      "19843.1796875\n",
      "15829.38671875\n",
      "5412.57861328125\n",
      "25572.46484375\n",
      "12119.0947265625\n",
      "20459.076171875\n",
      "7907.98193359375\n",
      "23071.822265625\n",
      "11124.279296875\n",
      "23156.30078125\n",
      "24463.7265625\n",
      "36567.203125\n",
      "38338.54296875\n",
      "21166.99609375\n",
      "19323.181640625\n",
      "12408.748046875\n",
      "11713.810546875\n",
      "16805.470703125\n",
      "41258.625\n",
      "13319.4951171875\n",
      "10325.771484375\n",
      "26788.916015625\n",
      "25344.666015625\n",
      "10168.4453125\n",
      "15467.08984375\n",
      "25908.953125\n",
      "29760.251953125\n",
      "12776.1806640625\n",
      "13762.02734375\n",
      "22876.376953125\n",
      "12384.7060546875\n",
      "15174.3505859375\n",
      "37250.703125\n",
      "9870.7587890625\n",
      "27918.408203125\n",
      "15568.4130859375\n",
      "15853.9580078125\n",
      "12962.4169921875\n",
      "10940.3212890625\n",
      "13896.7548828125\n",
      "17057.087890625\n",
      "21895.953125\n",
      "21252.173828125\n",
      "22669.93359375\n",
      "7523.4072265625\n",
      "Epoch 4/5 - Loss: 17351.1544 - Time per epoch: 53.5563\n",
      "12697.8408203125\n",
      "17404.884765625\n",
      "14798.6298828125\n",
      "14135.25\n",
      "10432.53515625\n",
      "14010.048828125\n",
      "22078.0859375\n",
      "13935.52734375\n",
      "18470.166015625\n",
      "28547.130859375\n",
      "13353.03125\n",
      "15329.2099609375\n",
      "8253.9541015625\n",
      "11159.7294921875\n",
      "4946.0849609375\n",
      "12947.8173828125\n",
      "16827.41015625\n",
      "31632.107421875\n",
      "13505.5107421875\n",
      "14998.7294921875\n",
      "35083.40625\n",
      "7074.94970703125\n",
      "21410.1875\n",
      "28025.375\n",
      "18116.302734375\n",
      "9264.1982421875\n",
      "29942.990234375\n",
      "28843.64453125\n",
      "29273.75\n",
      "9699.8740234375\n",
      "25916.685546875\n",
      "16714.615234375\n",
      "22077.98828125\n",
      "21900.00390625\n",
      "15148.6572265625\n",
      "14962.0107421875\n",
      "19979.7109375\n",
      "19192.642578125\n",
      "15386.46484375\n",
      "25413.31640625\n",
      "6947.00439453125\n",
      "19601.337890625\n",
      "13040.2060546875\n",
      "15699.5068359375\n",
      "18275.22265625\n",
      "15078.0107421875\n",
      "22855.796875\n",
      "16523.53515625\n",
      "11811.0107421875\n",
      "15305.5888671875\n",
      "20675.32421875\n",
      "18257.900390625\n",
      "9698.2734375\n",
      "15754.6533203125\n",
      "23340.4453125\n",
      "24201.09765625\n",
      "22012.044921875\n",
      "26137.396484375\n",
      "28358.330078125\n",
      "22078.73828125\n",
      "25111.37890625\n",
      "25891.833984375\n",
      "17473.580078125\n",
      "22044.919921875\n",
      "18263.005859375\n",
      "19405.083984375\n",
      "19134.8359375\n",
      "16560.62109375\n",
      "15227.9013671875\n",
      "14550.8359375\n",
      "21161.890625\n",
      "13113.8056640625\n",
      "14432.1923828125\n",
      "26245.48828125\n",
      "9364.8408203125\n",
      "26428.791015625\n",
      "19844.966796875\n",
      "8291.3583984375\n",
      "11373.9326171875\n",
      "3113.770751953125\n",
      "18530.365234375\n",
      "13318.7890625\n",
      "11398.2841796875\n",
      "17112.544921875\n",
      "13215.8310546875\n",
      "24974.533203125\n",
      "25756.259765625\n",
      "9442.1962890625\n",
      "20358.986328125\n",
      "10937.1787109375\n",
      "14738.1298828125\n",
      "10920.896484375\n",
      "13124.4775390625\n",
      "15060.5693359375\n",
      "16422.890625\n",
      "28341.07421875\n",
      "15569.0439453125\n",
      "16221.4677734375\n",
      "14610.96484375\n",
      "10065.357421875\n",
      "17290.908203125\n",
      "15315.4140625\n",
      "8496.6630859375\n",
      "23683.63671875\n",
      "21671.52734375\n",
      "16114.28125\n",
      "12818.6201171875\n",
      "10133.7333984375\n",
      "7140.779296875\n",
      "14201.6044921875\n",
      "8827.150390625\n",
      "21821.203125\n",
      "18210.755859375\n",
      "15806.4091796875\n",
      "19573.1796875\n",
      "21319.58984375\n",
      "23790.125\n",
      "23630.431640625\n",
      "22744.9921875\n",
      "21090.828125\n",
      "9133.8037109375\n",
      "14553.4072265625\n",
      "17177.751953125\n",
      "24156.037109375\n",
      "14514.33984375\n",
      "12186.3662109375\n",
      "12987.484375\n",
      "Epoch 5/5 - Loss: 17355.0219 - Time per epoch: 54.2668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================\n",
    "# Dataset\n",
    "# ============================\n",
    "class StaticToFixedLengthTargetDataset(Dataset):\n",
    "    def __init__(self, initial_states_df, targets_dir=\"data/dataset/test/sat_density\", desired_len=432):\n",
    "        self.data = initial_states_df.reset_index(drop=True)\n",
    "        self.targets_dir = targets_dir\n",
    "        self.desired_len = desired_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        static_input = torch.tensor(row.drop('File ID').values, dtype=torch.float32)\n",
    "        file_id = str(int(row['File ID'])).zfill(5)  # Ensure it's 5 digits like \"08081\"\n",
    "\n",
    "        # Pattern: <6-char satellite code>-<File ID>-*.csv\n",
    "        pattern = os.path.join(self.targets_dir, f\"??????-{file_id}-*.csv\")\n",
    "        matched_files = glob.glob(pattern)\n",
    "        #print (matched_files)\n",
    "\n",
    "        if len(matched_files) == 0:\n",
    "            raise FileNotFoundError(f\"No target file found for File ID {file_id}\")\n",
    "        elif len(matched_files) > 1:\n",
    "            raise RuntimeError(f\"Multiple files matched for File ID {file_id}: {matched_files}\")\n",
    "\n",
    "        target_path = matched_files[0]\n",
    "\n",
    "        # Load density data from 2nd column\n",
    "        target_df = pd.read_csv(target_path)\n",
    "        density = pd.to_numeric(target_df.iloc[:, 1], errors='coerce')\n",
    "        density = density.clip(lower=0, upper=1e3).fillna(0.0).values\n",
    "        actual_len = len(density)\n",
    "\n",
    "        # Pad or truncate to fixed length\n",
    "        padded = torch.zeros(self.desired_len, dtype=torch.float32)\n",
    "        mask = torch.zeros(self.desired_len, dtype=torch.bool)\n",
    "        if actual_len >= self.desired_len:\n",
    "            padded[:] = torch.tensor(density[:self.desired_len], dtype=torch.float32)\n",
    "            mask[:] = 1\n",
    "        else:\n",
    "            padded[:actual_len] = torch.tensor(density, dtype=torch.float32)\n",
    "            mask[:actual_len] = 1\n",
    "\n",
    "        if torch.isnan(padded).any():\n",
    "            print (f\"NaN detected in padded target for File ID {file_id}\")\n",
    "\n",
    "        return static_input, padded, mask\n",
    "\n",
    "# ============================\n",
    "# Model\n",
    "# ============================\n",
    "class StaticToSequenceModel(nn.Module):\n",
    "    def __init__(self, input_dim=9, embedding_dim=128, output_len=432):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim, output_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # (batch_size, 432)\n",
    "\n",
    "# ============================\n",
    "# Masked MSE Loss\n",
    "# ============================\n",
    "def masked_mse_loss(preds, targets, mask, eps=1e-8):\n",
    "    preds = torch.nan_to_num(preds, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    targets = torch.nan_to_num(targets, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "\n",
    "    loss = (preds - targets) ** 2\n",
    "    loss = loss * mask.float()\n",
    "\n",
    "    denom = mask.sum().clamp(min=1.0)  # avoid division by zero\n",
    "    return loss.sum() / denom\n",
    "\n",
    "# ============================\n",
    "# Training Loop\n",
    "# ============================\n",
    "def train_model(initial_states_df, targets_dir=\"data/dataset/test/sat_density\", num_epochs=5, batch_size=64, lr=1e-3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Dataset and Dataloader\n",
    "    dataset = StaticToFixedLengthTargetDataset(initial_states_df, targets_dir)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Model, optimizer, loss\n",
    "    model = StaticToSequenceModel().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for static_input, target_seq, mask in dataloader:\n",
    "            static_input = static_input.to(device)\n",
    "            target_seq = target_seq.to(device)\n",
    "            mask = mask.to(device)\n",
    "            if torch.isnan(static_input).any():\n",
    "                print(\"NaN detected in static_input\")\n",
    "            \n",
    "            \n",
    "\n",
    "            preds = model(static_input)\n",
    "            preds = torch.nan_to_num(preds, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "            loss = masked_mse_loss(preds, target_seq, mask)\n",
    "            print (loss.item())\n",
    "\n",
    "            if torch.isnan(preds).any() or torch.isnan(target_seq).any():\n",
    "                print(\"⚠️ NaNs found in predictions or targets\")\n",
    "            if torch.isinf(preds).any() or torch.isinf(target_seq).any():\n",
    "                print(\"⚠️ Infs found in predictions or targets\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        end = time.time()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f} - Time per epoch: {(end - start):.4f}\")\n",
    "\n",
    "train_model(initial_states_normalized, lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullDataset(Dataset):\n",
    "    def __init__(self, initial_states_df, density_length=432, goes_length=86400, omni2_length=1440, density_dir='data/dataset/test/sat_density', goes_dir=\"data/dataset/test/goes\",\n",
    "                 omni2_dir=\"data/dataset/test/omni2\"):\n",
    "        self.data = initial_states_df.reset_index(drop=True)\n",
    "        self.density_dir = density_dir\n",
    "        self.goes_dir = goes_dir\n",
    "        self.omni2_dir = omni2_dir\n",
    "        self.density_length = density_length\n",
    "        self.goes_length = goes_length\n",
    "        self.omni2_length = omni2_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        static_input = torch.tensor(row.drop('File ID').fillna(0.0).values, dtype=torch.float32)\n",
    "        \n",
    "        file_id = str(int(row['File ID'])).zfill(5)\n",
    "        \n",
    "        density_file = glob.glob(os.path.join(self.density_dir, f\"*-{file_id}-*.csv\"))\n",
    "        goes_file = glob.glob(os.path.join(self.goes_dir, f\"*-{file_id}-*.csv\"))\n",
    "        omni2_file = glob.glob(os.path.join(self.omni2_dir, f\"*-{file_id}-*.csv\"))\n",
    "\n",
    "        pos = len(self.density_dir)+1\n",
    "        density_sat = density_file[0][pos:pos+6]\n",
    "\n",
    "        density_df = ((pd.read_csv(density_file[0])))\n",
    "        density_df['Orbit Mean Density (kg/m^3)'] = np.where(density_df['Orbit Mean Density (kg/m^3)']>=1,np.nan,density_df['Orbit Mean Density (kg/m^3)'])\n",
    "        if density_df.shape[0] > self.density_length:\n",
    "            density_df = density_df[:self.density_length]\n",
    "        elif density_df.shape[0] < self.density_length:\n",
    "            padding = pd.DataFrame(np.empty((self.density_length-density_df.shape[0],2)),columns=density_df.columns)\n",
    "            padding[:] = np.nan\n",
    "            density_df = pd.concat((density_df,padding),ignore_index=True)\n",
    "        density_df_mask = (pd.notnull(density_df)).astype(int)\n",
    "        density_tensor = torch.tensor(density_df['Orbit Mean Density (kg/m^3)'].fillna(0.0).values, dtype=torch.float32)\n",
    "        density_df_mask_tensor = torch.tensor(density_df_mask.iloc[:,1].values, dtype=torch.float32)\n",
    "        density_stacked = torch.stack((density_tensor,density_df_mask_tensor))\n",
    "\n",
    "        goes_df = pd.read_csv(goes_file[0])\n",
    "        if goes_df.shape[0] > self.goes_length:\n",
    "            goes_df = goes_df[goes_df.shape[0]-self.goes_length:goes_df.shape[0]]\n",
    "        elif goes_df.shape[0] < self.goes_length:\n",
    "            padding = pd.DataFrame(np.empty((self.goes_length-goes_df.shape[0],43)),columns=goes_df.columns)\n",
    "            padding[:] = np.nan\n",
    "            goes_df = pd.concat((padding,goes_df),ignore_index=True)\n",
    "        goes_mask = (~pd.isnull(goes_df)).astype(int)\n",
    "        goes_valid_mask = ((goes_df['xrsa_flag'] == 0.0) & (goes_df['xrsb_flag'] == 0.0)).astype(int)\n",
    "        goes_mask = goes_mask.mul(goes_valid_mask.values,axis=0)\n",
    "        goes_tensor = torch.tensor(normalize(goes_df.iloc[:, 1:].fillna(0.0).values, norm='l2'), dtype=torch.float32)\n",
    "        goes_mask_tensor = torch.tensor(goes_mask.iloc[:, 1:].values, dtype=torch.float32)\n",
    "        #goes_stacked = torch.stack((goes_tensor,goes_mask_tensor))\n",
    "        \n",
    "        omni2_df = pd.read_csv(omni2_file[0])\n",
    "        if omni2_df.shape[0] > self.omni2_length:\n",
    "            omni2_df = omni2_df[omni2_df.shape[0]-self.omni2_length:omni2_df.shape[0]]\n",
    "        elif goes_df.shape[0] < self.omni2_length:\n",
    "            padding = pd.DataFrame(np.empty((self.omni2_length-omni2_df.shape[0],58)),columns=omni2_df.columns)\n",
    "            padding[:] = np.nan\n",
    "            omni2_df = pd.concat((padding,omni2_df),ignore_index=True)\n",
    "        omni2_tensor = torch.tensor(normalize(omni2_df.iloc[:, :57].fillna(0.0).values.astype(float), norm='l2'), dtype=torch.float32)\n",
    "        omni2_mask = (~pd.isnull(omni2_df)).astype(int)\n",
    "        omni2_mask_tensor = torch.tensor(omni2_mask.iloc[:, :57].values, dtype=torch.float32) \n",
    "        omni2_stacked = torch.stack((omni2_tensor,omni2_mask_tensor))\n",
    "\n",
    "        return static_input, density_tensor, density_df_mask_tensor, goes_tensor, goes_mask_tensor, omni2_tensor, omni2_mask_tensor#, density_sat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StormForecastModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 static_dim=9,\n",
    "                 goes_dim=42,\n",
    "                 omni2_dim=57,\n",
    "                 goes_hidden=64,\n",
    "                 omni2_hidden=64,\n",
    "                 static_embed_dim=64,\n",
    "                 output_len=432):\n",
    "        super().__init__()\n",
    "\n",
    "        # Static MLP\n",
    "        self.static_net = nn.Sequential(\n",
    "            nn.Linear(static_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, static_embed_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Feature encoders\n",
    "        self.goes_encoder = nn.Linear(goes_dim, goes_hidden)\n",
    "        self.omni2_encoder = nn.Linear(omni2_dim, omni2_hidden)\n",
    "\n",
    "        # Final regression\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(static_embed_dim + goes_hidden + omni2_hidden, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_len)\n",
    "        )\n",
    "\n",
    "    def masked_mean(self, x, mask):\n",
    "        # x: [B, T, F], mask: [B, T]\n",
    "        mask = mask.unsqueeze(-1)  # [B, T, 1]\n",
    "        x = x * mask  # mask out invalid steps\n",
    "        summed = x.sum(dim=1)  # sum over time\n",
    "        lengths = mask.sum(dim=1).clamp(min=1e-6)  # avoid divide-by-zero\n",
    "        return summed / lengths  # [B, F]\n",
    "\n",
    "    def forward(self, static_input, goes_seq, omni2_seq, goes_mask, omni2_mask):\n",
    "        # Encode static\n",
    "        static_embed = self.static_net(static_input)  # [B, static_embed_dim]\n",
    "\n",
    "        # Encode GOES\n",
    "        goes_encoded = self.goes_encoder(goes_seq)  # [B, T, H]\n",
    "        goes_pooled = self.masked_mean(goes_encoded, goes_mask)  # [B, H]\n",
    "\n",
    "        # Encode OMNI2\n",
    "        omni2_encoded = self.omni2_encoder(omni2_seq)  # [B, T, H]\n",
    "        omni2_pooled = self.masked_mean(omni2_encoded, omni2_mask)  # [B, H]\n",
    "\n",
    "        # Combine and predict\n",
    "        fused = torch.cat([static_embed, goes_pooled, omni2_pooled], dim=-1)  # [B, total]\n",
    "        output = self.fusion(fused)  # [B, 432]\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(preds, targets, mask, eps=1e-8):\n",
    "    loss = (preds - targets) ** 2\n",
    "    masked_loss = loss * mask.float()\n",
    "    return masked_loss.sum() / (mask.sum() + eps)\n",
    "\n",
    "def train(model, dataloader, device, num_epochs=5, lr=1e-4):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            static_input, target, target_mask, goes_seq, goes_mask, omni2_seq, omni2_mask, _ = batch\n",
    "\n",
    "            # Move to GPU\n",
    "            static_input = static_input.to(device)\n",
    "            target = target.to(device)\n",
    "            target_mask = target_mask.to(device)\n",
    "            goes_seq = goes_seq.to(device)\n",
    "            goes_mask = goes_mask.to(device)\n",
    "            omni2_seq = omni2_seq.to(device)\n",
    "            omni2_mask = omni2_mask.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            preds = model(static_input, goes_seq, omni2_seq, goes_mask, omni2_mask)\n",
    "\n",
    "            # Loss\n",
    "            loss = masked_mse_loss(preds, target, target_mask)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StormForecastModel()\n",
    "dataset = FullDataset(initial_states_normalized)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "\n",
    "train(model, dataloader, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "    def __init__(self, input_dim=9, embedding_dim=128, goes_len=86400, goes_dim=43, omni2_length=1440, omni2_dim=58, output_len=432):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        return (self.embed(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/127 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/127 [00:39<41:11, 19.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m model.eval()\n\u001b[32m     37\u001b[39m epoch_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity_mask_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes_mask_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2_mask_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity_sat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdensity_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/_utils/collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/_utils/collate.py:212\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    208\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    214\u001b[39m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/_utils/collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/_utils/collate.py:272\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    270\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    271\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "num_batches = len(initial_states_normalized)/batch_size\n",
    "dataset = FullDataset(initial_states_normalized)\n",
    "dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#dataset[1]\n",
    "embedder = FullModel().to(device)\n",
    "regressor = nn.Linear(128, 432).to(device)\n",
    "model = nn.Sequential(embedder, regressor).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "losses = []\n",
    "\n",
    "\n",
    "\n",
    "def MaskedRMSE(preds, targets, mask):\n",
    "    # preds = torch.Tensor.numpy(preds)\n",
    "    # targets = torch.Tensor.numpy(targets)\n",
    "    # mask = torch.Tensor.numpy(mask)\n",
    "    # print (preds)\n",
    "    # print (targets)\n",
    "    # print (mask)\n",
    "    diff = (targets - preds) * mask\n",
    "    sq = torch.square(diff)\n",
    "    sum = torch.sum(sq)\n",
    "    N = torch.sum(mask)\n",
    "    # print(sum)\n",
    "    # print(N)\n",
    "    loss = torch.sqrt((sum/N))\n",
    "    return loss\n",
    "\n",
    "for epoch in (range(num_epochs)):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    for static_input, density_tensor, density_mask_tensor, goes_tensor, goes_mask_tensor, omni2_tensor, omni2_mask_tensor, density_sat in tqdm(dataloader):\n",
    "        static_input = static_input.to(device)\n",
    "        density_tensor = density_tensor.to(device)\n",
    "        density_mask_tensor = density_mask_tensor.to(device)\n",
    "        preds = model(static_input)\n",
    "        # print(preds)\n",
    "        # print (preds.shape)\n",
    "        # print(f\"shapes\\nPreds: {preds.shape}, {preds.dtype}\\nTargets: {density_tensor.shape}, {density_tensor.dtype}\\nMask: {density_mask_tensor.shape}, {density_mask_tensor.dtype}\")\n",
    "        loss = MaskedRMSE(preds,density_tensor, density_mask_tensor)\n",
    "        #print(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss/ len(dataloader)\n",
    "    losses.append(avg_loss)\n",
    "    end = time.time()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.10f} - Time per epoch: {(end - start):.4f}\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8119 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6412e-04, -3.5223e-04,  3.4084e-04,  4.5743e-04, -3.0997e-04,\n",
       "          3.8624e-05, -4.9660e-04,  3.6685e-04,  6.6805e-04,  2.3664e-04,\n",
       "          4.1881e-04, -1.3260e-04,  3.5301e-04, -3.9159e-04,  1.7426e-04,\n",
       "         -1.5569e-05,  6.6600e-04,  1.7110e-04,  5.4594e-04,  4.4028e-04,\n",
       "          6.7592e-04, -5.5230e-04, -7.7586e-04, -1.8942e-04, -1.5887e-05,\n",
       "         -2.2934e-04, -3.3015e-04,  3.7521e-04,  4.8421e-04, -1.0995e-04,\n",
       "         -7.3139e-04, -1.8615e-04,  6.9783e-04, -6.8153e-04, -5.4119e-04,\n",
       "         -2.3852e-04,  7.0119e-04,  3.6764e-04,  4.4872e-04,  4.7903e-04,\n",
       "         -2.2988e-04,  4.9530e-04, -2.3529e-04,  3.1703e-04,  3.2064e-04,\n",
       "         -2.6860e-04,  3.3155e-05,  1.4689e-04, -3.1956e-04, -1.1548e-04,\n",
       "         -4.7844e-04,  1.3072e-04,  4.7526e-04, -6.4395e-04, -5.2673e-04,\n",
       "          2.4633e-04,  3.5200e-04,  5.0917e-04,  4.3526e-04,  2.7104e-04,\n",
       "          7.5075e-04,  5.0053e-04, -4.9528e-04,  3.5879e-04, -6.7240e-04,\n",
       "          6.0761e-04, -5.8948e-04,  4.1418e-04,  5.1042e-04,  3.7889e-04,\n",
       "          1.7092e-04,  4.6201e-04,  4.2782e-04,  6.2354e-04, -5.6364e-04,\n",
       "          5.6482e-04,  6.7784e-04, -3.4810e-04,  2.6137e-04, -1.1777e-04,\n",
       "          6.3705e-04,  4.7051e-04,  4.2716e-04, -4.7136e-04, -2.5092e-04,\n",
       "          3.5010e-04, -4.1949e-04, -3.6634e-04,  4.2731e-04,  3.2744e-04,\n",
       "          7.6116e-04, -6.0667e-04, -1.1195e-04,  5.6745e-05, -7.0375e-04,\n",
       "          1.9549e-05, -2.2626e-04, -5.8227e-04,  4.6115e-04, -6.1098e-04,\n",
       "          1.9519e-05, -3.4396e-04, -5.4236e-04, -9.6946e-05,  5.0072e-04,\n",
       "         -7.1368e-04, -8.7046e-05, -6.6128e-04, -6.9197e-04, -2.7991e-05,\n",
       "         -2.7591e-05,  6.0835e-04,  2.7138e-04, -6.8079e-04,  1.5130e-04,\n",
       "          6.3201e-04, -2.6698e-04, -1.0495e-04, -6.0800e-04, -5.3444e-04,\n",
       "          9.5229e-05, -2.7548e-04,  5.6771e-04, -1.2876e-04,  7.7721e-04,\n",
       "         -6.4746e-04,  3.2402e-04, -8.5460e-05, -2.7755e-04,  6.9775e-04,\n",
       "          1.5011e-04, -7.2555e-04, -6.9057e-05,  1.2720e-04,  3.8006e-04,\n",
       "         -3.6808e-04,  3.5848e-04, -2.7588e-05,  7.0045e-04,  1.2774e-04,\n",
       "         -4.4507e-04, -1.6860e-04,  4.1060e-04,  2.8664e-04,  3.8864e-05,\n",
       "          2.7797e-04,  1.4737e-04, -3.1718e-04,  2.9288e-04, -2.2539e-04,\n",
       "         -3.3149e-04, -6.2457e-04,  5.9243e-04,  5.6878e-04, -7.0760e-04,\n",
       "         -4.5118e-04,  4.3614e-04, -2.4100e-04,  1.4091e-04, -5.9899e-05,\n",
       "         -3.0851e-04,  4.8968e-04,  3.4016e-04, -4.1865e-04,  4.4515e-05,\n",
       "          4.8025e-05, -3.4136e-04,  5.6231e-04,  4.6630e-04,  4.1485e-04,\n",
       "         -6.4245e-04, -5.2778e-04,  1.1629e-04, -6.3592e-04,  7.3846e-05,\n",
       "         -6.7176e-04,  5.0474e-05, -7.8873e-05, -3.6156e-04,  1.7251e-04,\n",
       "          3.8825e-04,  9.2233e-05, -1.3184e-04, -1.1412e-04, -5.1545e-04,\n",
       "          6.3032e-04, -5.0705e-04,  6.7382e-04,  1.5756e-04, -2.7948e-04,\n",
       "          2.1021e-05, -2.5905e-04, -5.3672e-04, -3.0319e-04, -4.6359e-04,\n",
       "          6.1331e-04, -6.3576e-04, -5.1713e-04, -5.2033e-04,  9.9548e-05,\n",
       "         -3.1773e-04,  1.5382e-04, -8.4139e-05,  1.3177e-04,  2.1229e-04,\n",
       "          2.9719e-04, -7.8360e-04, -3.6334e-04, -3.0965e-04, -4.6045e-04,\n",
       "          2.9343e-04,  2.2262e-04,  7.2350e-04, -7.5095e-04,  2.0182e-04,\n",
       "         -3.8621e-04, -1.3085e-04,  4.3293e-04,  2.9636e-04, -2.7243e-04,\n",
       "         -4.6127e-04, -1.9145e-04, -5.3503e-04,  3.1086e-04,  1.3835e-04,\n",
       "         -3.6387e-04, -1.4263e-04,  6.1782e-04, -8.5694e-05,  9.2408e-05,\n",
       "          4.9805e-04,  4.5211e-04,  3.9045e-04, -1.4534e-04,  1.1867e-04,\n",
       "          2.3599e-04, -4.9147e-04,  5.7788e-04, -6.5406e-04,  5.7353e-04,\n",
       "          5.1025e-04, -4.5763e-05, -4.5003e-04, -4.6927e-04,  4.8765e-04,\n",
       "         -5.7927e-05, -1.4462e-04,  4.6414e-04,  1.6524e-04,  1.8455e-05,\n",
       "          6.1671e-04,  1.6685e-04,  5.6845e-04,  1.5849e-05,  5.3597e-04,\n",
       "         -4.0201e-04, -4.6763e-04, -5.7654e-04, -6.1493e-04,  2.3455e-04,\n",
       "         -5.6319e-05,  4.4455e-04,  3.2251e-04,  5.2124e-05,  1.3104e-04,\n",
       "          5.9640e-04, -6.1241e-04, -4.3670e-04, -2.3867e-04, -1.0073e-04,\n",
       "          1.6717e-04, -6.0793e-04, -3.1810e-04,  1.7139e-04, -1.8024e-04,\n",
       "          3.2230e-04,  8.2716e-05, -5.6044e-04,  1.0869e-04, -7.4500e-04,\n",
       "          5.7068e-04,  1.8589e-04, -5.7338e-04, -1.8273e-04,  4.0291e-04,\n",
       "         -3.8698e-04,  6.2466e-04, -2.1413e-04,  2.0003e-04, -5.2612e-04,\n",
       "         -5.5772e-04,  9.6299e-07,  6.0825e-04,  2.2507e-04, -3.0697e-04,\n",
       "         -7.3712e-04,  1.3839e-04,  5.2792e-05,  4.8579e-04,  2.1462e-04,\n",
       "         -5.1333e-04, -5.3319e-04,  2.7540e-04, -1.4987e-04, -7.2424e-05,\n",
       "          4.3854e-04,  4.5111e-04,  1.5021e-04, -1.4413e-04,  5.5739e-04,\n",
       "          5.9126e-04, -3.1509e-04,  1.9030e-04, -1.1523e-04,  1.9429e-04,\n",
       "          2.4923e-04, -3.3670e-04, -7.5390e-04, -1.1096e-04, -3.5991e-04,\n",
       "         -5.2764e-05,  3.6993e-04,  6.4655e-04,  7.6722e-04, -2.7975e-05,\n",
       "         -2.9904e-04, -5.3024e-04,  7.7115e-04, -1.0441e-04, -5.9629e-04,\n",
       "          1.1404e-04, -4.5361e-04,  1.0653e-05, -3.9821e-04,  3.3756e-04,\n",
       "          3.7599e-05,  1.3813e-05, -3.1648e-04,  5.0305e-04, -4.3280e-04,\n",
       "          2.2242e-04, -4.0427e-04, -5.3302e-04, -4.4420e-05, -6.0412e-04,\n",
       "         -1.1583e-04,  3.5063e-04,  5.1414e-05,  5.2650e-04, -3.2139e-04,\n",
       "          1.7821e-04, -1.0470e-04, -4.4222e-04, -5.8664e-04, -3.5380e-04,\n",
       "          2.6195e-04, -8.9899e-05, -5.1586e-04, -4.5429e-04, -1.0374e-04,\n",
       "          2.4625e-04, -5.3316e-04,  5.6688e-04,  2.8431e-05, -4.3474e-04,\n",
       "          7.2113e-05,  3.0772e-04, -4.6974e-04,  2.2212e-04,  3.1962e-04,\n",
       "         -5.3968e-04,  5.8488e-04, -4.4356e-04, -3.7449e-04,  1.3199e-04,\n",
       "          2.4633e-04,  5.0669e-04,  2.3002e-04,  4.5933e-04, -2.5608e-05,\n",
       "          2.6826e-04,  5.2730e-04,  5.1533e-05, -6.1317e-04, -9.8182e-05,\n",
       "         -4.7600e-06, -4.6541e-04,  5.6674e-05,  3.4972e-04,  2.1630e-05,\n",
       "          2.3995e-04, -1.6090e-04,  1.7102e-04, -5.5816e-05, -4.5709e-04,\n",
       "         -2.6984e-04,  4.6244e-04, -1.3375e-04, -5.3902e-04, -2.8067e-04,\n",
       "          6.5695e-05, -9.5939e-05, -3.6654e-04, -3.7912e-04, -5.4057e-04,\n",
       "          3.1544e-04,  2.8091e-04,  6.7990e-05, -5.1872e-04, -2.2709e-04,\n",
       "         -5.6159e-04, -6.9678e-05, -2.1874e-04, -4.0364e-05,  2.9393e-04,\n",
       "          4.6114e-04, -6.2275e-04,  4.9241e-04,  1.7448e-04, -2.7545e-04,\n",
       "         -1.1948e-04, -1.5891e-04,  7.3897e-04, -5.2352e-04, -6.4078e-04,\n",
       "          1.9933e-04,  5.6078e-05, -4.3691e-04, -5.5181e-04,  9.9165e-05,\n",
       "          5.5938e-06, -2.9118e-04]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "dataloader = DataLoader(dataset,batch_size=1,shuffle=True)\n",
    "model.eval()\n",
    "epoch_loss = 0.0\n",
    "for static_input, density_tensor, density_mask_tensor in tqdm(dataloader):\n",
    "    static_input = static_input.to(device)\n",
    "    density_tensor = density_tensor.to(device)\n",
    "    density_mask_tensor = density_mask_tensor.to(device)\n",
    "    preds = model(static_input)\n",
    "    # print(preds)\n",
    "    # print (preds.shape)\n",
    "    # print(f\"shapes\\nPreds: {preds.shape}, {preds.dtype}\\nTargets: {density_tensor.shape}, {density_tensor.dtype}\\nMask: {density_mask_tensor.shape}, {density_mask_tensor.dtype}\")\n",
    "    loss = MaskedRMSE(preds,density_tensor, density_mask_tensor)\n",
    "    break\n",
    "\n",
    "preds.shape\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# Positional Encoding for Sequences\n",
    "# -----------------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=10000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000.0) / d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# -----------------------------------\n",
    "# STORMTransformer with Mask Handling\n",
    "# -----------------------------------\n",
    "class STORMTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 static_dim=9,\n",
    "                 omni2_dim=57,\n",
    "                 goes_dim=42,\n",
    "                 d_model=128,\n",
    "                 output_len=432,\n",
    "                 nhead=4,\n",
    "                 num_layers=2,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "\n",
    "        self.omni2_proj = nn.Linear(omni2_dim, d_model)\n",
    "        self.goes_proj = nn.Linear(goes_dim, d_model)\n",
    "\n",
    "        self.omni2_pos = PositionalEncoding(d_model)\n",
    "        self.goes_pos = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.omni2_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.goes_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, output_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, static_input, omni2_seq, goes_seq, omni2_mask=None, goes_mask=None):\n",
    "        B = static_input.size(0)\n",
    "\n",
    "        static_embed = self.static_encoder(static_input)\n",
    "\n",
    "        omni2_embed = self.omni2_proj(omni2_seq)\n",
    "        omni2_embed = self.omni2_pos(omni2_embed)\n",
    "        omni2_key_mask = (~omni2_mask.bool()).any(dim=-1) if omni2_mask is not None else None\n",
    "        omni2_out = self.omni2_encoder(omni2_embed, src_key_padding_mask=omni2_key_mask)\n",
    "        omni2_summary = omni2_out.mean(dim=1)\n",
    "\n",
    "        if goes_seq.shape[1] > 1024:\n",
    "            step = goes_seq.shape[1] // 1024\n",
    "            goes_seq = goes_seq[:, ::step, :]\n",
    "            goes_mask = goes_mask[:, ::step, :] if goes_mask is not None else None\n",
    "\n",
    "        goes_embed = self.goes_proj(goes_seq)\n",
    "        goes_embed = self.goes_pos(goes_embed)\n",
    "        goes_key_mask = (~goes_mask.bool()).any(dim=-1) if goes_mask is not None else None\n",
    "        goes_out = self.goes_encoder(goes_embed, src_key_padding_mask=goes_key_mask)\n",
    "        goes_summary = goes_out.mean(dim=1)\n",
    "\n",
    "        combined = torch.cat((static_embed, omni2_summary, goes_summary), dim=-1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "# -----------------------------------\n",
    "# Masked MSE Loss\n",
    "# -----------------------------------\n",
    "def masked_mse_loss(preds, targets, mask, eps=1e-8):\n",
    "    preds = torch.nan_to_num(preds, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    targets = torch.nan_to_num(targets, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    loss = (preds - targets) ** 2 * mask\n",
    "    return loss.sum() / (mask.sum() + eps)\n",
    "\n",
    "# -----------------------------------\n",
    "# Full Training Loop with FullDataset\n",
    "# -----------------------------------\n",
    "def train_storm_transformer(initial_states_df, num_epochs=3, batch_size=4, lr=1e-4, device=None):\n",
    "    #from full_dataset import FullDataset  # Ensure your FullDataset class is in a separate file\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    dataset = FullDataset(initial_states_df)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = STORMTransformer().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in tqdm(dataloader):\n",
    "            (static_input, \n",
    "             density_tensor, \n",
    "             density_mask_tensor, \n",
    "             goes_tensor, \n",
    "             goes_mask_tensor, \n",
    "             omni2_tensor, \n",
    "             omni2_mask_tensor, \n",
    "             _) = batch\n",
    "\n",
    "            static_input = static_input.to(device)\n",
    "            density_tensor = density_tensor.to(device)\n",
    "            density_mask_tensor = density_mask_tensor.to(device)\n",
    "            goes_tensor = goes_tensor.to(device)\n",
    "            goes_mask_tensor = goes_mask_tensor.to(device)\n",
    "            omni2_tensor = omni2_tensor.to(device)\n",
    "            omni2_mask_tensor = omni2_mask_tensor.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(static_input, omni2_tensor, goes_tensor, omni2_mask_tensor, goes_mask_tensor)\n",
    "            loss = masked_mse_loss(preds, density_tensor, density_mask_tensor)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        batch_average_loss = total_loss/len(dataloader)\n",
    "        losses.append(batch_average_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {batch_average_loss:.15f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Positional Encoding for Sequences\n",
    "# -----------------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=10000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000.0) / d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# -----------------------------------\n",
    "# STORMTransformer with Mask Handling\n",
    "# -----------------------------------\n",
    "class STORMTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 static_dim=9,\n",
    "                 omni2_dim=57,\n",
    "                 goes_dim=42,\n",
    "                 d_model=128,\n",
    "                 output_len=432,\n",
    "                 nhead=4,\n",
    "                 num_layers=2,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "\n",
    "        self.omni2_proj = nn.Linear(omni2_dim, d_model)\n",
    "        self.goes_proj = nn.Linear(goes_dim, d_model)\n",
    "\n",
    "        self.omni2_pos = PositionalEncoding(d_model)\n",
    "        self.goes_pos = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.omni2_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.goes_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, output_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, static_input, omni2_seq, goes_seq, omni2_mask=None, goes_mask=None):\n",
    "        B = static_input.size(0)\n",
    "\n",
    "        static_embed = self.static_encoder(static_input)\n",
    "\n",
    "        omni2_embed = self.omni2_proj(omni2_seq)\n",
    "        omni2_embed = self.omni2_pos(omni2_embed)\n",
    "        omni2_key_mask = (~omni2_mask.bool()).any(dim=-1) if omni2_mask is not None else None\n",
    "        omni2_out = self.omni2_encoder(omni2_embed, src_key_padding_mask=omni2_key_mask)\n",
    "        omni2_summary = omni2_out.mean(dim=1)\n",
    "\n",
    "        if goes_seq.shape[1] > 1024:\n",
    "            step = goes_seq.shape[1] // 1024\n",
    "            goes_seq = goes_seq[:, ::step, :]\n",
    "            goes_mask = goes_mask[:, ::step, :] if goes_mask is not None else None\n",
    "\n",
    "        goes_embed = self.goes_proj(goes_seq)\n",
    "        goes_embed = self.goes_pos(goes_embed)\n",
    "        goes_key_mask = (~goes_mask.bool()).any(dim=-1) if goes_mask is not None else None\n",
    "        goes_out = self.goes_encoder(goes_embed, src_key_padding_mask=goes_key_mask)\n",
    "        goes_summary = goes_out.mean(dim=1)\n",
    "\n",
    "        combined = torch.cat((static_embed, omni2_summary, goes_summary), dim=-1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "# -----------------------------------\n",
    "# Masked MSE Loss\n",
    "# -----------------------------------\n",
    "def masked_mse_loss(preds, targets, mask):\n",
    "    diff = (targets - preds) * mask\n",
    "    sq = torch.square(diff)\n",
    "    sum = torch.sum(sq)\n",
    "    N = torch.sum(mask)\n",
    "    # print(sum)\n",
    "    # print(N)\n",
    "    loss = torch.sqrt((sum/N))\n",
    "    return loss\n",
    "\n",
    "# -----------------------------------\n",
    "# Full Training Loop with FullDataset\n",
    "# -----------------------------------\n",
    "train_losses =[]\n",
    "val_losses= []\n",
    "def train_storm_transformer(initial_states_df, num_epochs=10, batch_size=16, lr=1e-4, device=None):\n",
    "    #from full_dataset import FullDataset\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    # 🔀 Split into train and val\n",
    "    train_df, val_df = train_test_split(initial_states_df, test_size=0.05)\n",
    "\n",
    "    train_dataset = FullDataset(train_df)\n",
    "    val_dataset = FullDataset(val_df)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = STORMTransformer().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader):\n",
    "            static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = [b.to(device) for b in batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "            loss = masked_mse_loss(preds, density, density_mask)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # 🔍 Validation\n",
    "        total_val_loss = 0.0\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(val_loader):\n",
    "                    static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = [b.to(device) for b in batch]\n",
    "                    preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "                    loss = masked_mse_loss(preds, density, density_mask)\n",
    "                    total_val_loss += loss.item()\n",
    "        except:\n",
    "            print(\"Didnt work\")\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} — Train Loss: {avg_train_loss} | Val Loss: {avg_val_loss}\")\n",
    "\n",
    "        # 💾 Save if improved\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_path = f\"checkpoints/storm_epoch_{epoch+1}.pt\"\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"✅ Model improved. Saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/483 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:27<00:00,  3.29s/it]\n",
      "100%|██████████| 26/26 [01:19<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 — Train Loss: 0.011633931810526065 | Val Loss: 0.005352307702056491\n",
      "✅ Model improved. Saved to: checkpoints/storm_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:23<00:00,  3.28s/it]\n",
      "100%|██████████| 26/26 [01:20<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 — Train Loss: 0.00382988435008002 | Val Loss: 0.0029437169880391313\n",
      "✅ Model improved. Saved to: checkpoints/storm_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:25<00:00,  3.28s/it]\n",
      "100%|██████████| 26/26 [01:20<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 — Train Loss: 0.002602643213103724 | Val Loss: 0.0020691500349829975\n",
      "✅ Model improved. Saved to: checkpoints/storm_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:24<00:00,  3.28s/it]\n",
      "100%|██████████| 26/26 [01:19<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 — Train Loss: 0.001390635460076707 | Val Loss: 0.000812962277380463\n",
      "✅ Model improved. Saved to: checkpoints/storm_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:27<00:00,  3.29s/it]\n",
      "100%|██████████| 26/26 [01:19<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 — Train Loss: 0.00010495477069448601 | Val Loss: 4.936498586315653e-06\n",
      "✅ Model improved. Saved to: checkpoints/storm_epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:25<00:00,  3.28s/it]\n",
      "100%|██████████| 26/26 [01:20<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 — Train Loss: 4.595014123037376e-06 | Val Loss: 3.857655288951579e-06\n",
      "✅ Model improved. Saved to: checkpoints/storm_epoch_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:26<00:00,  3.28s/it]\n",
      "100%|██████████| 26/26 [01:19<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 — Train Loss: 4.83784419065504e-06 | Val Loss: 3.2902886372399876e-06\n",
      "✅ Model improved. Saved to: checkpoints/storm_epoch_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:26<00:00,  3.28s/it]\n",
      "100%|██████████| 26/26 [01:19<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 — Train Loss: 7.11319532077915e-06 | Val Loss: 6.818886609275628e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:26<00:00,  3.29s/it]\n",
      "100%|██████████| 26/26 [01:19<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 — Train Loss: 6.3424163616079376e-06 | Val Loss: 4.264409653842449e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:10<00:00,  3.25s/it]\n",
      "100%|██████████| 26/26 [01:19<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 — Train Loss: 4.224208920827145e-06 | Val Loss: 3.6963406448474134e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:28<00:00,  3.29s/it]\n",
      "100%|██████████| 26/26 [01:19<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 — Train Loss: 4.336992924059742e-06 | Val Loss: 3.195294250592549e-06\n",
      "✅ Model improved. Saved to: checkpoints/storm_epoch_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:26<00:00,  3.29s/it]\n",
      "100%|██████████| 26/26 [01:19<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 — Train Loss: 4.374549327121054e-06 | Val Loss: 3.5555588930527356e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:28<00:00,  3.29s/it]\n",
      "100%|██████████| 26/26 [01:20<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 — Train Loss: 3.3975865500141865e-05 | Val Loss: 3.941598046926979e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:27<00:00,  3.29s/it]\n",
      "100%|██████████| 26/26 [01:19<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 — Train Loss: 4.338248628370461e-06 | Val Loss: 5.75980201434644e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:26<00:00,  3.28s/it]\n",
      "100%|██████████| 26/26 [01:19<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 — Train Loss: 4.3511188521180255e-06 | Val Loss: 4.536636459726231e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:26<00:00,  3.28s/it]\n",
      "100%|██████████| 26/26 [01:20<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 — Train Loss: 4.097751099729119e-06 | Val Loss: 3.5075801966181293e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [26:26<00:00,  3.29s/it]\n",
      "100%|██████████| 26/26 [01:20<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 — Train Loss: 4.202842442367153e-06 | Val Loss: 4.47616730525624e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 191/483 [10:29<16:02,  3.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_storm_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_states_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 124\u001b[39m, in \u001b[36mtrain_storm_transformer\u001b[39m\u001b[34m(initial_states_df, num_epochs, batch_size, lr, device)\u001b[39m\n\u001b[32m    121\u001b[39m model.train()\n\u001b[32m    122\u001b[39m total_train_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mFullDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     38\u001b[39m density_df_mask_tensor = torch.tensor(density_df_mask.iloc[:,\u001b[32m1\u001b[39m].values, dtype=torch.float32)\n\u001b[32m     39\u001b[39m density_stacked = torch.stack((density_tensor,density_df_mask_tensor))\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m goes_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoes_file\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m goes_df.shape[\u001b[32m0\u001b[39m] > \u001b[38;5;28mself\u001b[39m.goes_length:\n\u001b[32m     43\u001b[39m     goes_df = goes_df[goes_df.shape[\u001b[32m0\u001b[39m]-\u001b[38;5;28mself\u001b[39m.goes_length:goes_df.shape[\u001b[32m0\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:334\u001b[39m, in \u001b[36mgetstate\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_storm_transformer(initial_states_normalized,num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 965/965 [28:15<00:00,  1.76s/it]\n",
      " 10%|▉         | 5/51 [00:09<01:26,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Didnt work\n",
      "Epoch 1/20 — Train Loss: 0.00026589945274455847 | Val Loss: 0.00000013971743319595\n",
      "✅ Model improved. Saved to: checkpoints/storm_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 965/965 [28:07<00:00,  1.75s/it]\n",
      " 10%|▉         | 5/51 [00:09<01:27,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Didnt work\n",
      "Epoch 2/20 — Train Loss: 0.00001941913264528798 | Val Loss: 0.00000025277192354920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 267/965 [07:55<20:41,  1.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_storm_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_states_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mtrain_storm_transformer\u001b[39m\u001b[34m(initial_states_df, num_epochs, batch_size, lr, device)\u001b[39m\n\u001b[32m    117\u001b[39m model.train()\n\u001b[32m    118\u001b[39m total_train_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mFullDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     38\u001b[39m density_df_mask_tensor = torch.tensor(density_df_mask.iloc[:,\u001b[32m1\u001b[39m].values, dtype=torch.float32)\n\u001b[32m     39\u001b[39m density_stacked = torch.stack((density_tensor,density_df_mask_tensor))\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m goes_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoes_file\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m goes_df.shape[\u001b[32m0\u001b[39m] > \u001b[38;5;28mself\u001b[39m.goes_length:\n\u001b[32m     43\u001b[39m     goes_df = goes_df[goes_df.shape[\u001b[32m0\u001b[39m]-\u001b[38;5;28mself\u001b[39m.goes_length:goes_df.shape[\u001b[32m0\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:334\u001b[39m, in \u001b[36mgetstate\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_storm_transformer(initial_states_normalized,num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(val_loader):\n\u001b[32m      7\u001b[39m     static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = [b.to(device) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     preds = \u001b[43mmodel\u001b[49m(static_input, omni2, goes, omni2_mask, goes_mask)\n\u001b[32m      9\u001b[39m     loss = masked_mse_loss(preds, density, density_mask)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(initial_states_normalized, test_size=0.1, random_state=42)\n",
    "val_dataset = FullDataset(val_df)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "for epoch in range(10):\n",
    "    for batch in tqdm(val_loader):\n",
    "        static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = [b.to(device) for b in batch]\n",
    "        preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "        loss = masked_mse_loss(preds, density, density_mask)\n",
    "        print(loss)\n",
    "        total_val_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_storm_transformer(initial_states_df, num_epochs=10, batch_size=8, lr=1e-4, device=None):\n",
    "    from full_dataset import FullDataset\n",
    "    from storm_transformer import STORMTransformer, masked_mse_loss\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    # 🔀 Train/validation split\n",
    "    train_df, val_df = train_test_split(initial_states_df, test_size=0.05, random_state=42)\n",
    "\n",
    "    train_dataset = FullDataset(train_df)\n",
    "    val_dataset = FullDataset(val_df)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = STORMTransformer().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    checkpoint_path = \"checkpoints/storm_last.pt\"\n",
    "    best_model_path = \"checkpoints/storm_best.pt\"\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    # 🔁 Resume support\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"🔁 Resuming from checkpoint: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint.get('epoch', 0)\n",
    "        best_val_loss = checkpoint.get('val_loss', float(\"inf\"))\n",
    "\n",
    "    # 🚀 Training loop\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        print(f\"\\n🚀 Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for batch in tqdm(train_loader):\n",
    "            static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask, _ = batch\n",
    "\n",
    "            static_input = static_input.to(device)\n",
    "            density = density.to(device)\n",
    "            density_mask = density_mask.to(device)\n",
    "            goes = goes.to(device)\n",
    "            goes_mask = goes_mask.to(device)\n",
    "            omni2 = omni2.to(device)\n",
    "            omni2_mask = omni2_mask.to(device)\n",
    "\n",
    "            if (omni2_mask.any(dim=-1).sum(dim=1) == 0).any() or (goes_mask.any(dim=-1).sum(dim=1) == 0).any():\n",
    "                print(\"⚠️ Skipping batch with fully masked inputs\")\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "            loss = masked_mse_loss(preds, density, density_mask)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # 🧪 Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask, _ = batch\n",
    "\n",
    "                static_input = static_input.to(device)\n",
    "                density = density.to(device)\n",
    "                density_mask = density_mask.to(device)\n",
    "                goes = goes.to(device)\n",
    "                goes_mask = goes_mask.to(device)\n",
    "                omni2 = omni2.to(device)\n",
    "                omni2_mask = omni2_mask.to(device)\n",
    "\n",
    "                if (omni2_mask.any(dim=-1).sum(dim=1) == 0).any() or (goes_mask.any(dim=-1).sum(dim=1) == 0).any():\n",
    "                    continue\n",
    "\n",
    "                preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "                loss = masked_mse_loss(preds, density, density_mask)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # 🧠 Mask diagnostics\n",
    "                goes_mask_sum = goes_mask.sum().item()\n",
    "                omni2_mask_sum = omni2_mask.sum().item()\n",
    "                density_mask_sum = density_mask.sum().item()\n",
    "\n",
    "                print(f\"🧪 Eval Batch {batch_idx+1}/{len(val_loader)} — \"\n",
    "                      f\"OMNI2 Mask Sum: {omni2_mask_sum} | \"\n",
    "                      f\"GOES Mask Sum: {goes_mask_sum} | \"\n",
    "                      f\"Density Mask Sum: {density_mask_sum}\")\n",
    "\n",
    "                # ⚠️ Alert if any mask has < 10% coverage\n",
    "                if omni2_mask_sum < 0.1 * omni2_mask.numel():\n",
    "                    print(\"⚠️ Low OMNI2 coverage in this batch!\")\n",
    "                if goes_mask_sum < 0.1 * goes_mask.numel():\n",
    "                    print(\"⚠️ Low GOES coverage in this batch!\")\n",
    "                if density_mask_sum < 0.1 * density_mask.numel():\n",
    "                    print(\"⚠️ Low density mask coverage in this batch!\")\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"\\n📊 Epoch {epoch+1}/{num_epochs} — \"\n",
    "              f\"Train Loss: {avg_train_loss:.20f} | Val Loss: {avg_val_loss:.20f}\")\n",
    "\n",
    "        # 💾 Save full checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': avg_val_loss\n",
    "        }, checkpoint_path)\n",
    "\n",
    "        # 💎 Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(\"✅ Best model updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Positional Encoding for Sequences\n",
    "# -----------------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=10000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000.0) / d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# -----------------------------------\n",
    "# STORMTransformer with Mask Handling\n",
    "# -----------------------------------\n",
    "class STORMTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 static_dim=9,\n",
    "                 omni2_dim=57,\n",
    "                 goes_dim=42,\n",
    "                 d_model=128,\n",
    "                 output_len=432,\n",
    "                 nhead=4,\n",
    "                 num_layers=2,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "\n",
    "        self.omni2_proj = nn.Linear(omni2_dim, d_model)\n",
    "        self.goes_proj = nn.Linear(goes_dim, d_model)\n",
    "\n",
    "        self.omni2_pos = PositionalEncoding(d_model)\n",
    "        self.goes_pos = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.omni2_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.goes_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, output_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, static_input, omni2_seq, goes_seq, omni2_mask=None, goes_mask=None):\n",
    "        B = static_input.size(0)\n",
    "\n",
    "        static_embed = self.static_encoder(static_input)\n",
    "\n",
    "        omni2_embed = self.omni2_proj(omni2_seq)\n",
    "        omni2_embed = self.omni2_pos(omni2_embed)\n",
    "        omni2_key_mask = (~omni2_mask.bool()).any(dim=-1) if omni2_mask is not None else None\n",
    "        omni2_out = self.omni2_encoder(omni2_embed, src_key_padding_mask=omni2_key_mask)\n",
    "        omni2_summary = omni2_out.mean(dim=1)\n",
    "\n",
    "        if goes_seq.shape[1] > 1024:\n",
    "            step = goes_seq.shape[1] // 1024\n",
    "            goes_seq = goes_seq[:, ::step, :]\n",
    "            goes_mask = goes_mask[:, ::step, :] if goes_mask is not None else None\n",
    "        global tester_mask\n",
    "        global tester_seq\n",
    "        tester_seq = goes_seq\n",
    "        tester_mask = goes_mask\n",
    "        #print(goes_seq,\"\\n\",goes_mask)\n",
    "        #print(goes_mask.sum())\n",
    "        goes_embed = self.goes_proj(goes_seq)\n",
    "        goes_embed = self.goes_pos(goes_embed)\n",
    "        goes_key_mask = (~goes_mask.bool()).any(dim=-1) if goes_mask is not None else None\n",
    "        global tester_key_mask\n",
    "        global tester_embed\n",
    "        tester_embed = goes_embed\n",
    "        tester_key_mask = goes_key_mask\n",
    "        goes_out = self.goes_encoder(goes_embed, src_key_padding_mask=goes_key_mask)\n",
    "        goes_summary = goes_out.mean(dim=1)\n",
    "\n",
    "        combined = torch.cat((static_embed, omni2_summary, goes_summary), dim=-1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "# -----------------------------------\n",
    "# Masked MSE Loss\n",
    "# -----------------------------------\n",
    "def masked_mse_loss(preds, targets, mask, eps=1e-8):\n",
    "    preds = torch.nan_to_num(preds, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    targets = torch.nan_to_num(targets, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    loss = (preds - targets) ** 2 * mask\n",
    "    return loss.sum() / (mask.sum() + eps)\n",
    "\n",
    "# -----------------------------------\n",
    "# Full Training Loop with FullDataset\n",
    "# -----------------------------------\n",
    "train_losses =[]\n",
    "val_losses= []\n",
    "def eval_storm_transformer(initial_states_df, num_epochs=10, batch_size=4, lr=1e-4, device=None):\n",
    "    #from full_dataset import FullDataset\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    # 🔀 Split into train and val\n",
    "    train_df, val_df = train_test_split(initial_states_df, test_size=0.05)\n",
    "\n",
    "    train_dataset = FullDataset(train_df)\n",
    "    val_dataset = FullDataset(val_df)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = STORMTransformer().to(device)\n",
    "    model.load_state_dict(torch.load(\"checkpoints/storm_epoch_10.pt\", weights_only=True))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "\n",
    "        # 🔍 Validation\n",
    "        model.train()\n",
    "        total_val_loss = 0.0\n",
    "        #try:\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader):\n",
    "                static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = batch\n",
    "\n",
    "                static_input = static_input.to(device)\n",
    "                density = density.to(device)\n",
    "                density_mask = density_mask.to(device)\n",
    "                goes = goes.to(device)\n",
    "                goes_mask = goes_mask.to(device)\n",
    "                omni2 = omni2.to(device)\n",
    "                omni2_mask = omni2_mask.to(device)\n",
    "                valid_goes = goes_mask.any(dim=-1).sum(dim=1) > 0  # (B,)\n",
    "                valid_omni2 = omni2_mask.any(dim=-1).sum(dim=1) > 0  # (B,)\n",
    "                valid_mask = valid_goes & valid_omni2\n",
    "\n",
    "                # Skip batch if any sample is fully masked\n",
    "                # if not valid_mask.all():\n",
    "                #     print(\"⚠️ Skipping eval batch due to fully masked sample(s).\")\n",
    "                #     continue\n",
    "                preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "                loss = masked_mse_loss(preds, density, density_mask)\n",
    "                total_val_loss += loss.item()\n",
    "        #except:\n",
    "         #   print(\"Didnt work\")\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Val Loss: {avg_val_loss}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working train loop testing eval\n",
    "\n",
    "# -----------------------------------\n",
    "# Positional Encoding for Sequences\n",
    "# -----------------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=10000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000.0) / d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# -----------------------------------\n",
    "# STORMTransformer with Mask Handling\n",
    "# -----------------------------------\n",
    "class STORMTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 static_dim=9,\n",
    "                 omni2_dim=57,\n",
    "                 goes_dim=42,\n",
    "                 d_model=128,\n",
    "                 output_len=432,\n",
    "                 nhead=4,\n",
    "                 num_layers=2,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "\n",
    "        self.omni2_proj = nn.Linear(omni2_dim, d_model)\n",
    "        self.goes_proj = nn.Linear(goes_dim, d_model)\n",
    "\n",
    "        self.omni2_pos = PositionalEncoding(d_model)\n",
    "        self.goes_pos = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.omni2_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.goes_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, output_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, static_input, omni2_seq, goes_seq, omni2_mask=None, goes_mask=None):\n",
    "        B = static_input.size(0)\n",
    "\n",
    "        static_embed = self.static_encoder(static_input)\n",
    "\n",
    "        omni2_embed = self.omni2_proj(omni2_seq)\n",
    "        omni2_embed = self.omni2_pos(omni2_embed)\n",
    "        omni2_key_mask = (~omni2_mask.bool()).any(dim=-1) if omni2_mask is not None else None\n",
    "        omni2_out = self.omni2_encoder(omni2_embed, src_key_padding_mask=omni2_key_mask)\n",
    "        omni2_summary = omni2_out.mean(dim=1)\n",
    "\n",
    "        if goes_seq.shape[1] > 1024:\n",
    "            step = goes_seq.shape[1] // 1024\n",
    "            goes_seq = goes_seq[:, ::step, :]\n",
    "            goes_mask = goes_mask[:, ::step, :] if goes_mask is not None else None\n",
    "\n",
    "        goes_embed = self.goes_proj(goes_seq)\n",
    "        goes_embed = self.goes_pos(goes_embed)\n",
    "        goes_key_mask = (~goes_mask.bool()).any(dim=-1) if goes_mask is not None else None\n",
    "        goes_out = self.goes_encoder(goes_embed, src_key_padding_mask=goes_key_mask)\n",
    "        goes_summary = goes_out.mean(dim=1)\n",
    "\n",
    "        combined = torch.cat((static_embed, omni2_summary, goes_summary), dim=-1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "# -----------------------------------\n",
    "# Masked MSE Loss\n",
    "# -----------------------------------\n",
    "def masked_mse_loss(preds, targets, mask, eps=1e-8):\n",
    "    preds = torch.nan_to_num(preds, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    targets = torch.nan_to_num(targets, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    loss = (preds - targets) ** 2 * mask\n",
    "    return loss.sum() / (mask.sum() + eps)\n",
    "\n",
    "# -----------------------------------\n",
    "# Full Training Loop with FullDataset\n",
    "# -----------------------------------\n",
    "def reEval_storm_transformer(initial_states_df, num_epochs=3, batch_size=8, lr=1e-4, device=None):\n",
    "    #from full_dataset import FullDataset  # Ensure your FullDataset class is in a separate file\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_df, val_df = train_test_split(initial_states_df, test_size=0.05)\n",
    "\n",
    "    train_dataset = FullDataset(train_df)\n",
    "    val_dataset = FullDataset(val_df)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = STORMTransformer().to(device)\n",
    "    model.load_state_dict(torch.load(\"checkpoints/storm_epoch_10.pt\", weights_only=True))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader):\n",
    "                (static_input, \n",
    "                density_tensor, \n",
    "                density_mask_tensor, \n",
    "                goes_tensor, \n",
    "                goes_mask_tensor, \n",
    "                omni2_tensor, \n",
    "                omni2_mask_tensor, \n",
    "                _) = batch\n",
    "\n",
    "                static_input = static_input.to(device)\n",
    "                density_tensor = density_tensor.to(device)\n",
    "                density_mask_tensor = density_mask_tensor.to(device)\n",
    "                goes_tensor = goes_tensor.to(device)\n",
    "                goes_mask_tensor = goes_mask_tensor.to(device)\n",
    "                omni2_tensor = omni2_tensor.to(device)\n",
    "                omni2_mask_tensor = omni2_mask_tensor.to(device)\n",
    "\n",
    "                preds = model(static_input, omni2_tensor, goes_tensor, omni2_mask_tensor, goes_mask_tensor)\n",
    "                loss = masked_mse_loss(preds, density_tensor, density_mask_tensor)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "        batch_average_loss = total_loss/len(val_loader)\n",
    "        losses.append(batch_average_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {batch_average_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 8, got 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mreEval_storm_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_states_normalized\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 117\u001b[39m, in \u001b[36mreEval_storm_transformer\u001b[39m\u001b[34m(initial_states_df, num_epochs, batch_size, lr, device)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(val_loader):\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m         (static_input, \n\u001b[32m    118\u001b[39m         density_tensor, \n\u001b[32m    119\u001b[39m         density_mask_tensor, \n\u001b[32m    120\u001b[39m         goes_tensor, \n\u001b[32m    121\u001b[39m         goes_mask_tensor, \n\u001b[32m    122\u001b[39m         omni2_tensor, \n\u001b[32m    123\u001b[39m         omni2_mask_tensor, \n\u001b[32m    124\u001b[39m         _) = batch\n\u001b[32m    126\u001b[39m         static_input = static_input.to(device)\n\u001b[32m    127\u001b[39m         density_tensor = density_tensor.to(device)\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 8, got 7)"
     ]
    }
   ],
   "source": [
    "reEval_storm_transformer(initial_states_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8232\n",
      "8232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function Tensor.size>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester_key_mask_int = tester_key_mask.\n",
    "if tester_key_mask.any() == False:\n",
    "    print (\"yes\")\n",
    "print ((tester_key_mask.size()[0]*tester_key_mask.size()[1]))\n",
    "print (np.count_nonzero(tester_key_mask.to(\"cpu\")))\n",
    "\n",
    "tester_embed.size\n",
    "# if tester_embed == 0.9454:\n",
    "#     print (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 20.00 MiB is free. Process 5350 has 1.27 GiB memory in use. Including non-PyTorch memory, this process has 5.53 GiB memory in use. Of the allocated memory 5.24 GiB is allocated by PyTorch, and 161.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43meval_storm_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_states_normalized\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 152\u001b[39m, in \u001b[36meval_storm_transformer\u001b[39m\u001b[34m(initial_states_df, num_epochs, batch_size, lr, device)\u001b[39m\n\u001b[32m    146\u001b[39m valid_mask = valid_goes & valid_omni2\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# Skip batch if any sample is fully masked\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# if not valid_mask.all():\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m#     print(\"⚠️ Skipping eval batch due to fully masked sample(s).\")\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m#     continue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m loss = masked_mse_loss(preds, density, density_mask)\n\u001b[32m    154\u001b[39m total_val_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mSTORMTransformer.forward\u001b[39m\u001b[34m(self, static_input, omni2_seq, goes_seq, omni2_mask, goes_mask)\u001b[39m\n\u001b[32m     61\u001b[39m omni2_embed = \u001b[38;5;28mself\u001b[39m.omni2_pos(omni2_embed)\n\u001b[32m     62\u001b[39m omni2_key_mask = (~omni2_mask.bool()).any(dim=-\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m omni2_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m omni2_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43momni2_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43momni2_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43momni2_key_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m omni2_summary = omni2_out.mean(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m goes_seq.shape[\u001b[32m1\u001b[39m] > \u001b[32m1024\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/nn/modules/transformer.py:517\u001b[39m, in \u001b[36mTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    514\u001b[39m is_causal = _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[32m    525\u001b[39m     output = output.to_padded_tensor(\u001b[32m0.0\u001b[39m, src.size())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/nn/modules/transformer.py:922\u001b[39m, in \u001b[36mTransformerEncoderLayer.forward\u001b[39m\u001b[34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    918\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m    919\u001b[39m         x\n\u001b[32m    920\u001b[39m         + \u001b[38;5;28mself\u001b[39m._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal)\n\u001b[32m    921\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/nn/modules/transformer.py:947\u001b[39m, in \u001b[36mTransformerEncoderLayer._ff_block\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.linear2(\u001b[38;5;28mself\u001b[39m.dropout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m    948\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout2(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/app/py_torch/lib/python3.13/site-packages/torch/nn/functional.py:1704\u001b[39m, in \u001b[36mrelu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   1702\u001b[39m     result = torch.relu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1703\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1704\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 20.00 MiB is free. Process 5350 has 1.27 GiB memory in use. Including non-PyTorch memory, this process has 5.53 GiB memory in use. Of the allocated memory 5.24 GiB is allocated by PyTorch, and 161.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "eval_storm_transformer(initial_states_normalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
