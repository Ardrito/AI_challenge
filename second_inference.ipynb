{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3026e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.transforms as transformers\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import math\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b475574",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states = []\n",
    "\n",
    "path = \"input_data/\"\n",
    "\n",
    "for dir, sub_dir, files in os.walk(path):\n",
    "    for file in sorted(files):\n",
    "        #print(file)\n",
    "        temp = pd.read_csv((path+file),index_col=None, header=0)\n",
    "        initial_states.append(temp)\n",
    "\n",
    "initial_states_df = pd.concat(initial_states,axis=0,ignore_index=True)\n",
    "\n",
    "hold = initial_states_df\n",
    "x = initial_states_df.iloc[:,2:].values\n",
    "x = normalize(x,norm='l2')\n",
    "hold = pd.concat([hold['File ID'],pd.DataFrame(x)],axis=1)\n",
    "initial_states_normalized = hold\n",
    "#'2000-08-02 04:50:33'\n",
    "timestamps = initial_states_df['Timestamp']\n",
    "#initial_states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e980523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullDatasetPT(Dataset):\n",
    "    def __init__(self, initial_states_df, pt_dir='data/processed/pt_files'):\n",
    "        self.data = initial_states_df.reset_index(drop=True)\n",
    "        self.pt_dir = pt_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        file_id = str(int(row['File ID'])).zfill(5)\n",
    "        pt_path = os.path.join(self.pt_dir, f\"{file_id}.pt\")\n",
    "\n",
    "        if not os.path.exists(pt_path):\n",
    "            raise FileNotFoundError(f\".pt file not found for File ID: {file_id}\")\n",
    "\n",
    "        static_input = torch.tensor(row.drop(\"File ID\").fillna(0.0).values, dtype=torch.float32)\n",
    "        pt_data = torch.load(pt_path)\n",
    "\n",
    "        return (\n",
    "            static_input,\n",
    "            pt_data[\"density\"],\n",
    "            pt_data[\"density_mask\"],\n",
    "            pt_data[\"goes\"],\n",
    "            pt_data[\"goes_mask\"],\n",
    "            pt_data[\"omni2\"],\n",
    "            pt_data[\"omni2_mask\"]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd2593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Positional Encoding for Sequences\n",
    "# -----------------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=10000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000.0) / d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# -----------------------------------\n",
    "# STORMTransformer with Mask Handling\n",
    "# -----------------------------------\n",
    "class STORMTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 static_dim=9,\n",
    "                 omni2_dim=57,\n",
    "                 goes_dim=42,\n",
    "                 d_model=256,\n",
    "                 output_len=432,\n",
    "                 nhead=8,\n",
    "                 num_layers=4,\n",
    "                 dropout=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.static_encoder = nn.Sequential(\n",
    "            nn.Linear(static_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "\n",
    "        self.omni2_proj = nn.Linear(omni2_dim, d_model)\n",
    "        self.goes_proj = nn.Linear(goes_dim, d_model)\n",
    "\n",
    "        self.omni2_pos = PositionalEncoding(d_model)\n",
    "        self.goes_pos = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.omni2_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.goes_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256,360),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(360, output_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, static_input, omni2_seq, goes_seq, omni2_mask=None, goes_mask=None):\n",
    "        B = static_input.size(0)\n",
    "\n",
    "        static_embed = self.static_encoder(static_input)\n",
    "\n",
    "        omni2_embed = self.omni2_proj(omni2_seq)\n",
    "        omni2_embed = self.omni2_pos(omni2_embed)\n",
    "        omni2_key_mask = (~omni2_mask.bool()).any(dim=-1) if omni2_mask is not None else None\n",
    "        omni2_out = self.omni2_encoder(omni2_embed, src_key_padding_mask=omni2_key_mask)\n",
    "        omni2_summary = omni2_out.mean(dim=1)\n",
    "\n",
    "        if goes_seq.shape[1] > 1024:\n",
    "            step = goes_seq.shape[1] // 1024\n",
    "            goes_seq = goes_seq[:, ::step, :]\n",
    "            goes_mask = goes_mask[:, ::step, :] if goes_mask is not None else None\n",
    "        global tester_mask\n",
    "        global tester_seq\n",
    "        tester_seq = goes_seq\n",
    "        tester_mask = goes_mask\n",
    "        #print(goes_seq,\"\\n\",goes_mask)\n",
    "        #print(goes_mask.sum())\n",
    "        goes_embed = self.goes_proj(goes_seq)\n",
    "        goes_embed = self.goes_pos(goes_embed)\n",
    "        goes_key_mask = (~goes_mask.bool()).any(dim=-1) if goes_mask is not None else None\n",
    "        global tester_key_mask\n",
    "        global tester_embed\n",
    "        tester_embed = goes_embed\n",
    "        tester_key_mask = goes_key_mask\n",
    "        goes_out = self.goes_encoder(goes_embed, src_key_padding_mask=goes_key_mask)\n",
    "        goes_summary = goes_out.mean(dim=1)\n",
    "\n",
    "        combined = torch.cat((static_embed, omni2_summary, goes_summary), dim=-1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "# -----------------------------------\n",
    "# Masked MSE Loss\n",
    "# -----------------------------------\n",
    "def masked_mse_loss(preds, targets, mask, eps=1e-8):\n",
    "    # preds = torch.nan_to_num(preds, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    # targets = torch.nan_to_num(targets, nan=0.0, posinf=1e3, neginf=0.0)\n",
    "    # loss = (preds - targets) ** 2 * mask\n",
    "    # return loss.sum() / (mask.sum() + eps)\n",
    "    diff = (targets - preds) * mask\n",
    "    sq = torch.square(diff)\n",
    "    sum = torch.sum(sq)\n",
    "    N = torch.sum(mask)\n",
    "    # print(sum)\n",
    "    # print(N)\n",
    "    loss = torch.sqrt((sum/N))\n",
    "    return loss\n",
    "\n",
    "# -----------------------------------\n",
    "# Full Training Loop with FullDataset\n",
    "# -----------------------------------\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7e5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_storm_transformer(initial_states_df, num_epochs=10, batch_size=8, lr=1e-3, device=None):\n",
    "    # from full_dataset import FullDataset\n",
    "    # from storm_transformer import STORMTransformer, masked_mse_loss\n",
    "    torch.manual_seed(42)\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # üîÄ Train/validation split\n",
    "    train_df, val_df = train_test_split(initial_states_df, test_size=0.05, random_state=42)\n",
    "\n",
    "    train_dataset = FullDatasetPT(train_df)\n",
    "    val_dataset = FullDatasetPT(val_df)\n",
    "\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=8, pin_memory=True, )\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "\n",
    "    model = STORMTransformer().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    checkpoint_path = \"checkpoints/storm_last.pt\"\n",
    "    best_model_path = \"checkpoints/storm_best.pt\"\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    # üîÅ Resume support\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"üîÅ Resuming from checkpoint: {checkpoint_path}\")\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        # model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        # start_epoch = checkpoint.get('epoch', 0)\n",
    "        # best_val_loss = checkpoint.get('val_loss', float(\"inf\"))\n",
    "\n",
    "    # üöÄ Training loop\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        print(f\"\\nüöÄ Epoch {epoch + 1}/{num_epochs}\")\n",
    "        #start_load = time.time()\n",
    "        # for batch in tqdm(train_loader):\n",
    "        #     static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = batch\n",
    "        #     #nd_load = time.time()\n",
    "\n",
    "        #     static_input = static_input.to(device)\n",
    "        #     density = density.to(device)\n",
    "        #     density_mask = density_mask.to(device)\n",
    "        #     goes = goes.to(device)\n",
    "        #     goes_mask = goes_mask.to(device)\n",
    "        #     omni2 = omni2.to(device)\n",
    "        #     omni2_mask = omni2_mask.to(device)\n",
    "\n",
    "        #     # if (omni2_mask.any(dim=-1).sum(dim=1) == 0).any() or (goes_mask.any(dim=-1).sum(dim=1) == 0).any():\n",
    "        #     #     print(\"‚ö†Ô∏è Skipping batch with fully masked inputs\")\n",
    "        #     #     continue\n",
    "\n",
    "        #     optimizer.zero_grad()\n",
    "        #     preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "        #     #print (preds)\n",
    "        #     loss = masked_mse_loss(preds, density, density_mask)\n",
    "        #     loss.backward()\n",
    "        #     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        #     optimizer.step()\n",
    "\n",
    "        #     total_train_loss += loss.item()\n",
    "\n",
    "        #     #end_batch = time.time()\n",
    "\n",
    "        #     # print (\"Load time:\", end_load - start_load )\n",
    "        #     # print (\"Calc time:\", end_batch - end_load)\n",
    "\n",
    "        # avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # print (\"Preds:\", preds)\n",
    "        # print (\"Targets\",density)\n",
    "        # üß™ Validation\n",
    "        \n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                static_input, density, density_mask, goes, goes_mask, omni2, omni2_mask = batch\n",
    "\n",
    "                static_input = static_input.to(device)\n",
    "                density = density.to(device)\n",
    "                density_mask = density_mask.to(device)\n",
    "                goes = goes.to(device)\n",
    "                goes_mask = goes_mask.to(device)\n",
    "                omni2 = omni2.to(device)\n",
    "                omni2_mask = omni2_mask.to(device)\n",
    "\n",
    "                if (omni2_mask.any(dim=-1).sum(dim=1) == 0).any() or (goes_mask.any(dim=-1).sum(dim=1) == 0).any():\n",
    "                    continue\n",
    "\n",
    "                preds = model(static_input, omni2, goes, omni2_mask, goes_mask)\n",
    "                loss = masked_mse_loss(preds, density, density_mask)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # üß† Mask diagnostics\n",
    "                goes_mask_sum = goes_mask.sum().item()\n",
    "                omni2_mask_sum = omni2_mask.sum().item()\n",
    "                density_mask_sum = density_mask.sum().item()\n",
    "\n",
    "                print(f\"üß™ Eval Batch {batch_idx+1}/{len(val_loader)} ‚Äî \"\n",
    "                      f\"OMNI2 Mask Sum: {omni2_mask_sum} | \"\n",
    "                      f\"GOES Mask Sum: {goes_mask_sum} | \"\n",
    "                      f\"Density Mask Sum: {density_mask_sum}\")\n",
    "\n",
    "                # ‚ö†Ô∏è Alert if any mask has < 10% coverage\n",
    "                if omni2_mask_sum < 0.1 * omni2_mask.numel():\n",
    "                    print(\"‚ö†Ô∏è Low OMNI2 coverage in this batch!\")\n",
    "                if goes_mask_sum < 0.1 * goes_mask.numel():\n",
    "                    print(\"‚ö†Ô∏è Low GOES coverage in this batch!\")\n",
    "                if density_mask_sum < 0.1 * density_mask.numel():\n",
    "                    print(\"‚ö†Ô∏è Low density mask coverage in this batch!\")\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"\\nüìä Epoch {epoch+1}/{num_epochs} ‚Äî \"\n",
    "              f\"Val Loss: {avg_val_loss}\")\n",
    "        \n",
    "        print (\"Preds:\", preds)\n",
    "        print (\"Targets\",density)\n",
    "\n",
    "        # üíæ Save full checkpoint\n",
    "        # torch.save({\n",
    "        #     'epoch': epoch + 1,\n",
    "        #     'model_state_dict': model.state_dict(),\n",
    "        #     'optimizer_state_dict': optimizer.state_dict(),\n",
    "        #     'val_loss': avg_val_loss\n",
    "        # }, checkpoint_path)\n",
    "\n",
    "        # # üíé Save best model\n",
    "        # if avg_val_loss < best_val_loss:\n",
    "        #     best_val_loss = avg_val_loss\n",
    "        #     torch.save(model.state_dict(), best_model_path)\n",
    "        #     print(\"‚úÖ Best model updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f393f7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Resuming from checkpoint: checkpoints/storm_last.pt\n",
      "\n",
      "üöÄ Epoch 1/10\n",
      "üß™ Eval Batch 22/51 ‚Äî OMNI2 Mask Sum: 656640.0 | GOES Mask Sum: 5002624.0 | Density Mask Sum: 3364.0\n",
      "üß™ Eval Batch 28/51 ‚Äî OMNI2 Mask Sum: 656640.0 | GOES Mask Sum: 5302084.0 | Density Mask Sum: 3319.0\n",
      "üß™ Eval Batch 30/51 ‚Äî OMNI2 Mask Sum: 656640.0 | GOES Mask Sum: 5539086.0 | Density Mask Sum: 3358.0\n",
      "üß™ Eval Batch 47/51 ‚Äî OMNI2 Mask Sum: 656640.0 | GOES Mask Sum: 6195294.0 | Density Mask Sum: 3456.0\n",
      "\n",
      "üìä Epoch 1/10 ‚Äî Val Loss: 8.811491830320115e-06\n",
      "Preds: tensor([[ 3.1056e-05,  3.4915e-05,  1.7463e-04,  ...,  2.0950e-04,\n",
      "          8.5663e-05,  2.0908e-04],\n",
      "        [-3.5213e-05,  1.6214e-06,  1.5371e-04,  ..., -2.9411e-05,\n",
      "          1.1948e-04, -8.8779e-05],\n",
      "        [-3.5213e-05,  1.6214e-06,  1.5371e-04,  ..., -2.9411e-05,\n",
      "          1.1948e-04, -8.8779e-05],\n",
      "        ...,\n",
      "        [-3.5213e-05,  1.6214e-06,  1.5371e-04,  ..., -2.9411e-05,\n",
      "          1.1948e-04, -8.8779e-05],\n",
      "        [-3.4222e-05,  2.6450e-06,  1.5587e-04,  ..., -1.3329e-05,\n",
      "          1.1326e-04, -6.8517e-05],\n",
      "        [-3.5213e-05,  1.6214e-06,  1.5371e-04,  ..., -2.9411e-05,\n",
      "          1.1948e-04, -8.8779e-05]], device='cuda:0')\n",
      "Targets tensor([[1.3829e-13, 1.3859e-13, 1.3682e-13,  ..., 1.5377e-13, 1.5906e-13,\n",
      "         1.6171e-13],\n",
      "        [1.8301e-12, 1.8331e-12, 1.8207e-12,  ..., 1.5357e-12, 1.5355e-12,\n",
      "         1.5225e-12],\n",
      "        [1.1241e-12, 1.1153e-12, 1.1160e-12,  ..., 1.1185e-12, 1.1316e-12,\n",
      "         1.1142e-12],\n",
      "        [3.2781e-13, 3.2819e-13, 3.2564e-13,  ..., 3.0137e-13, 2.9789e-13,\n",
      "         2.9640e-13],\n",
      "        [5.1611e-12, 5.1743e-12, 5.1893e-12,  ..., 4.7765e-12, 4.7810e-12,\n",
      "         4.7847e-12],\n",
      "        [1.2604e-13, 1.2789e-13, 1.2860e-13,  ..., 1.7023e-13, 1.6933e-13,\n",
      "         1.6881e-13]], device='cuda:0')\n",
      "\n",
      "üöÄ Epoch 2/10\n",
      "üß™ Eval Batch 22/51 ‚Äî OMNI2 Mask Sum: 656640.0 | GOES Mask Sum: 5002624.0 | Density Mask Sum: 3364.0\n",
      "üß™ Eval Batch 28/51 ‚Äî OMNI2 Mask Sum: 656640.0 | GOES Mask Sum: 5302084.0 | Density Mask Sum: 3319.0\n",
      "üß™ Eval Batch 30/51 ‚Äî OMNI2 Mask Sum: 656640.0 | GOES Mask Sum: 5539086.0 | Density Mask Sum: 3358.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-17 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 59, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 35, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/multiprocessing/connection.py\", line 519, in Client\n",
      "    c = SocketClient(address)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/runpod_conda/lib/python3.12/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_storm_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_states_normalized\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36mtrain_storm_transformer\u001b[39m\u001b[34m(initial_states_df, num_epochs, batch_size, lr, device)\u001b[39m\n\u001b[32m     87\u001b[39m total_val_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdensity_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoes_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momni2_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1458\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1461\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1410\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1408\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1409\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1410\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1411\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1412\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1251\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1239\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1248\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1254\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1256\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/runpod_conda/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_storm_transformer(initial_states_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05500b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "runpod_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
